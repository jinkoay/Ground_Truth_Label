And we already got the crash out of the way. It did crash, so I feel much better, earlier.	0
@@	0
Yeah.	0
Interesting.	0
Hmm.	0
Will you get the door, and - ?	0
@@	0
O_K. You collected an agenda, huh?	0
O_K, so um.	0
I  did  collect an agenda. So  I'm  gonna go first.	0
Mwa-ha-ha!  It shouldn't take too long.	0
Yeah.	0
Um, so we're pretty much out of digits. We've gone once through the set.	0
Um, so the only thing I have to do	0
No there's only ten.	0
Yeah, that's right.	0
so I - I just have to go through them and uh	0
Well, O_K.	0
pick out the ones that have problems, and either correct them or have them re-read. So we probably have like	0
four or five more forms to be read, to be once through the set.	0
I've also extracted out about an hour's worth. We have about two hours worth.	0
I extracted out about an hour's worth which are the f- digits with - for which	0
whose speaker have speaker forms, have filled out speaker forms. Not everyone's filled out a speaker form. So I extracted one	0
for speakers who  have  speaker forms	0
and for meetings in which the "key" file and the transcript files are parsable.	0
Some of the  early  key files, it looks like, were done by  hand,  and so they're not automatically parsable and I have to go back and fix those.	0
So what that means is we have about an hour of transcribed digits that we can play with.	0
Um,	0
So you think two - you think two hours is the - is the total that we have?	0
Liz  -	0
Yep,	0
yeah.	0
And you think we-  th-  uh,	0
I - I didn't quite catch all these different things that are not quite right, but you think we'll be able to retrieve the other hour, reasonably?	0
Yes, absolutely.	0
O_K.	0
So it's just a question of a little hand-editing of some files and then waiting for more people to turn in their speaker forms.	0
I have this web-based speaker form, and I sent mail to everyone who hadn't filled out a speaker form, and they're slowly s- trickling in.	1
So the relevance of the speaker form here, s-	0
It's for labeling the extracted audio files.	0
Oh, O_K.	0
By speaker I_D and microphone type.	0
Wasn't like whether they were giving us permission to use their digits or something.	0
No, I spoke with Jane about that and we sort of decided that	0
it's probably not an issue that - We edit out any of the errors anyway.	0
Yeah.	0
Right? So the- there are  no  errors in the digits, you'll always read the string correctly.	0
So I can't imagine why  anyone   would care.	0
So the other topic with digits is uh,	0
Liz would like to elicit different prosodics, and so we tried last week with them written out in English.	1
And it just didn't work at all because no one grouped them together. So it just sounded like	1
many many more lines instead of anything else.	0
So in conversations with Liz and uh Jane	0
we decided that if you wrote them out as numbers instead of words it would elicit more phone number, social security number-like readings.	0
The problem with that is it becomes numbers instead of digits.	0
When I look at this, that first line is "sixty one, sixty two, eighteen, eighty six, ten."	0
Um, and so the question is does anyone care? Um, I've already spoken with Liz and she feels that,	0
Mm-hmm.	0
correct me if I'm  wrong,  that for  her,  connected numbers is fine, as opposed to connected digits.	0
Um, I think two hours is probably fine for a  test  set,	0
but it may be a little short if we actually wanna do training and adaptation and all that other stuff.	0
Yeah	0
Um, do um	0
you want different prosodics, so if you always had the same groupings you wouldn't like that? Is that correct?	0
Well, we actually figured out a way to - the - the groupings are randomly generated.	0
Yeah, the - the -	0
No but,	0
I was asking if that was something you really  cared  about because if it  wasn't,	0
it seems to me if you made it really specifically	0
telephone   groupings	0
that maybe people wouldn't, uh, go  and do  numbers so much.	0
You know if it- if it's -	0
Uh -	0
I think they may still do it, um,	0
Maybe  some,  but I- probably not so  much.	0
What about putting a hyphen between the numbers in the group?	0
And -	0
Right? So if you - if - if you have uh	0
Six dash one, you mean?	0
if you go six six six uh dash uh two nine three one.	0
I - well O_K - I - it  might  help, I would like to g- get away from having only one specific	0
grouping. Um, so if that's your question, but I mean it seems to me that, at least for  us,  we can learn to read them as digits if that's what people want. I - I'm	0
That's what I was asking, yeah.	0
Yeah.	0
Yeah.	0
Yeah.	0
don't think that'd be that hard to read them as single digits. Um,	1
I agree.	0
and it  seems  like  that  might be better for  you  guys since then you'll have just more  digit  data, and that's always a good thing.	0
Right.	0
It's a little bit better for me too because the digits are easier to recognize. They're better trained than the numbers.	0
Yep.	0
Right.	0
So we could just, uh, put in the	0
instructions "read them as digits".	0
Right. Right, read them as single digits, so sixty-one w- is read as six one, and if people make a mistake we -	0
Mm-hmm .	0
How about "O_" versus "zero"?	0
I mean, the other thing is we could just bag it because it's - it's -	0
it's- I'm not worrying about it I mean, because we  do  have digits training data that we have from	0
uh from [MASK]. I'm sorry, digits -  numbers  training that we have from [MASK], we've	0
done lots and lots of studies with that. And um.	0
But it's nice to get it in this room with the acous- I mean - for - it's -	0
Yeah.	0
No, no, I guess what I'm saying is that	0
Just let them read it how they read it.	0
to some extent maybe we could just read them - have them read how - how they read it	0
and  it  just means that we have to expand our - our vocabulary out to stuff that we already have. Yeah.	0
Right.	0
Well  that's  fine with  me  as long as - It's just that I didn't want to cause the people who  would  have been collecting  digits  the  other  way	0
to not have the digits. So -	0
We can go back to the other thing  later.  I mean we s- we - we've -	0
O_K.	0
We can do this for awhile and then go back to digits for awhile, or	0
um. Do yo- I mean, do you want - do you want this -	0
O_K.	0
Do you need training data or adaptation data out of this? How much of this do you need? with uh the -	0
It's actually unclear right now. I just thought well we're - if we're collec- collecting digits, and Adam had said we were running out of the T_I forms,	0
I thought it'd be nice to have them in groups, and probably, all else being equal, it'd be better for me to just have single digits since it's,	1
O_K.	0
you know, a recognizer's gonna do better on those anyway,	0
um, and it's more predictable. So we can know from the transcript what the person said and the transcriber, in general. But if they make mistakes, it's no big deal if the people say a hundred instead of "one O_O".	0
O_K, well if you pre-	0
and also w- maybe we can just let them choose "zero" versus "O_" as they - as they like because even the same person c- sometimes says "O_" and sometimes	0
says "zero" in different context, and that's sort of interesting.	0
Yeah.	0
So I don't have a	0
Specific need cuz if I did I'd probably try to collect it,	0
you know, without bothering this group, but	0
If we can try it -	0
O_K so - so I can just add to the instructions to read it as digits not as connected numbers.	0
Right, and you can give an example like,	0
Mm-hmm.	0
you know, "six - sixty-one would be read as six one". And  I   think  people will get it.	0
Right.	0
Mm-hmm. And i- actually it's no more artificial than what we've been doing with  words.  I'm  sure  people can adapt to this,	0
Right, right. It's just easier to read.	0
read it single. The spaces already bias it toward being separated.	0
Right.	0
And I know I'm gonna find this easier than words.	0
Oh yeah, absolutely,  cognitively  it's  much  easier.	0
O_K-	0
I  also  had a hard - hard time with the words, but then we went back and forth on that.  O_K, so let's give that a try and -	0
Yeah.	0
O_K. And is the spacing alright or do you think there should be more space between digits and groups?	0
O_K.	0
I mean what do other people think cuz you guys are reading  them.	0
Or is that alright?	0
I think that i- it's fine. I- it - it - to me it looks like you've got the func- the idea of grouping and you have the grou- the idea of separation and, you know, it's just a matter of u- i- the  instructions,  that's all.	0
O_K.	0
O_K.	0
Great. O_K. Well let's give it a try.	0
And I think there are about ten different gouping patterns isn't that right, Liz?	0
Let's try it.	0
Righ- right, and you just - they're randomly  generated and randomly assigned to digits.	0
That we did.	0
I did - Mm-hmm. Go ahead.	0
So we have - Sorry, I - I was just gonna say, so we have in the vicinity of forty hours	1
of - of recordings now.	1
And you're saying two hours, uh, is digits, so that's roughly the ratio then, something like twenty - twenty to one. Which I guess makes -	1
Yep.	0
makes sense. So if we did another forty hours of recordings then we could get another couple hours of this.	0
Right.	0
Um, yeah like you say, I think a couple hours for a - for a - for a test - test set's O_K.	1
It'd be nice to get, you know, more later because we'll - we might use - use this up, uh, in some sense, but - but uh -	0
Mm-hmm.	0
Right.	0
Yeah, I  also  would like to argue for that cuz it - it seems to me that, um,	0
there's a real strength in having the same test replicated in - a whole bunch of times and adding to that	0
basic test bank. Hmm? Cuz then you have, you know, more and more,	0
Right.	0
u- chances to get away from random errors.	0
And I think,	0
um, the other thing  too  is that right now we have sort of a  stratified  sample with reference to  dialect  groups, and it  might  be - there might be an argument to be made for having	0
uh f- for replicating  all  of the digits that we've done, which were done by non-native speakers so that we have a  core  that totally replicates the original data set,	0
which is totally American speakers, and then we have these stratified additional language groups overlapping certain aspects of the database.	0
Right.	0
I think that uh trying to duplicate,	0
spending  too  much effort trying to duplicate the existing [MASK]-digits	0
probably isn't too worthwhile because the recording situation is  so  different. It's gonna be very hard to be comparable.	1
Yeah.	0
Except  that if you have the stimuli  comparable,	0
then it says something about the - the contribution of setting and -	0
No it's - it's not the same.	0
A little bit, but the other differences are so major.	0
O_K.	0
They're such major sources of variance that it's - it's - it's uh -	0
Yeah I mean read versus not.	1
What's an example of a - of m- some of the other differences? Any	0
other a- difference?	0
Well i- i- individual human glottis  is going to be different for each one, you know, it's just - There's so many things.	0
O_K.	0
O_K.	0
it's - it - and - and enunciation.	0
Well, and not just that, I mean the uh	0
the corpus  itself.  I mean, we're collecting it in a read digit in a particular list, and I'm sure that they're doing	0
more specific stuff. I mean if I remember correctly it was like postman reading zipcodes and things like that.	0
[MASK] was? I thought - I thought it was read.	0
I thought so.	0
Was it read?	0
Yeah, I think the reading zipcode stuff you're thinking  of would be  [MASK].	0
Oh, I may well be.	0
Yeah, no [MASK] was read in th- in read in the studio I believe.	0
I haven't ever  listened  to [MASK]. So I don't really know how it compares.	0
Yeah.	0
Yeah. But it - but -	0
But - but  regardless  it's gonna - it's hard to compare cross-corpus.	0
It- it's different people  is the - is the  core  thing. And they're different circumstances with different recording environment and so forth, so it's - it's - it's really pretty different. But I think	0
So.	1
O_K, fine.	0
the idea of using a set thing was just to give you  some  sort of framework, so that even though you couldn't do  exact  comparisons, it wouldn't be s-  valid  scientifically at least  it'd  give you	0
some  kind of	0
uh frame of reference. Uh, you know it's not -	0
O_K.	0
Hey Liz,	0
What - what do the groupings represent? You said there's like ten different groupings?	1
Right, just groupings in terms of	1
number of groups in a line, and number of digits in a group, and the pattern of groupings.	1
Mm-hmm.	0
Are the patterns - like are they based on anything or	0
Um,	1
I - I just roughly looked at what kinds of digit strings are out there, and they're usually grouped into either two, three, or four,	1
Oh.	0
four digits at a time. And they can have,	1
I mean, actually, things are getting longer and longer.  In the old days you probably only had three sequences, and telephone numbers were less, and so forth.	0
So, there's between, um -	0
Well if you look at it, there are between like three and five groups, and each one has between two and	0
four groupings and -	0
I purposely didn't want them to look like they were in any kind of pattern. So	1
Mmm.	0
And  which  group appears is picked randomly, and what the  numbers  are are picked randomly.	1
Right.	0
Mm-hmm.	0
So unlike the previous one, which I d- simply replicated [MASK], this is generated randomly.	1
Mmm, oh, O_K.	0
Oh O_K.	0
But I think it'd be great i- to be able to compare digits, whether it's these digits or [MASK],	0
to speakers, um, and compare that to their spontaneous speech, and then we do need	0
you know a fair amount of - of digit data because you might be wearing a different microphone and, I mean - so it's - it's nice to have the digits	1
Mm-hmm.	0
you know, replicated many times.	1
Especially  for speakers that don't  talk  a lot. So  um, for adaptation. No, I'm serious, so	1
Yeah.	0
Yeah.	0
Yeah all we have for some people is digits.	0
we have a problem with acoustic adaptation, and we're not using the digit data now, but you know -	1
Yeah.	0
Oh, you're  not.	0
Not for adaptation, nope. v-	0
W- we're not - we were running adaptation only on the data that we ran recognition on	0
and I'd - As soon as someone started to read transcript number, that's read speech and I thought "well, we're gonna do better on that,	0
Oh I see.	0
that's not fair to  use ". But, it might be fair to use the data for adaptation, so.	0
Oh yeah that's true, absolutely.	0
O_K.	0
So those speakers who are very quiet,  shy - r- Right -	0
That would be interesting to  see  whether that  helps.	0
Do you think that would help adapting on - Yeah. Yeah, I have a real problem with that.	0
Like Adam?	0
Yeah.	0
Well, it sh- I mean it's the same micropho- see the nice thing is we have that in the - in the same meeting,	0
Right. Same - same acoustics, same microphone, same channel.	0
Yeah.	0
and so you don't get -	0
Yeah.	0
Right, and so I still like the idea of having some kind of	0
O_K.	0
Good.	0
digit  data .	0
Yeah I mean, for the - for the um	0
acoustic  research, for the signal-processing,	0
far-field stuff,	0
I see it as - as - as the place that we  start.	0
But, th- I mean, it'd be  nice  to have twenty hours of digits data, but - but uh the truth is I'm hoping that	1
we - we through the - the stuff that - that you guys have been doing	0
as you continue that, we get, uh, the best we can do on the spontaneous stuff uh,	0
uh near-field, and then um,	1
we do a lot of the testing of the algorithms on the digits for the far-field,	1
and at  some  point when we feel it's mature and we understand what's going on with it then we - we  have  to move on	0
to the spontaneous data with the far-field. So.	1
Great.	0
The only thing that we  don't  have, I know this	0
sounds weird, and maybe it's completely stupid, but we don't have any  overlapping  digits.	1
Yeah, we talked about that a couple times.	0
An- yea- I know it's weird, but	0
um -	0
Overlapping  digits!	0
The - the problem I see with trying to do overlapping digits is the cognitive load.	0
Alright everybody's laughing. O_K.	0
Dueling digits.	0
No it's - it's not stupid, it's just - I mean,  try  to  do  it.	1
I'm just talkin- for the stuff that like Dan  Ellis  is gonna try, you know, cross-talk cancellation. O_K.	0
I mean, here, let's try it. You read the last line, I'll read the first line.	0
Let's try it.	0
Oh!	0
Wait - oh it - these are all the same forms. O_K  So but -	0
Sixty-one.	0
So - so you read the last line, I'll read the first line.	0
So you plu- you plug your ears.	0
No, I'll p-	0
Oh I guess if you plug you're ears you could do it, but then you don't get the -	0
the same effects.	0
Well, what I mean is actually no-	0
Yeah.	0
not the overlaps that are well-governed linguistically, but the actual	0
fact that there is speech coming from two people and the beam-forming stuf- all the acoustic stuff that like Dan Ellis and - and company want to do.	0
Yeah.	0
Oh I see.	0
Digits are nice and well behaved, I mean	0
Anyway, it's just a thought. It - it would go faster.	0
I guess we could try. We could try doing some.	0
Parallel.  It's the [MASK] of digit reading.	0
It would take one around  amount of ti-  That's right.	0
Well - Well O_K. Well let's try it.	0
I - I mea- I'm - I was sort of serious, but I really, I mean, I'm - I don't feel strongly enough that it's a good idea, so.	0
See, y-	0
You do the  last  line, I'll do the  first  line.	0
O_K.	0
That's not bad.	0
No, I can do it.	0
A- and that prosody was  great,  by the way.	0
I couldn't understand a single thing you guys were saying.	0
I  think  it was numbers, but I'm  not   sure.	0
It - it sort of sounded like a duet, or something.	0
Yeah.	0
Performance art.	0
Alright , let's try  three  at once you - you pick one in the middle.	0
The Aurora theater.	0
O_K.	0
Go.	0
I'm sorry. I'm mean I think it's doable, I'm just -	0
The  poor  transcribers they're gonna hate us.	0
So, we - we  could  have a  round  like where you do two at a time, and then the next person picks up when the first guy's done, or something. Like a,	0
So pairwise.	0
Oh like a round, yeah, like in a - a - yeah.	0
Yeah, just pairwise, or yeah.	0
what do you call it? Li- a r- like - yeah, like that.	0
Row, row, row your boat.  Yeah.	0
A round.	0
Round.	0
Mm-hmm.	0
O_K.	1
It's gonna require some coordination.	0
Then it would go like h-  twice  as fast, or  a  third  as fast.	0
Anyway, it's just a thought. I'm actually sort of serious if it would help people do that kind o- but the people who wanna work on it we should talk to them. So.	1
Yeah.	0
You have to have a similar pace.	0
I don't think we're gonna collect vast amounts of data that way, but I think having a little bit might at least be fun for somebody like Dan to play around with, yeah.	1
Mmm.	0
O_K.	0
I think maybe if we wanted to do that we would do it as a separate session, something like that rather than	1
Yeah.	0
doing it during a real meeting and you know, do two people at a time then three people at a time and things like that. So.	0
Can try it out. If we have nothing - if we have no agenda we could do it some week. O_K.	0
See - see what Dan thinks.	0
Yeah, right.	0
Yeah, yeah. Spend the whole time reading digits with different qu- quantities.	0
c- c- Can I- can I have an- another - another question w-  about  this? So, um, there are these digits, which are detached digits, but there are other words that  contain	0
I  thought  this was gonna be fast. Oh well.	1
the same	0
general phon- phoneme sequences. Like "wonderful" has "one" in it and - and Victor Borge had a - had a  piece  on this where he inflated the digits. Well,	0
I wonder if there's, um, an- if there would be a value in  having  digits that are in essence embedded in real words to	0
compare in terms of like the articulation of "one" in "wonderful" versus "one" as a digit being read.	0
That's "two" bad.	0
Yeah.	0
I'm all "four" it.	0
There  you go.	0
Not after I "eight" though.	1
Uh, they don't all work as  well,   do  they?	0
Hmm.	0
What  does  nine  work in? Uh,	0
Uh.	0
Nein!	0
You scream it.	0
Nein!   You have to be German, yeah.	0
Oh.  In  German,  yeah.  That's right!	0
Oh, oh!	0
It's great for the Germans.	0
That's German, yeah.	0
Nein.	0
Yeah.	0
Oh!	1
It only sounds w- good when you  scream  it, though.	0
I think everybody's a little  punchy  here  today. Yes.	0
So.	0
Well, I mean, I just wanted to offer that as a possible task	0
because, you know, if we were to each read his embedded	0
numbers words in sent- in sentences cuz it's like an entire sketch he does and	0
I wouldn't take the inflated version. So he talks about the woman being "two-derful", and -	0
and - a- But, you know, if it were to be deflated, just the normal word, it would be like a little  story  that we could read.	0
Mm-hmm.	0
I don't know if it would be useful for comparison, but it's  embedded  numbers.	0
Well I don't know.	0
I think for something like that we'd be better off doing like uh [MASK].	0
Well I think the question is what the research is, so I mean, I presume that	0
the reason that you wanted to have these	0
digits this way is because you wanted to actually do some research	0
Hmm.	0
looking at the prosodic	0
form here.	0
Right, yeah.	0
Yeah O_K.	0
So if somebody  wanted  to do that, if they wanted to look at the - the - the difference of	0
the uh phones in the digits in the context of a word versus uh	0
the digits - a - a non-digit word versus in digit word, uh that would be a good thing to do, but I think someone would have to express interest in that.	1
I see. O_K.	0
I think, to -	0
I mean if  you  were interested in it then we could do it, for instance.	0
O_K,  thank  you.  Huh.	0
O_K, are we done with digits?	0
Um,	0
We have [MASK] results from Liz, transcript status from Jane, and disk space and storage formats from Don.	1
Does - do we have any prefer- preference on which way we wanna - we wanna go?	0
Well I was actually gonna skip the [MASK] results part, in favor of getting the  transcription  stuff	0
Mm-hmm.	1
talked about since I think that's more	0
important to moving forward, but I mean Morgan has this paper copy and if people have questions,	0
um, it's pretty preliminary in terms of [MASK] results because we didn't do anything fancy, but I think	1
e- just having the results there, and pointing out	0
some main conclusions like it's not the speaking style that differs, it's the fact that there's overlap that causes recognition errors.	1
And then, the fact that it's almost all insertion errors, which you would expect but you might also think that	1
in the overlapped regions you would get substitutions and so forth,	1
um,	1
leads us to believe that	0
doing a better segmentation, like your channel-based segmentation, or some kind of	0
uh, echo cancellation to get basically back down to the individual	0
speaker utterances would be probably all that we would need to be able to do good recognition on the - on the close-talking mikes.	1
Um, why don't you, if you have a hard copy, why don't you email it	1
So these -	0
So, that's about the summary -	0
to the list.	1
But this is - Morgan has this paper. I mean he - he - it - it's that paper. Yeah, yeah.	0
Yeah, yeah.	0
Yeah, so it's the same thing? It's the same thing I mailed to every-	0
Oh it's in the paper.	0
O_K.	0
everybody that w- where it was, yeah.	0
So, we basically, um,	0
O_K then, it's already been mailed.	0
did a lot of work on that and it's -	0
Let's see, th-	0
I guess the other neat thing is it shows for sure w- that the lapel, you know within speaker is	1
Horrible?	0
bad. And it's bad because it picks up the overlapping speech.	1
So, your - your [MASK] results were run on the channels  synchronized,  O_K.	0
Yes, cuz that's all that w- had been transcribed at the time,  um	0
O_K. O_K.	0
but as we - I mean I wanted to here more about the transcription. If we can get	0
the	0
channel  asynchronous  or the - the closer t-  that  would be very interesting for us because we -	0
Yeah.	0
So if -	0
Yeah, that's - that's why I only	0
Yeah.	0
used the part from use- which we had uh about uh about the alt- over all the channels or mixed channel rather  mixed  signal.	0
Right. That's -	0
Yeah.	0
Yeah sure. Yeah.	0
Yeah.	0
cuz -	0
So if there was a  segment   of speech this long	1
Yeah.	0
And someone said "oh" in the front - in the middle.	1
and	0
oh and someone said "oh," the whole thing was passed to the recognizer? That's why there's so many insertion errors?	0
There were several speakers in it, yeah.	0
That's  right.  In fact I - I pulled out a couple classic examples in case you wanna u- use them in your talk of	0
Mm-hmm.	0
Chuck on the lapel, so Chuck wore the lapel three out of four times.	0
Mmm.	0
I  noticed  that Chuck was wearing the lapel a lot.	0
Um, yeah, and  I  wore the lapel  once,  and for  me  the  lapel  was  O_K . I mean I still -	0
Early on, yeah.	0
and I don't know why. I'm - But	0
um,	0
for  you  it was - Or who was next to me or something like that.	0
Probably how you wear it - wore it I would guess.	0
Yeah, where you were sitting probably affected it.	0
Yeah.	0
Right, but when Chuck wore the lapel and Morgan was talking there're a couple really long utterances where Chuck is	0
saying a  few  things inside, and it's picking up all of Morgan's words pretty well	0
and so the rec- you know, there're error rates because of insertion -	1
Insertions aren't bounded, so with a one-word utterance and ten insertions you know you got  huge  error rate.	1
Uh-huh.	0
Yeah.	0
And that's - that's where the problems come in. So I- this is sort of what we expected, but it's nice to be able to - to show it.	1
Right.	0
And also I just wanted to mention briefly that, um,	1
uh Andreas and I called up Dan Ellis who's still stuck in Switzerland, and we were	1
gonna ask him if - if there're -	0
you know, what's out there in terms of echo cancellation and things like that. Not that we were gonna do it, but we wanted to know	1
And he said, "Lots lots lots lots."	1
what would need to be  done.  And	0
he - We've given him the data we have so far, so these sychronous cases where there are overlap.	0
Yep.	0
And he's gonna look into trying to run	0
some things that are out there and	0
see how well it can do	0
because right now we're not  able  to actually report on recognition in a real paper, like a Eurospeech paper, because it would look sort of premature.	1
So -	0
So -	0
So the idea is that you would take this big hunk where somebody's only speaking	0
a small amount in it, and then try to figure out	0
where  they're speaking  based on	0
Right. Or who's - At any point in time who's the foreground speaker, who's the background speaker.	0
the  other  peopl-	0
I thought we were just gonna move the  boundaries  in.	0
So yeah -	0
So.	0
Yeah, should it -	0
Well that's with the hand stuff.	0
So there's like -	0
But how would you do that automatically?	1
Right.	0
Uh, I've actually done some experiments with cross-correlation and it seems to work pretty well to - to get rid of those - those overlaps, yeah.	0
Well ther- there's -	0
Mm-hmm.	0
I mean that- that's the sort of thing that you would  do.  So.	1
Yeah. Yeah.  Exactly,  so it's - it's a -	0
So why do you want to do echo cancellation?	0
Um, it would be techniques used from adaptive - adaptive echo cancellation which I don't know enough about to talk about. Um.	0
Uh-huh.	0
It - just - it just to r- to remove cross-talk. Yeah.	1
Yeah.	0
But, right, um, and that would be similar to what you're also trying to do, but using	0
um, you know, more than energy - I - I don't know	0
Yeah.	0
what exactly would go into it. So the idea is to basically run this on the whole meeting.	1
Yeah, sure.	0
So it would be -	0
and get the locations, which gives you also the time boundaries	1
O_K. So do sort of what he's already - what he's  trying  to do.	0
of the individual speak-	1
Right. Except that there are many techniques for the kinds of cues, um, that you can use to do that.	1
O_K, I s- I see.	0
Yeah, in another way, yeah.	0
Yeah.	0
Yeah.	0
I see.	0
Yeah, Dave - Dave uh is, um, also gonna be doin- usin- playing around with echo cancellation for the near-field far-field stuff, so we'll be -	0
So.	0
And I guess Espen? This - is - uh - is he here too? May also be working - So it would just be ver- that's really the next step because we can't	1
Yeah.	0
do too much, you know, on term- in terms of recognition results knowing that this is a big problem	1
Mm-hmm.	0
um, until we can do that kind of processing.	1
And so, once we have some -	0
O_K.	0
Yeah I'm working on it.	0
some of yours, and  @@  we'll move on.	0
I think this also ties into one of the things that Jane is gonna talk about too.	0
Um,	0
O_K.	0
Mm-hmm. Mm-hmm.	0
I also wanted to say I  have  done all this chopping up of digits, so I have some naming conventions that we should try to agree on.	0
Oh right. Yeah. Right. Definitely -	0
So let's do that off-line, we don't need to do it during the meeting.	0
O_K.	0
Uh, and Don should -	0
And - and I have scripts that will extract it out from "key" files and -	0
and do all the naming automatically, so you don't have to do it by hand.	0
O_K.	0
Alright.	0
Great. So that- that's it for the -	0
You've compiled the list of, uh, speaker names?	0
Speakers and -  O_K.	0
Mm-hmm.	0
Not names, but	0
Yep. Yeah, names - names in the - names to I_Ds, so you	0
I_Ds.	0
O_K.	0
Great.	0
and it does all sorts of matches because the way people filled out names is different on every single file so it does a very fuzzy sort of match.	0
Right.	0
Cool.	0
So at this point we can sort of finalize the naming, and so forth, and we're gonna basically re-	1
Yep.	0
Mm-hmm.	0
rewrite out these waveforms that  we  did because as you notice in the paper your [MASK] in one meeting	1
Yeah.	0
That was my fault.	0
um, no it's - it's -	0
No, I  didn't  notice that actually.  @@	0
um, that's why those comments are s-  are in there. So -	0
Yeah. Then disregard it then.	0
Yep. So th- I now have a script that you can just say basically	0
Right.	0
Yeah.	0
O_K.	0
look up Morgan, and it will give you his I_D. So.	0
Great, great. Terrific.	0
O_K .	0
Um,	0
alright.	0
Do we -	0
Don, you had disk space and storage formats.  Is that something we need to talk about at the meeting,  or should you just talk with Chuck	1
Um,	0
at some other time?	0
I had some general questions just about	0
the compression algorithms of shortening waveforms and I don't know exactly who to ask. I thought that maybe you would be the -	0
the person to talk to. So, is it a lossless compression  when you compress, so -	0
Mm-hmm.	0
Entropy coding. So.	0
It just uses entropy coding? O_K. So, I mean, I guess my question would be is I just got this new eighteen gig drive installed.	0
Um, yeah, which is -	0
And I assume half of it is scratch and half of it is - ?	0
I'm not exactly sure how they partitioned it. But um,	0
Probably, yeah.	0
That's  typical,  huh.	0
yeah, I don't know what's typical here, but um,	0
it's  local  though, so -	0
That  doesn't matter.	0
But -	0
You can access it from anywhere in ICSI.	0
O_K.	0
In fact, this is an eighteen gig drive,  or is it a thirty six gig drive with eighteen -	0
Alright. How do you  do  that?	0
N_ -	0
Eighteen.	0
Eigh- eighteen. It was a spare that Dave had around -	0
Oh O_K.	0
Slash N_ slash machine name, slash [MASK] in all likelihood.	0
Oh I see. O_K. Alright, I  did  know that.	0
Um, so the - the only question is how much of it - The distinction between scratch and  non-scratch  is whether it's backed up or not.	0
Mm-hmm.	0
Right.	0
So what you wanna do is use the  scratch  for stuff that you can regenerate.	0
O_K.	0
So,	0
the stuff that isn't backed up is not a  big  deal because disks don't crash very  frequently,  as  long  as you can regenerate it.	0
Right.	0
Right. I mean  all  of this stuff can be regenerated, it's just a question -	0
Yeah it's -	0
Well the -	0
Then put it all on scratch because we're - ICSI is - is bottlenecked by backup.	0
Yeah.	0
Mm-hmm, very good point.	0
O_K.	0
Well I'd leave all the - All the transcript stuff shouldn't -  should  be backed up, but all the waveform -	0
So we wanna put -	0
Mm-hmm.	0
Sound  files should not be backed up, the ones that you write out.	0
Yeah, I guess -	0
Right.	0
O_K. So, I mean, I guess th- the other question was then,	0
should we  shorten  them, downsample them, or keep them in their original form?	0
Um -	0
It just depends on your tools.	0
I mean, because it's not backed up and it's just on scratch, if your sc- tools can't  take  shortened format, I would leave them expanded,	0
Right.	0
so you don't have to unshorten them every single time you wanna do  anything.	0
O_K.	0
We  can  downsample them,	0
Do you think that'd be O_K?	0
so.	0
Yeah.	0
To downsample them?	0
Yeah, we get the same performance. I mean the r- the front-end on the [MASK] just downsamples them on the  fly,  so -	1
O_K.	0
Yeah, I guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques.	0
So that's -	0
I - I - I'm sorry - Yeah, l- I mean over  all  our data, we - we want to not downsample.	1
Yeah, if	0
fe-	0
You'd - you wanna not. O_K. So we're - what we're doing is we're writing out -	0
Yeah.	0
I mean, this is just a  question.	0
We're writing out these individual	0
segments, that wherever there's a time boundary from Thilo, or - or Jane's transcribers, you know, we - we chop it  there.	0
Yeah.	0
Mm-hmm.	0
And the reason is so that we can feed it to the recognizer, and throw out ones that we're not using and so forth.	0
Mm-hmm.	0
Yeah.	0
And  those  are the ones that we're  storing.	0
Yeah, as I said, since that's - it's  regeneratable,  what I would do is take -	0
So -	0
Yeah.	0
downsample it,	0
and compress it however you're e- the [MASK] wants to take it in.	0
Yeah.	0
So we can't shorten them, but we can downsample them. So.	1
ye-	0
Right.	0
Yeah, I mean - yeah, I'm sorry. As - yeah, as long as there is a - a form that we can come from again,	1
r-	0
Yeah.	0
that is not  downsampled,   then,	1
Oh yeah th-	0
Yeah those are gonna be kept.	1
Yeah.	0
Yeah.	1
That - that's why we need more disk space cuz we're basically duplicating the originals, um -	1
uuu	0
Yeah. Then it's fine. But for - for - fu- future research we'll be doing it with different microphone positions and so on we would like to -	0
Right.	0
Oh yeah. No. We always have the original long ones.	0
Yep.	0
Right.	0
Yeah.	0
So the S_R_I front-end won't take a uh - an - an - a large audio file name and then a -	1
a list of segments to chop out	0
from that large audio file?  They actually have to be chopped out already?	1
Um, it's better if they're chopped out, and - and it - it will be -	1
Uh-huh.	0
yeah, y- we could probably  write  something to do that,  but it's actually  convenient  to have them chopped out cuz you can run them,	1
you know, in different orders. You c- you can actually move them around.	1
And that's the whole point about the naming conventions is that you could	1
Uh, you can get rid of-	0
Yeah, it- it's a  lot   faster.	0
run all the  English  speaking,	0
all the native speakers, and all the  non-native  speakers, and all the  men,  and all the  women.  Yeah.	0
Right.	0
You can grab everything with the word "the" in it, and it's -	0
That's a lot quicker than actually trying to access the wavefile each time, find the time boundaries and -	0
So in principle, yeah, you  could   do  that, but it's -	0
I don't - I don't think that's really  right.	0
but it's um -	0
"That's just not right, man."	0
These are long - These are long - You know. This is an hour of speech.	0
The - the point -	0
So - so s- For example, what if you wanted to run -	0
run all the native speakers.	0
Right, so if - if you did it  that  way you would have to generate a program that looks in the database somewhere, extracts out the language, finds the time-marks for that  particular  one, do it  that  way.	0
The way  they're  doing it, you have that already  extracted  and it's  embedded  in the file name.	0
And so, you know, you just say -	0
We- yeah that's - so that's part of it is -	0
y- so you just say you know "asterisk E_ asterisk dot wave", and you get what you want.	0
Right.	0
And the other part is just that once they're written out it - it is a lot faster to -	0
to process them.	0
Rather than doing seeks	0
So.	0
through the file.	0
Otherwise, you're just accessing -	0
This is all just temporary access, so I don't - I think - it's all just - It's fine. You know.	0
Fine to do it however is convenient.	0
Right.	0
I mean it just depends how big the file is. If the file sits in memory you can do extremely fast seeks but.	0
Right.	0
The other thing is that, believe it or not -	0
Yeah and they don't.	0
I mean, we have some -	0
Two gig?	0
So we're also looking at these in Waves like for the  alignments  and so forth.	1
You can't  load  an hour of speech into  [MASK] .	1
Yeah.	0
You need to s- have these small files, and in fact, even for the  Transcriber  program	1
Yes  you can.	0
Um -	0
Yeah, you -  you  can give Waves a start and an end time.	0
And middle.	0
Yeah, if you try to load s- really long waveform into [MASK], you'll be  waiting  there for -	0
No, I - I'm not suggesting you load a long wave file, I'm just saying you give it a start and an  end  time. And it'll just	0
Oh-	0
I th-	0
go and pull out that section.	0
w- The  transcribers  didn't have any problem with that did they Jane?	0
What's th- u- w- in what respect?	0
Loading the long -	0
They loaded - they loaded the long	0
No, with the  Transcriber  tool, it's no  problem.	1
long files into [MASK].	0
It takes a very long ti-	0
In the - in-	0
Yeah just to load a  transcription	0
Mm-hmm.	0
@@	0
Right.	0
It takes a l- very long time.	0
takes a long time, but not for the wavefile. The  wavefile  is there  immediately.	0
Mm-hmm.	0
Yeah.	0
Huh.	0
Are you talking about  Transcriber  or  [MASK] ?	0
Yeah.	0
Oh, I'm tr- talking about Transcriber.	0
Actually,	0
you're talking about Transcriber, right?	0
Yeah.	0
It was also true of the digits task which was [MASK].	0
Because -	0
because i- we used [MASK] to do the  digits.	0
Yeah.	0
And they were loading the full mixed files then, and it didn't  seem  to be any problem.	0
Very quickly.	0
I agree.	0
Huh.	0
Well we - we have a problem with that,	0
you know, time-wise on a -	0
It- it's a lot slower to load in a long file, and also to check the file,  so if you have a	0
Hmm.	0
Seemed really fast.	0
transcript, um,	0
Well  regardless,  it's -	0
I mean it's -	0
Yeah.	0
I - I think	0
overall  you  could  get everything to work by	0
accessing the same waveform and trying to find two - you know, the begin and end times.	0
Um,	0
but I think it's more efficient, if we have the storage space, to have the small ones.	0
and, it's no problem, right? Because it's not backed up.	0
Yeah, it's -	0
Yeah.	0
It's - it's just -	0
So we just -	0
If we  don't  have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space.	0
You know, it's  not  a big deal.	0
You're right about the backup being  a bottleneck. It's good to	0
Right.	0
Yeah, so these wouldn't be backed up, the -	0
think towards scratch.	0
Yeah.	0
Yep.	0
Right.	0
So remind me afterward and I'll -	0
And -	1
and we'll look at your disk and see where to put stuff.	0
O_K.	0
Alright.	0
I mean, I could just u- do a [MASK] on it right? And just see which - how much is on each -	0
Yep.	0
So.	0
Each partition. And you wanna use, either [MASK] or scratch.	0
O_K.	0
Well X_ question mark, anything starting with X_ is scratch.	0
O_K.	0
With two - two digits.	0
Two digits, right, [MASK],	0
O_K? Jane?	0
So,  @@ .	0
O_K. So I got a little  print-out  here. So three on this side, three on this side.	0
And I stapled them.	0
O_K.	0
Alright so, first of all, um, there was a -	1
an interest in the transcribe- transcription, uh, checking procedures and -	1
and I can  tell you first, uh, to go through the steps although you've probably seen them.	0
Um, as you might  imagine,  when you're dealing with,	0
um,	0
r-	0
really c- a fair number of words, and uh,	0
@@	0
natural  speech which means s- self-repairs and all these other factors, that there're	0
lots of things to be,	0
um, s- standardized and streamlined and checked on.	0
And, um,	0
so,	0
I did a bunch of	0
checks, and the first thing I did was obviously a spell-check. And at that point I discovered certain things like,	1
um, "accommodate" with one "M_", that kind of thing.	0
And then, in addition to that, I did an exhaustive listing of the  forms  in the data file, which included n- detecting things like f- faulty punctuation and things - Yeah?	1
I'm - I'm sorry to interrupt you could - could I just back up a little bit and -	0
Sure, please, yeah, please, please. Yeah, yeah, yeah.	0
So you're doing these - So  the whole process is that the transcribers get the conversation and they do their pass over it.	0
Yes.	0
And then when they're finished with it, it comes to you, and  you  begin these sanit- these quality checks. O_K. O_K.	0
That's right.	0
Exactly. I do these checks. Uh-huh. Exactly.	0
Yeah.  Thank  you.	0
And so, uh, I do a - an exhaustive listing of the forms -	0
Actually, I  will  go through this in - in order, so if - if we could maybe wait and stick	0
keep that for a second cuz we're not ready for that.	0
So on the  fifth  page, seven down -	0
Yeah, yeah, yeah, yeah. Exactly! Exactly!	0
Alright so,	0
a spelling check first then an exhaustive listing of the, uh - all the forms in the data with the punctuation attached	0
and at that point I pick up things like,	0
oh, you know, word followed by two commas. And th- and	1
then another check involves, uh, being sure that every utterance has an identifiable speaker.	1
And if  not,  then  that  gets checked.	0
Then there's this issue of glossing s- w- so-called "spoken-forms".	1
So there -	1
mo- for the most part, we're keeping it standard wo- word level transcription. But there's -	1
w- And that- that's done with the assumption that  pronunciation variants can be handled. So for things like "and",	0
the fact that someone doesn't say the "D_",	0
uh that's not important enough to capture in the transcription because a - a good pronunciation, uh,	0
you know, model would be able to handle that. However, things like "cuz" where you're lacking an entire very prominent first syllable,	1
and furthermore, it's a form that's specific to spoken language,	0
those are r- reasons - f- for  those  reasons I - I kept that separate, and used the convention of using "C_U_Z" for that form,	1
however,   glossing  it so that it's possible with the script to plug in the full	1
orthographic form for that one, and a couple of others, not many. So "wanna" is another one, "going -" uh, "gonna" is another one,	1
with just the assumption, again, that this - th- these are things which it's not really fair to a- c- consider - expect that - a pronunciation model, to handle.	0
And  Chuck,  you in- you indicated that "cuz" is -	0
is one of those that's handled in a different way also, didn't you? Did I -	0
I don't remember.	0
O_K. So - so- it might not have been -  It might not have been you, but someone told me that in fact "cuz" is treated differently	0
Hmm.	0
in, um, i- u- in this context because of that r- reason that, um, it's a little bit farther than a pronunciation variant.	0
O_K, so after that, let's see, um.	0
So that was part of the spell-check,  or was that - that was  after  the spell-check?	0
Well so when I get the exhau- So the  spell-check  picks up those words because they're not in the dictionary. So it gets "cuz" and "wanna" and that -	0
Uh-huh.	0
And then you gloss them?	0
Yeah, mm-hmm. Run it through - I have a sed - You know, so I do sed script saying whenever you see "gonna"	0
you know, "convert it to gonna", you know, "gloss equals quote going-to quote",	0
you know. And with all these things being in curly  brackets  so they're always  distinctive.  O_K, I also wrote a script which will,	0
Mm-hmm.	0
um,  retrieve  anything in curly brackets,	0
or anything which I've classified as an acronym,	0
and -	0
a  pronounced  acronym.	0
And the way I tag ac-  pronounced  acronyms is that	1
I have underscores between the components. So if it's "A_C_L"	1
then it's "A_" underscore "C_" underscore "L_".	0
And the th-	0
And so - so your list here, are these ones that actually occurred in the meetings?	0
Yes. Uh-huh, yeah.	0
Whew!	0
O_K, so  now.	0
Uh and - a-	0
We are acronym- loaded.	0
Um, can I ask a question about the glossing, uh before we go on? So,	0
Yeah.	0
for a word like "because"	0
is it that it's always predictably "because"?	0
I mean, is "C_U_Z" always meaning "because"?	0
Yes, but not the reverse. So sometimes people  will  say "because" in the meeting, and if - if they actually  said  "because",	0
then it's written as "because" with no - w- "cuz" doesn't even figure into the equation.	0
Beca- because -	0
But - but in  our  meetings people don't say "hey cuz how you doing?"	0
Right.	0
Right.	0
Except right there.	0
Yeah.	0
Yeah.	0
Um, so, I guess - So, from the point of view of -	0
That's a good point.	0
The - the  only  problem is that with - for the recognition we - we map it to "because", and so if we know that "C_U_Z" -	1
Well,	0
That's fine. Well Don has a script.	0
but they have the gloss. You have the gloss form so you always replace it.	0
Yeah.	0
but, we don't -	1
Exactly.	0
If that's how - what you wanna do.	0
Uh-huh. And  Don  knows this, and he's bee- he has a glo- he has a script that -	0
Yeah.	0
I replace the "cuz" with "because" if it's glossed.	0
S-	0
Right. But,	0
if it's -	0
O_K.	0
And -	0
But then there are  other  glosses that we  don't	0
replace, right?	0
Because -	0
Yes. And that's why there're different tags on the glosses,	0
O_K. So, then it's fine.	0
on the different - on the different types of comments, which we'll - which we'll see in  just  a second.	0
Right.	0
O_K.	0
So the pronounceable acronyms get underscores, the things in curly brackets are viewed as comments. There're comments of four types. So this is a good time to introduce that.	1
The four types. w- And maybe we'll expand that but the - but the comments are, um, of four types  mainly  right now. One of them is, um,	1
Um -	0
Can - ca-	0
the gloss type we just mentioned.	1
Another type is, um -	0
So a- are we done with acronyms? Cuz I had a question on what - what this meant.	0
I'm still doing the overview. I haven't actually gotten here yet.  O_K so, gloss is things like replacing the full form	0
Oh I'm sorry.	0
u- with the, um,	0
more abbreviated one to the left.	0
Uh, then you have if it's - uh, there're a couple different types of	1
elements that can happen that aren't really	0
properly  words,  and wo- some of them are laughs and breathes, so we have - uh that's prepended with a v- a tag of [MASK].	1
Whew!	0
@@	0
And the non-vocal ones are like door-slams and tappings, and that's prepended with a	0
no-  non-vocalization.	0
So then it - just an ending curly brace there, or is there something else in there.	0
Oh yeah, so i- e- this would -	0
Let's just take one example.	0
A comment, basically.	0
Oh, oh, oh.	0
And then the no- non-vocalization would be something like a door-slam.	0
They always end. So it's like they're paired curly brackets. And then the third type right now,	1
uh, is  m- things that fall in the category of  comments  about what's happening. So it could be something like,	1
you know, "referring to so-and-so", "talking about such-and-such",	0
uh, you know, "looking at so-and-so".  Yeah.	0
So on the m-	0
on the middle t- So, in the  first  case that gloss applies to the word to the left. But in the  middle  two -	0
Yeah, and this gets substituted here.	0
They're impulsive.	0
Th- it's not applying to anything, right? O_K.	0
Huh-uh.	0
No, they're events.	0
They're actually - They have the status of events.	0
O_K.	0
Well the "[MASK]" can be - The "[MASK]" is applying to the left.	0
Right, I just meant the middle two ones, yeah.	0
Yep.	0
Well, and actually, um, it  is   true  that, with respect to "laugh", there's  another  one	0
which is "while laughing", and that is, uh, i- i- An argument could be made for this -	0
"While laughing".	0
tur- turning that into a qualitative statement because it's talking about the thing that preceded it, but at present we haven't been, um,	0
uh,  coding  the exact  scope  of  laughing,  you know,	0
and so to have "while laughing", you know that it happened somewhere in there which could well mean that it occurred	0
separately and following, or, you know, including some of the utterances to the left. Haven't been awfully precise about that, but I have here,	0
now we're about to get to the - to this now,  I have  frequencies.  So you'll see how often these different things occur. But, um,	1
uh, the very front page deals with this, uh, final	0
c- pa- uh, uh, aspect of the standardization which has to do with	1
the spoken forms like "mm-hmm" and "mm-hmm" and "ha" and "uh-uh" and	0
all these different types. And, um, uh, someone pointed out to me,	1
this  might have been Chuck,  about, um - about how a recognizer, if it's looking for "mm-hmmm" with  three  M_'s,  and it's transcribed with  two  M_'s,	0
that it might - uh, that it might increase the error rate which is - which would  really  be a  shame  because	0
um, I p- I personally w- would not be able to make a claim that those are dr- dramatically different items.	0
So, right now I've standardized across  all  the existing data with these spoken forms. I - I should say	1
Oh good. So it's a small list.	0
all existing data except thirty minutes which got found today. So, I'm gonna -  I'm gonna -  I'm gonna check -	0
That - that's known as "found data".	0
Yeah, yeah. Acsu- actually yeah. I got - It was stored in a place I didn't expect,	0
It's like the z- Zapruder Film.	0
so - and - and um,	0
w- we, uh, sh- yea- reconstructed how that happened.	0
I wanna work with  lost  data.	0
Yeah. It's much easier.	0
And this is - this'll be  great.  So I'll - I'll be able to get through that tonight, and then everyth- i- well, actually later today probably.	0
Hmm.	0
And so then we'll have everything following these conventions. But you notice it's really rather a small set	0
of these kinds of things. And I made it so that these are, um, with a couple exceptions but, things that you wouldn't find in the spell-checker so that they'll show up really easily.	0
Yeah.	0
And, um -	0
Jane, can I ask you a question? What's that very  last  one correspond to? I don't even know how to pronounce that.	0
Sure.	0
Yeah.	0
Well, yeah. Now that - that s- only occurs once, and I'm thinking of changing that.	0
Right.	0
So- c- I haven't listened to it so I don't know.	0
Uh, is that like someone's like  burning  or some  such  thing? Like their  hair's  on fire?	0
I haven't heard it actually. I n- I need to listen to that one.	0
Ah!	0
Uh,  it looks like that .	0
Actually we - we gave this to our pronunciation person, she's like, "I don't know what that is  either ". So.	0
It's the Castle of Ah!	0
Did she hear the th- did she actually hear it? Cuz I haven't heard it.	0
No, we just gave her a list of words	0
that, you know, weren't in our dictionary and so of course it picked up stuff like this, and she just	0
didn't listen so she didn't know. We just -	0
we're waiting on that  just to do the alignments.	0
Yeah. Yeah I'm curious to se- hear what it is, but I didn't know - wanna change it to something else until I knew.	0
Maybe it's "argh"?	0
Right.	0
@@	0
Well, sss,  you know -	0
But  that's  not really like -	0
Hhh.	0
Yeah.	0
No one really says "argh," you know, it's not -	0
@@	0
Right, no one say-	0
Well,  you  just did.	0
Well,	0
Yeah.  That's right.	0
@@  -	0
there's another - there's another word error.	0
Except for now!	0
Yes, that's right. We're gonna have a big problem when we talk about that.	0
Cha- ching.	0
Ah.	0
We're gonna  never  recognize this meeting.	0
O_K.	0
In  Monty Python you say "argh" a lot. So. Well, or if you're a  C_  programmer.	0
Oh yeah?	0
Mmm.	0
Yeah, that's right. That's right.	0
Yeah.	0
You say [MASK]	0
That's true.	0
Yeah	0
Yeah.	0
But it has a different prosody.	0
Arg.	0
It does.	0
Arg - [MASK], yeah.	0
Mm-hmm.	0
Ah!	0
Uh,	0
So, Jane, what's the - d- I have one question about the	0
Maybe he died while dictating.	0
so.	0
the "[MASK]" versus like th	0
That's partly a nonnative-native thing, but I have found "[MASK]" in native speakers too.	0
@@	0
O_K.	0
But it's mostly non-native -	0
S- O_K.	0
H_	0
That's "eh" versus "ah"?	0
Eh.	0
Eh?	1
"Eh," yeah right, cuz there were - were some speakers that did definite "eh's" but right now we -	0
Mm-hmm.	0
They were the Canadians, right?	0
Canadians, yeah, yeah, yeah.	0
That's right.	0
So, it - it's actually probably good for us to know the difference between the real "eh"	1
and the one that's just like " uh " or transcribed "aaa"  cuz in - like in Switchboard, you would see	1
Exactly.	0
e- all of these forms, but they all were like "uh".	0
You mean just the single letter "a"  as in the particle?	0
The transcription or -	0
No, no, I mean like the - the "[MASK]", or - the "[MASK]", "[MASK]",	0
Article.	0
"[MASK]".	0
Oh.	0
uh, like "eeh".	0
All the "[MASK]"'s I've seen have been like that. They've been like "eh"  like that have bee- has been transcribed to "[MASK]".	0
Mm-hmm, that's right.	0
And sometimes it's stronger, like "eeh"  which is like closer to "E_H". But.	0
Mmm.	0
Right.	0
Yeah.	0
I'm just - these poor transcribers, they're gonna  hate  this meeting.	0
I know.  We  should go off-line.	0
Well,  we're not doing - We're not doing  length.	0
Quick Thilo, do a - do a filled pause for us.	0
Yeah, that's right.	0
Ooo  no.	0
But you're a native  German  speaker so it's not a -	0
Yeah.	0
not a issue for - It's only -	0
@@  Them Canadians.	0
Onl- yeah.  No, only if you don't have	0
lax vowels, I guess. Right. So it's - like Japanese and Spanish and -	0
Oh.	0
This makes sense. Yeah I - I think you've - uh-huh, yeah.	0
Uh- huh.	0
Oh I see. I didn't get that, O_K.	0
That makes sense.	0
Yeah, and so, you know, I mean, th- th- I have - there are some, um, Americans who - who are using this "eh" too, and I haven't listened to it systematically, maybe with some of them, uh, they'd end up being "uh's" but, uh, I- my spot-checking has made me think that we do have "eh" in	0
also, um, American e- e- data represented here. But	0
any case, that's the - this is reduced down from really quite a long- a much longer list, and this is	0
Yeah this is great. This is really really helpful.	0
Mm-hmm.	0
Yeah, it's good, yeah.	0
functionally pretty, you know, also -  It was fascinating, I was listening to some of these, uh, I guess two nights ago, and it's just hilarious to liste- to - to do a search for the "mm- hmm's ".	0
And you get "mm-hmm"  and diff- everybody's doing it.	0
And just listen to  them?   Yeah.	0
Just - I wanted to say - I w- think it would be fun to make a montage of it because  there's a  "Mm-hmm. Mm-hmm. Mm-hmm."	0
Performance art, just extract them all.	0
Right.	0
It's really - it's really fun to listen to.	0
Morgan  can make a  song  out of it.	0
All these different vocal tracts, you know, but it's - it's the same item. It's very interesting. O_K.	0
Uh, then the acronyms y- and the ones in parentheses are ones which the transcriber wasn't sure of, and I haven't been able to listen to to - to clarify, but you can see that	0
Oh I see.	0
the parenthesis convention makes it very easy to find  them   cuz it's the only place where - where they're used.	0
o-	0
How about question mark?	0
The question marks, yeah. What are those?	0
Question mark is punctuation. So it - they said that  @@  -	0
Oh.	0
Mm-hmm.	0
um, "[MASK]?"	0
So they - so it's "[MASK]?"	0
Ah.	0
Exactly.  Exactly.	0
Yeah, so the only - Well, and I  do  have a  stress  marker here. Sometimes the contrastive stress is showing up, and, um -	0
I'm sorry, I - I got lost here. What- w- what's the difference between the parenthesized acronym and the non-parenthesized?	0
The parenthesized is something that the transcriber  thought  was [MASK], but wasn't entirely sure.	0
So I'd need to go back or  someone  needs to go back, and say, you know, yes or no, and then get rid of the parentheses. But the parentheses are used only in that context in the transcripts, of	0
Ah.	0
Right.	0
of noti- noticing that there's something uncertain.	0
Yeah, P_make is - That's a good one. That's correct.	0
Yeah I mean cuz they - they have no idea, right. If you hear [MASK], I mean, they do pretty well but it's -	0
Yeah.	0
Mm-hmm.	0
I -  I  don't recognize a  lot  of these. I -	0
you know how are - how are they gonna know?	0
I know! I - I was  saying   that  I think a  lot  of them are the Networks meeting.	0
Yeah.	0
I think that's  true.  Yeah, absolutely. N_S_A, a lot of these are - are coming from them. I listened to some of that.	0
Maybe.	0
Yeah.	0
I see a few.	0
Although I see - I see plenty of uh	0
Yeah, we don't have that many acronyms comparatively in this meeting. It's not so bad.	0
Yeah.	0
Yeah. I agree.	0
Right.	0
And Robustness has a fair amount, but the N_S_A group is just very very many.	0
Yeah.	0
Mmm.	0
The recognizer, it is funny. Kept getting P_T_A for P_D_A.	0
That's not bad.	0
This is close, right, and the P_T_A was in these, uh, topics about children, so, anyway.	0
Yeah.	0
Yeah, that's pretty close.	0
Yeah.	0
That's interesting.	0
Is the P_- P_T_A working?	1
Right and sometimes, I mean, you see a couple of these that are actually "O_K's"	0
so it's - it's - may be that they got to the point where - I mean it was low enough understandable - understandability that they weren't entirely sure the person said "O_K."	0
You know, so it isn't really necessarily a	0
an undecipherable acronym, but just n- needs to be double checked. Now we get to the comments. This -	0
There's a lot of "O_K's".	0
The number to the left is the number of incidences? Uh-huh.	0
Count. Yep.	0
Number of times out of the entire database, w- except for that last thirty minutes I haven't checked yet.	0
So C_T_S is really big here, yeah.	0
Yeah, I wonder what it is.	0
Yeah.	0
So what is the difference between "papers rustling" and "rustling papers"?	0
I_P, I know what I_P is.	0
I'd have to listen. I - I- I agree. I w- I'd like to standardize these down farther but, um,	0
uh,	0
uh, to me that sounds equivalent.	0
Yeah.	0
But, I - I'm a little hesitant to - to collapse across categories unless I actually listen to  them.	0
Seems so.	0
O_K.	0
Oh I'm sure we've said [MASK] more than five times.	0
Well, then,  at  least now. Yeah.  Six.	0
Now it's at least six times, yeah.	0
S- s- six now, yeah.	0
O_K well -	0
I'm wai-	0
Wh- the self-referential aspect of these - these p-	0
Yes, it's very bad.	0
Yeah.	0
Well this is  exactly  how people will prove that these meetings  do  differ because we're recording, right?	0
Yes.	0
Y- no- normally you don't go around saying, "Now you've said it six times. Now you've said-"	0
Yeah  that's right.	0
But did you notice that there were seven hundred and eighty five instances of "O_K"? And that's just without the - without	0
Yep.	0
No, I didn't. Yeah.	0
Seven hundred eighty-five instances.	0
Yeah.	0
punc- punctuation. Extra forty one if it's questioned.	0
And that's an underestimate cuz they're	0
Where's that?	0
So th-	0
Yep.	0
On the page two of acronyms.	0
Yeah.	0
Is this  after  - like did you do some uh replacements for all the different form of "O_K" to this? O_K.	0
Seven hundred eighty.	0
Yeah. Of "O_K", yes. Mm-hmm. So that's the single existing convention for "O_K".	0
Wait a minute, w- s-	0
So now we're up to seven hundred and eighty  eight.	0
Yeah that's -	0
Although, what's - there's one with a  slash  after it.	0
Yeah. That's - that's - I  looked  for that one. I actually explicitly looked for that one, and I think that, um,	0
That's  kind of disturbing.	0
Yeah, we'll have to look at it you know.	0
Yeah.	0
Anyway. Mm-hmm.	0
I - I'm not exactly sure about that.	0
Was that somewhere where they were gonna say "new speaker" or something?	0
No, I looked for that, but that doesn't actually exist. And it may be, I don't - I can't explain that.	0
That's alright. I'm just pointing that out. There's -	0
I- i- it's the only -	0
it's the only pattern that  has  a slash after it, and I think it's - it's an epiphenomenon.	0
Well there's  not   @@ .	1
So I'll just - I was just looking at the bottom of page three there, is that "to be" or "not to be".	0
Yeah.  Oh that's cute. That's funny.	0
There's no tilde in front of it, so.	0
Yeah.	0
O_K.	0
O_K anyways, sorry.	0
There is th- one -	0
"Try to stay on topic, Adam."	0
Y- well, no, that's r-	0
that's legitimate. So now, uh, comments, you can see they're listed again, same deal, with exhaustive listing of everything found in everything except for these final th-	0
O_K so, um, on some of these QUALs,	0
thirty minutes.	0
Yeah.	0
are they really [MASK], or are they glosses? So like there'	0
"T_C_L".  Where  do you see that?	0
Uh	0
Oh, oh. The reason is because w- it was said "tickle".	0
What's a [MASK]?	0
Oh I see, I see. So it's  not  gloss. O_K, I see.	0
Hmm.	0
Yep.	0
It wasn't  said  "T_C_L". Of  course.	0
Sh- shouldn't it be [MASK] or something? Like - it's not -	0
On the - in the actual script - in the actual  transcript,  I s- I -	0
So this - this happens in the very first one.	0
I actually wrote it as "tickle".	0
Mm-hmm.	0
O_K.	0
Because we - they didn't say "T_C_L", they said "tickle".	0
Yeah.	0
Right.	0
And then,  following  that is "[MASK] T_C_L".	0
Oh I see. O_K.	0
I f- I forget,  what's  [MASK]?	1
[MASK]- qualifier.	1
It's just comment about what they said.	0
Comment. Comment or contextual comment.	1
Yeah. It's not something you wanna replace  with but -	0
So they didn't mean "tickle" as in	0
Yeah.	0
Elmo, they meant "tickle" as in -	0
Tickle?	0
Yeah.	0
Huh.	0
Right.	0
But at  some  point - I mean, we probably shoul-	0
We'll probably add it to the language model.	0
But we should add it to the  dictionar-	0
No, to the  pronunciation  model.	0
Yeah.	0
What  did I  say?	0
Language, uh -	0
To the language model - model.	0
Well  both.  We can go on lan- lan- add it to both dictionary and  language  model.	1
Oh lan- Oh O_K- we-  O_K - it's in the language model,	0
Add  what,  Liz?	0
Yeah.	0
w-  yeah,  but it- so it's the  pronunciation  model that has to have a pronunciation of	0
" tickle".	0
Well "tickle" was pronounced "tickle".	0
Right?	0
It's pronounced the same - it's pronounced the same as the  verb.  So I think it's the  language  model that makes it  different.	0
What are you saying?	0
"tickle" is pronounced "tickle"?	0
I'm sorry!	0
Oh,  sorry.  What I  meant  is that there should be a pronunciation	0
"tickle" for T_C_L as a word. And that  word  in the - in, you know, it  stays  in the language model wherever it was.	0
Oh I see.	0
Yeah.	0
Mm- hmm.	0
Right. Right.	0
Yeah you never would put "tickle" in the language model in  that  form, yeah.	0
Right.	0
@@	0
Right.	0
Right. There's actually a bunch of cases like this with people's names and -	0
So how w- there'd be a problem for doing the language modeling then with our transcripts the way they are.	0
Yes. Yeah.	0
Yeah so th- th- there- there's a few cases like that where the	0
um,	0
the word needs to be spelled out in - in a	0
consistent way as it would appear in the language, but there's not very many of these. Tcl's one of them.	0
And - and you'll ha- you'll  have  to do it  sychronously.	0
Um, y- yeah.	0
Right, so y- so, whoever's creating the new	1
It's just disturbing.	0
models, will have to also go through the transcripts and  change  them  synchronously.	1
Right.	0
Right. We have this - there is this	1
Hmm.	0
thing I was gonna talk to you about at some point about, you know, what do we do with the dictionary	0
as we're up- updating the dictionary, these changes have to be consistent with what's in the - Like spelling people's names and so forth.	1
If we make a spelling correction to their	0
name, like someone had Deborah Tannen's name misspelled, and since we know who that is, you know, we could correct it, but -	0
You can correct it.  Yeah.	0
but we need to make sure we have	0
the misspel- If it  doesn't  get corrected we have to have a pronunciation as a mispelled word in the dictionary. Things like that.	0
Mm-hmm.	0
These are so funny to read.	0
Well, of course now the - the Tannen corre- the spelling c- change.  Uh,  that's  what gets - I - I picked  those  up in the  frequency  check.	0
So.	0
Right. Right. So if there's things that get corrected before we get them, it's - it's not an issue, but if there's things that	1
Mm-hmm.	0
um, we change later, then we always have to keep	0
our - the dictionary up to date. And then, yeah, in the case of "tickle" I guess we would just have a,	1
you know, word "T_C_L" which -	0
Mm-hmm.	0
You add it to the dictionary.	0
which  normally  would be an acronym,	0
you know, "T_C_L"	0
Right.	0
but just has another pronunciation.	0
Yep.	0
" ICSI " is - is one of those that sometimes people pronounce and sometimes they say "I_C_S_I." So,	0
Mm-hmm.	0
Oh yeah.	0
those that are l- are listed in the acronyms, I actually  know  they were  said  as letters. The  others,  um,	0
e- those really  do  need to be listened to cuz I haven't been able to  go  to all the IC- ICSI things, and -	0
Right, exactly.	0
and  until  they've been  listened  to they stay as "I_C_S_I".	0
Mm-hmm.	0
Right.	0
Don and I were just noticing,  love  this one over on page three, "vocal - vocal gesture mimicking sound of screwing something into head to hold mike in place."	0
It's  this,  "rrre-rrre-rrre".	0
That's  great.	0
It was  me.	0
It  was!  In fact, it  was!	0
Yeah!	0
A  lot  of these are me the - the "beep is said with a high pit- high pitch and lengthening."	0
He - he s- he said - he said get -	0
To head .	0
Yeah, that's it.	0
That was the - I was imitating uh, beeping out -	0
Beep.	0
Perfect. Yeah that's it. That's it.	0
Oh there  is  something spelled out "B_E_E_E_E_E_E_P"	0
Yeah.	0
Um -	0
Yeah, that's - that's been changed.	0
Yeah.	0
in the old -	0
Thank  you.	0
Because he was saying, "How many E_'s do I have to  allow  for?"	0
What I meant was "beep".	0
You need a lot of -	0
You need a lot of qualification Adam.	0
That's been changed. So, exactly, that's where the lengthening comment c- came in.	0
I guess so. Anyway.	0
Right, thanks, yeah.	0
s- chan- brought it down.	0
Subtext.	0
So they're vocalization,	0
Right.	0
And those of course get - get picked up in the frequency check because you see "beep"  and you know - I mean it gets kicked out in the spelling, and it also gets kicked out in the, uh, freq- frequency listing.	0
glosses.	0
Right.	0
Right.	0
Right.	0
I have the - there're various things like "breathe" versus "breath" versus "inhale" and, hhh,	1
you know,  I  don't know. I - I think they don't have any  implications  for anything  else  so it's like I'm tempted to  leave  them for now an- and -	0
It's easy enough to  find  them when they're in curly brackets. We can always get an exhaustive listing of these things and find  them   and change  them.	0
Yeah.	0
"Sings finale-type song" that's - that's good.	0
Yeah.	0
Yeah, that was in the first meeting.	0
Um,	0
Yeah, but I don't actually remember what it  was.  But that was -  Eric  did that. Yeah.	0
Yeah.	0
So on -	0
Tah-dah!  I don't know. Something like  that  maybe, yeah.	0
I think maybe something like that.	0
Well, that'd qualify.	0
On the glosses for numbers,	1
Yeah.	0
it seems like there are lots of different ways it's being done. There's a -	1
O_K. Interesting question.	0
Yes. O_K, now first of all -	0
Ooo-ooo! Very important. Uh Chuck - Chuck led to a refinement here which is to add "NUMS" if these are parts of the read numbers. Now you already know i-	0
"Ooo-ooo."	0
that I had, uh, in places where they  hadn't  transcribed numbers, I put "numbers" in  place  of any kind of numbers, but there are places where they,	0
um, it - th- this convention came  later  an- and at the very first digits task in  some  transcripts they actually transcribed numbers.	0
And, um,	0
d-	0
Chuck pointed out that this is  read  speech, and it's nice to have the option of	0
ignoring it for certain other prob- uh p- uh, things. And that's why there's this other	0
tag here which occurs a hundred and five - or three hundred and five times right now which is just -	0
well n- n- "NUMS" by itself which means this is part of the numbers task. I may change it to "digits". I mean, i- with the sed command you can really just change it however you  want	1
"NUMS", yeah.	1
because it's systematically encoded, you know? Have to think about what's the best for - for the overall  purposes,  but in any case,	0
Yep.	0
um, "numbers" and "NUMS" are a part of this  digits  task thing.	0
Um, now th- Then I have these numbers that have quotation marks around  them.	0
Um, I didn't want to put  them   in as  gloss  comments because then you get the  substitution.  And  actually,	0
th- um,  the reason I b- did it this way was because I initially started out with the other	0
version, you have the numbers and you have the full form and the parentheses,   however  sometimes people stumble over	0
these  numbers  they're saying. So you say, "Seve- seventy eight point two", or whatever.	0
And there's no way of  capturing  that if you're putting the  numbers  off to the side. You can't have the seven and -	0
So what's to the left of these?	0
The left is i- so example the very first one,  it would be, spelled out in words,	0
Mm-hmm.	0
O_K, that's what I was asking.	0
"point five".	0
Right.	0
Only it's spelled out in words. So i- this is also spelled out in - in words. "Point five."	0
Point F_I_V_E, yeah.	0
Good.	0
And then, in here, "NUMS", so it's not going to be mistaken as a gloss.	0
It comes out as "NUMS quote dot five".	0
O_K now, the other example is, in the  glosses  right there,	0
Thank  you.	0
"gloss one one one dash one three zero". What - what's to the left of that?	0
Well now -	0
Right.	0
In that case it's people saying things like "one one one dash so-and-so" or they're saying	0
uh "two - I mean zero" whatever. And in that case, it's part of the numbers task, and it's not gonna be included in the read digits anyway, so - I m- in the uh -	0
O_K.	0
So there will be a "NUMS" tag on those lines?	0
There  is.  Yeah. I've added that all now too.	0
Yeah.	0
Good.	0
There's a "numbers" tag - I'm sorry I'm - I didn't follow that last thing.	0
Wait.	0
So, so gloss - in the same line that would have "gloss quote one one one dash one thirty", you'd have a gloss at the end of the line saying,	0
Right.	0
uh, "curly bracket NUMS curly bracket".	0
So if you - if you did a,	0
uh, a [MASK] and you get rid of anything that was read.	0
Oh, so you could do "grep minus V_ nums". So that's the - yeah. So there  wouldn't  be something like	0
O_K.	0
i- if somebody said something like, "Boy, I'm really tired, O_K." and then started reading that would be on a separate line?	0
Yes.	0
O_K great. Cuz I was  doing  the "grep minus V_" quick and dirty and	0
looked  like that was working O_K, but -	0
Mm-hmm. Good.	0
Great.	0
Yep.	0
Now why do we - what's the reason for having like the point five have the "NUMS" on it? Is that just like when they're talking about their data or something? Or -	1
This is more because -	0
Yeah.  Oh these are all these, the "NUMS point", this all where they're saying "point" something or other.	1
These are all like	0
inside the	0
spontaneous -	0
And the other thing too is for readability of the transcript. I mean if you're trying to follow this while you're reading it	1
it's really hard to read, you know - eh, "so in the data column five has",	0
you know, "one point five compared to seventy nine point six", it's like when you see the words it's really hard to follow the argument.	0
And this is just really a - a way of someone who would handle th- the data in a more discourse-y way	1
to be able to follow what's being said. So this is where Chuck's, um, overall h- architecture comes in, where	1
Oh O_K.	0
Label it.	0
I see.	0
we're gonna have a master file of the channelized data. Um, there will be scripts that are written	1
to convert it into these t- these main two uses and th- some scripts will take it down th-	1
e- into a f- a for- ta- take it to a format that's usable for the  recognizer  an- uh, other scripts will take it to a form that's usable for the -	1
for linguistics an- and  discourse  analysis. And, um, the	1
implication that - that  I  have is that th- the master copy will stay unchanged. These will just be things that are generated, and	1
Right	0
O_K.	0
e- by using scripts.	0
Master copies of superset.	0
When things  change  then the - the script will cham- change but the - but there won't be stored copies of - in different versions of things.	0
Good.	0
So, I guess I'd have  one  request here which is just, um, maybe to make it more robust, th-	0
that the tag, whatever you would choose for this type of "NUMS"  where it's inside the spontaneous speech, is different than the tag that you use for the read speech.	0
Right.	0
Right. That would argue for changing the other ones to be " digits " or something.	0
Um, that way w- if we make a mistake parsing, or something, we don't see the "point five", or - or it's not there, then we	0
Mm-hmm.	0
a- Just - an- And actually for things like	0
"seven eighths", or people do fractions too I guess, you - maybe you want one overall tag for sort of	0
that would be similar to that, or -	0
Except -	0
As long as they're sep- as they're different strings that we - that'll make our p- sort of	0
Well -	0
processing more robust. Cuz we really  will  get rid of everything that	0
has the "NUMS" string in it.	0
I suppose what you  could  do is just make sure that you get rid of everything that has "curly brace NUMS curly brace".	0
Well -	0
Ex- exactly.	0
Exactly.	0
I mean that would be the -	0
That was - that was my motivation.	0
Yeah.	0
And i- these can be  changed,  like I  said.  You know, I mean, as I  said  I was  considering  changing it to " digits ".	0
And, it just - i- you know, it's just a matter of deciding on  whatever  it is, and being sure the scripts  know.	0
Right.	0
It would probably be safer, if you're willing, to have a separate tag just because	0
um, then we know for sure. And we can also do counts on them without having to do the processing. But you're right, we  could  do it this way, it -	0
it  should  work. Um,	0
Yeah, and it makes it - I guess the thing about -	0
but it- it's probably not hard for a person to tell the difference because one's in the context of a -	0
Yeah.	0
you know, a transcribed word string, and -	0
Right.	0
The  other  thing is you can get  really   so   minute  with these things and  increase  the  size  of the files and the re- and  decrease  the readability to  such  an extent by	0
So -	0
simply something like " percent ". Now I - I could have adopted a similar convention for " percent ", but somehow	0
percent  is not so hard, you know? i- It's just	0
Hmm.	0
when you have these  points  and you're trying to figure out where the decimal places are -  And we could always add it later. Percent's easy to detect.  Point  however is - is	0
uh a word that has a couple different  meanings.  And you'll find  both  of those in  one  of these meetings,	0
where he's saying "well the first point I wanna make is so-and-so" and he goes through four  points,  and  also  has all these decimals.	0
So  Liz,  what does the  recognizer  do,	0
So.	0
uh,	0
Hmm.	0
what does the [MASK]  output  for things like that? "seven point five". Does it output the word -	0
"Seven point five".	0
Right, the  word  "seven"? The  number  "seven"?	0
Well, the  numbers?	0
The  word.	0
The word "seven", O_K.	0
Yeah.	0
Yeah.	0
So I'd - so "I'd like - I'd like to talk about point five".	0
And - and actually, you know the language -	0
it's the  same   point,  actually, the - the p- you know, the word "to" and the word	0
Yeah.	0
y- th- "going to" and "to go to" those are two different " to's " and so there's no  distinction  there.	0
Mm-hmm.	0
It's just - just the word " point "	0
has - Yeah, every word has only one,	0
yeah e- one  version  even if -	0
even if it's -	0
A- actually even like the word "read"  and "read" . Those are two different words. They're  spelled  the same way, right? And they're still gonna be transcribed as R_E_A_D.	0
Mm-hmm.	0
Right.	0
Mm-hmm.	0
So, yeah, I - I  like  the idea of having this in there, I just - I was a little bit worried that, um,	0
the tag for removing the  read  speech - because i- What if we have like	0
"read letters" or, I don't know, like "read something" like "read" yeah, basically.	0
We might wanna - just a separate tag that says it's  read.	0
Mm-hmm.	0
But other than that I- it sounds great.	0
Yeah.	0
O_K?	0
Are we done?	0
Well I wanted to say also regarding the channelized data, that, um, Thilo requested, um, that	1
Oh, I guess we're  not  done.	0
Yeah.	0
we ge- get some segments done by hand to e- e- s- reduce the size of the time bins wh- like was Chuc- Chuck was mentioning earlier that, um,	1
that, um, if you - if you said, "Oh"	0
and it was in part of a really long, s- complex, overlapping segment, that the same start and end times would be held for that one as for the longer utterances, and -	0
Well -	0
We did that for  one  meeting, right, so you have  that  data don't you?	1
Yeah, that's the training data.	1
And he requested that there be, uh, similar, uh, samples done for five minute stretches c- involving a variety of speakers and overlapping secti- sections.	1
He gave me - he did the - very nice, he - he did some shopping through the data and found segments that would be useful.	0
Yeah.	0
And at this point, all four of the ones that he specified have been done.  In addition  the	0
I've - I have the transcribers  expanding  the amount that they're doing actually. So right now, um,	0
Oh great.	0
I know that as of  today  we got an extra fifteen  minutes  of that type, and I'm having them expand the realm on either side of these places where they've already started.	0
Oh great.	0
O_K.	0
But if - if - you know, and I - and he's gonna give me some more sections that - that he thinks would be useful for this purpose.	0
Yeah.	0
Yeah.	0
Because it's true, I mean, if we could do the -	1
the more fine grained tuning of this, uh, using an  algorithm,  that would be  so  much more efficient. And, um.	1
So this is gonna be  useful to expand this.	0
So I - I thought we - we sh- we sh- perhaps we should try to - to  start  with those  channelized  versions just to - just to  try  it. Give it -	1
Give one tr- transcriber the - the  channelized  version of - of my speech-nonspeech detection and	1
look if - if that's helpful for them, or just let them try if - if that's better or	1
If they - if they can -	0
You mean to start from scratch f- in a brand new transcript? That'd be excellent. Yeah, that'd be really great.	0
Yeah. Yeah.	0
Yeah.	0
As it stands we're still in the phase of sort of, um,	0
cleaning up the existing data getting things, uh, in i- m- more tight- tightly time - uh, aligned. I also wanna tell - um, I also wanted to r-	0
raise the issue that - O_K so, there's this idea we're gonna have this master copy of the transcript,	0
it's gonna be modified by scripts t- into these two different functions. And actually the master -	0
Two or  more.  Two or more different functions.	0
Two - two or more.	0
And that the master is gonna be the channelized version.	0
Right.	0
So right now we've taken this i- initial one, it was a single channel basically the way it was input. And now, uh,	0
thanks to the advances made in the interface, we can from now on use the channelized part,	0
and, um, any changes that are made get made in the channelized version kind of thing. But I wanted to get all the finished - all the checks -	0
Yeah, so that has implications for  your  script.	0
Yeah. So, uh, have those - e- e- the vis- the ten hours that have been transcribed already, have those been channelized?	1
Yes, they have.	1
And I know - I've seen  @@  - I've seen they've been channelized, but	0
All ten hours?	0
Except for the missing thirty minutes.	0
Great.	0
have they uh - have they been - has the time - have the time markings been adjusted, uh, p- on a per channel -	0
Uh, for - for a total of like twenty m-	0
f- for a total of -	0
Let's see, four times -	0
total of about an -  thirty minutes.	0
That's - that's been the case. And plus the training, whatever you have.	0
So,	0
I guess, I mean, I don't know if we should talk about this now, or not, but I-	0
Well it's just we're  missing tea. So.	1
Yeah, I know. No, but I mean my question is like should I wait	0
until  all  of those are processed, and channelized, like the time markings are adjusted before I do all the processing, and we start like branching off	0
into the - into the - our layer of uh	0
Well, you know the problem - the problem is that some - some of the adjustments that they're making  are  to bring - are to  combine	1
transcripts.	0
bins that were - time bins which were previously  separate.  And the  reason  they do that is sometimes there's a word that's cut off.	1
Right.	0
And so, i-	1
i- i- it's true that it's likely to be adjusted in the way that the words are more complete.	1
And,	0
O_K. No I know - I know that adjusting those things are gonna - is gonna make it better.	1
so I - it's gonna be a more reliable thing and I'm not sure -	0
Yeah.	0
I mean I'm sure about that, but do you have like a time frame when you can expect like  all  of it to be done, or when you expect them to finish it, or -	1
Well partly it depends on how - um, how e-	0
effective it will be to apply an  algorithm  because	0
Yeah.	0
i- this takes  time,  you know, it takes a couple hours t- to do, uh, ten minutes.	1
Yeah.	0
Yeah, I don't doubt it. Um,	0
so.	0
So right  now  the - what  you're  doing is you're taking the - uh, the o- original version and you're sort of channelizing yourself, right?	0
Yeah. I'm doing it myself. I mean i- if the time markings aren't different across channels, like the channelized version really doesn't	0
have any more information.	0
Mm-hmm.	0
So, I was just - I mean, originally I had done before like the channelized versions were coming out. Um,	0
Right.	0
Right.	0
and so it's a question of like what -	0
So I - I th- I think probably the way it'll go is that, you know, when we	1
make this first general version and then start working on the script, that script	0
Mm-hmm.	0
@@  that will be ma- you know primarily come from what  you've  done, um, we'll need to work on a channelized version of those originals.	1
Mm-hmm.	0
Mm-hmm.	0
And so it  should  be pretty much identical to what you  have  t- except for the one that they've already tightened the boundaries on.	0
Yep. Mm-hmm.	0
Right.	0
Um,	0
So	0
Yeah, I mean - yeah.	0
uh, and then probably what will  happen  is as the transcribers finish tightening more and  more,  you know, that	1
original  version will get  updated  and then we'll rerun the script and produce better	1
O_K.	0
uh versions. But the - I guess the ef- the effect for  you  guys, because you're pulling out	1
the little wave forms into separate ones, that would mean these boundaries are constantly changing you'd have to constantly re- rerun that, so, maybe -	1
I know .	0
Right.	0
But that - Mm-hmm.	0
But that - that's not hard.	0
No.	0
I- I think the harder part is making sure that the transc- the transcription -	0
O_K.	0
So if you b-  merge  two things, then you  know  that it's the sum of the transcripts, but if you  split	1
inside  something, you don't where the word - which  words  moved.	1
Mm-hmm.	0
Mm-hmm.	0
And that's wh- that's where it becomes a little bit -	0
uh, having to rerun the processing. The cutting of the waveforms is pretty trivial.	1
Mm-hmm.	0
Yeah. I mean as long as it can all be done automatically,	0
I mean, then that's not a concern. You know, if I just have to run three scripts to extract it all and let it run on my computer	0
Right.	0
Mm-hmm.	0
Yeah.	0
Uh-huh.	0
for an hour and a half, or however long it takes to parse and	0
create all the reference file, that's not a problem.	0
Mm-hmm.	0
Um,	0
so yeah. As long as we're at that point. And I know exactly like what the steps will work - what's going on, in the editing process, so.	0
Yeah.	0
O_K.	0
So that's - I- I mean I could - there were other checks that I did, but it's - I think that we've - unless you think there's anything else, I think that I've covered it.	0
Yeah.	0
I can't think of any of the - other ones.	0
O_K.	0
Great.	0
O_K.	0
Oop!	0
Man!	1
