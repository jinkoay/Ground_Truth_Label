We can  say  the word "zero" all we want, but just -	0
square brackets, coffee sipping, square brackets.	0
That's  not  allowed, I think.    Curly  brackets.  Oops.	0
Is that voiced or unvoiced?	0
Curly  brackets.  Well ,  correction for transcribers. Yeah.	0
Do we  use  square brackets for anything?	0
Not ri- not right now. I mean No.	0
There's gonna be some zeros from this morning's meeting because I noticed that	0
Barry, I think maybe  you  turned your mike off before the digits were Oh, was it during digits? Oh, so it doesn't matter.	0
So it's not it's not that bad if it's at the end, but it's in the beginning, it's  bad.	0
It's  still  not a good idea.	0
Yeah, you wanna you wanna keep  them   on so you get  good noise -	0
Uh, I probably just should have left it on. Yeah I did have to run, but -	0
Is there any way to change that in the  software?	0
Change  what  in the software?	0
Where like you just don't like if you if it starts catching zeros, like in the driver or something -	0
in the card, or somewhere in the hardware -	0
Where if you start seeing zeros on w- across one channel, you just add some  random,	0
noise floor like a small noise floor.	0
I mean  certainly  we could  do  that, but I don't think that's a good idea. We can do that in post-processing if if the application needs it.	0
Well, I u- I actually don't know what the  default   is anymore as to how we're using the the front-end stuff but -	0
for for when we use the  ICSI  front-end,	0
there is an there is an o- an option in in RASTA, which,  um,	0
in- when I  first  put it in,	0
uh, back in the days when I actually  wrote  things, uh,	0
I   did  actually put in a random bit or so that was  in it , but	0
then I realized that putting in a random bit was equivalent to adding uh adding flat spectrum,	0
and it was a lot faster to just add a constant to the  to the spectrum. So then I just started doing that instead of calling "rand"  or something, so.	0
So it d- it  does  that.	0
Gee! Here we all are!	0
Uh, so the  only  agenda items were Jane was Jane wanted to talk about some of the I_B_M	1
transcription process. I sort of	1
condensed the three things you said into that.	0
And then just I only have like, this afternoon and maybe tomorrow morning to get anything done before I go to Japan for ten days.	0
So if there's anything that n- absolutely, desperately needs to be done, you should let me know now.	0
Uh, and you just sent off a	1
I  hope  they  accept  it. I mean, I -	1
both  actu-  as as a submission and  you know, as a paper.	0
Yeah, I guess you  first  you have to do the  first  one, and then Yeah.	0
Well yeah, you sent it in   late.  Yeah.	0
We actually exceeded the delayed deadline by o- another day, so.	1
Oh they they had some extension that they announced or something?	0
Well yeah. Liz had sent them a note saying "could we please  have another"   I don't know, "three days" or something, and	0
And then she said "Did I say three? I meant four."	0
Oh, that was the other thing uh,	0
uh, Dave Gelbart sent me email, I think he sent it to you too,  that um,	1
section in si- in Eurospeech on new,	1
And it's not due until like May fifteenth.	1
Oh this  isn't  the Aurora one? It's another one?	0
No. It's a different one.	0
I got  this  mail from -	0
I s- forwarded it to Jane as I thought being the most relevant person.	0
So, I thought it was  highly  relevant have you did you look at the U_R_L?	0
Yeah. I think so too.	0
Um, I haven't gotten over to there yet, but what our discussion yesterday, I really I I wanna submit one.	0
I think  Christoph Draxler sent this, yeah.	0
And, you offered to to  join  me, if you want me to. Yeah.	0
I'll  help,  but obviously I can't,	0
I think  several people sent this, yeah.	0
But any any help you need I can certainly provide.	0
that's that's a great idea.	0
there there were some interesting results in this paper, though. For instance that Morgan uh, accounted for fifty-six percent of the Robustness meetings in terms of number of words.	1
In in terms of what?	0
That's just cuz he talks really fast.	0
is it partly, eh, c- correctly identified words?	0
No. Well, according to the  transcripts.	1
I think it's he's he's in all of them,	0
I mean, we didn't mention Morgan by name we just -	0
and he talks a lot.	0
Well we have  now,  but -	0
We we we something about -	0
Did you identify him as a  senior   member?	0
No, we as- identify him as the person dominating the conversation.	1
I mean I get these A_A_R_P things, but I'm not se-  really  senior  yet,  but -	0
but uh, other than that delightful result, what was the rest of the paper about?	0
Um, well it was about it had three sections uh three kinds of uh	1
You  sent  it to me but I haven't  seen  it yet.	0
Uh, the one was that the just the the amount of overlap um,	1
The   good, the bad, and the ugly.	0
s- in terms of in terms of number of words and also we computed something called a "spurt",	1
which is essentially a stretch of speech with uh, no pauses exceeding five hundred milliseconds.	1
Um, and we computed how many overlapped i-	1
spurts there were and how many overlapped  words  there were.	1
Um, for four different  corpora, the Meeting Recorder meetings, the Robustness meetings	1
and, found and sort of compared the numbers.	0
you know, as you might  expect  the Meeting Recorder  meetings had the  most  overlap  uh, but  next  were Switchboard and  CallHome,  which both had roughly the same,	1
and the   Robustness   meetings were had the  least,  so -	1
result  there  is that uh	0
two-party telephone conversations have  about the same amount of overlap,	0
sort of in gen- you know order of magnitude-wise as, uh as face-to-face meetings with multiple -	0
I have I had better start changing all my  slides!	0
Yeah.  Also, I in the Levinson, the pragmatics book,  in you know, uh, textbook,  there's I found this great quote where he says	1
you know, how people it talks about how uh how how people are so good at turn taking, and  so they're so good that	1
generally, u- the overlapped speech does not is less than five percent.  So,	1
this is  way  more than five percent.  Um.	0
Did he mean face like face-to-face? Or ?	0
Well, in  real  conversations, everyday conversations.	0
It's s- what these conversation analysts have been studying for years and years  there .	0
Well, of course, no, it  doesn't  necessarily go  against  what he  said,  cuz he said "generally  speaking ". In order to -	1
to go against  that  kind of a claim you'd have to  big  canvassing.	0
Well, he he made a claim Well -	0
Yeah, we we have pretty limited sample here.	0
Five percent of  time  or five percent of  what?	0
Yeah, I was gonna ask that  too.	0
Well it's  time.  So  but  still  but  still  u-	0
Exactly. It's i- it's not against his conclusion, it just says that it's a bi- bell curve, and that,	0
you have something that has a nice range, in your sampling.	0
Yeah. So there are slight There are differences in how you measure it, but  still  it's  You know, the difference between um -	0
between  that  number and what we have in  meetings,  which is more like,	0
you know, close to in meetings like these, uh you know, close to  twenty  percent.	0
But what was it like, say, in the  Robustness  meeting, for instance?	0
Robustness meeting? It was  about half of the r-	1
So,  in terms of number of words, it's like seventeen or eigh- eighteen percent for the  Meeting  Recorder meetings and  about  half  that for,	1
But I don't know if that's really a fair way of comparing between,	0
Then  then then you have to -	0
Yeah. I I I don't know. I mean that's just something -	0
Yeah, I just wonder if you have to normalize by the numbers of speakers or something.	1
Then Yeah, then normalize by by something like that, yeah.	0
Well, we didn't get to look at that, but  this  obvious thing to see if if there's a dependence on the number of uh participants.	1
Yeah, that's a good point. Yeah.	0
I bet there's a  weak  dependence. I'm sure it's it's not a real strong one.	1
Cuz not everybody  talks.  Yeah.	0
You have a lot of a lot of  two-party,	1
subsets  within the meeting. Well regardless it's an interesting result  regardless.	1
Right. And and and then and we also d- computed this both with and without backchannels, so you might think that backchannels have a special  status  because they're essentially just -	0
So, did we all said "uh-huh" and nodded at the same time, so.	0
But, even if you take out all the  backchannels  so basically you treat backchannels l- as  nonspeech,  as pauses,  you  still  have significant overlap. You know, it goes down from maybe -	1
For  Switchboard  it goes down from I don't know  f-	0
I don't know f- fourteen percent of the words to maybe	0
I don't know, eleven percent or something it's it's not a  dramatic  change, so it's -	0
Anyway, so it's uh -	0
That was that was one set of  results, and then the  second  one was just basically the -	1
the stuff we had in the in the H_L_T paper on how overlaps effect the  recognition performance.	1
And we rescored things um, a little bit more carefully. We also fixed the transcripts in in numerous ways.	1
Uh, but mostly we added one -	0
what if you  uh, basically score ignoring all -	0
So so the the conjecture from the H_L_T results was that	1
most of the added recognition error is from insertions  due to background speech.	1
So, we scored  all the recognition results,	0
uh, in such a way that	0
Oh by the way, who's on channel  four?  You're getting a lot of breath.	0
I j- was just wondering. Yeah.	0
uh, well Don's been working hard.  @@	0
O_K, so  so if you have the  foreground  speaker	0
speaking here, and then there's some  background  speech, may be  overlapping  it somehow,	0
um, and this is the time bin	0
then of course you're gonna get insertion errors here and here. Right?  So we  scored  everything, and I must say the NIST scoring tools are pretty nice for this,	1
where you just basically ignore everything outside of the,	1
uh, region that was deemed to be  foreground  speech.	1
And  where  that  was  we had to use the t- forced alignment,	0
uh, results from s- for so -	0
That's somewhat that's somewhat subject to error, but still we we -	0
Uh, Don did some ha- hand-checking	0
and and we think that based on that, we think that the results are you know, valid, although of course, some error is gonna be in there.	0
But basically what we found is after we take out these regions so we only score the regions that were certified as foreground speech,	1
the recognition error went down to almost	1
uh, the  level of the  non-overlapped   speech.	1
So that means that  even if you  do  have background speech, if you can somehow separate out or find  where  it  is,	0
uh, the recognizer does a good job,	0
even though there is this back-	0
Yeah, I guess that doesn't surprise me, because,	0
with the close-talking mikes, the the signal will be  so  much  stronger.	0
What what sort of normalization do you do?	1
Uh, well, we just -	0
we do u- you know, vit-	0
I mean in you recognizer, in the S_R_I recognizer.	0
Well, we do uh, V_T_L -	1
vocal tract length normalization, w- and we uh -	1
you know, we we uh,	1
make all the features have zero mean and unit variance.	1
Over over the entire c- over the entire  channel.  Over the but  you  know.	1
Um, now we didn't re-align the recognizer for this. We just took the old -	1
So this is actually a  sub-optimal  way of doing it, right? So we took the old recognition output and we just  scored  it differently.	0
So the recognizer didn't have the benefit of  knowing  where the foreground speech a- start-	1
Were you including the the  lapel   in this?	0
And did the did did the la- did the the problems with the  lapel  go away also? Or -	0
Um, it  Yeah.  It u- not per I mean, not  completely,  but yes, dramatically.	0
So we have to um -	0
I mean, you still -	0
Well I should bring the should bring the table with results. Maybe we can look at it   Monday .	0
I would  presume  that you  still  would have  somewhat  higher error with the lapel for insertions than Yeah.	0
Cuz again, looking forward to the non-close miked case, I think that we s- still -	0
I'm not looking forward to it.	0
i- it's the high signal-to-noise ratio	0
here that that helps you.	0
So so that was number that was the  second  set of -	0
uh, the  second  section. And  then,	1
the  third  thing was, we looked at,	1
uh, what we call "interrupts", although that's that may be  a  misnomer,  but basically  we looked at cases where -	1
Uh, so we we used the punctuation from the original transcripts	1
and we inferred the beginnings and ends of sentences.	1
Di- did you use upper-lower case also, or not?	0
U- upper lower case or no?  O_K.	0
No, we only used, you know, uh periods, uh, question marks and  exclamation.	0
And we know that there's th- that's not a very g-	0
I mean, we miss a  lot  of them, but but it's f- i- i-	0
Yeah. That's O_K but -	0
we looked at locations where,	0
if you have  overlapping  speech and someone  else  starts a sentence,	1
you know, where do these where do other people start their  turns not  turns  really, but you know,  sentences,   um -	1
So we  only  looked at cases where there was a  foreground  speaker  and then	0
at the to- at the so the the foreground speaker started into their sentence and then someone else started later.	0
Somewhere in between the start and the end? O_K.	0
Somewhere in between the start and the end of the foreground?	0
Yes.  Uh, so that such that there was overlap between the two sentences.	1
So, the the question was how can we what can we say about the places where the second or or actually,  several  second speakers,	1
um  start their  "interrupts", as we call them.	1
Three words from the end.	0
And we looked at this in terms of um -	0
So so we had  we had um u-	0
to for for the purposes of this analysis, we  tagged  the  word  sequences, and and we  time-aligned  them.	1
Um,  and we considered it interrupt if it occurred in the middle of a word, we basically -	0
you know, considered that to be a interrupt	0
as if it were at at the beginning of the word. So that,	1
if any part of the word was overlapped, it was considered an interrupted  word.	1
And then we looked at the the locatio- the,	0
you know, the  features  that the  tags  because we had  tagged  these word strings,   um, that that occurred  right  before these these uh,  interrupt  locations.	1
And the tags we looked at are	1
the  spurt  tag, which basically says -	1
End  of spurt. So -	1
there was a  pause  essentially here, because spurts are a defined as being you know, five hundred milliseconds or longer pauses,	1
and then we had things like discourse markers,	1
uh, filled pauses  So disfluen- the D_'s are for,	1
the interruption points of a disfluency, so, where you hesitate, or where you start the repair there.	0
Uh, what  else  do we had. Uh, repeated you know, repeated words is another  of that  kind of disfluencies and so forth.  So we had both the beginnings and ends of these -	0
uh so, the end of a filled pause	0
and the end of a discourse marker.	0
And we just eyeballed I mean	1
we didn't really hand-tag all of these things. We just  looked at the distribution of words, and so every  "so yeah", and "O_K", uh, and "uh-huh" were were the were deemed to be backchannels and  "wow" and "so" and  uh "right", uh were	1
um  Not "right". "Right" is a backchannel. But so, we sort of just based on the lexical -	1
identity of the words, we we tagged them as one of these things.	1
And of course the d- the interruption points we got from the original transcripts.	0
So, and then we looked at the disti- so we looked at the  distribution of these different kinds of tags,  overall  uh, and and and particularly at the interruption points.	0
And uh, we found that there  is  a marked  difference  so	0
that for instance  after  -	1
so at the end  after  a discourse marker or  after  backchannel or  after   filled  pause, you're  much  more likely to be interrupted  than  before.	1
O_K?  And also of course after  spurt  ends, which means basically in p- inside pauses.  So pauses are always an  opportunity   for -	1
So we have this little histogram which shows these distributions and,  um,	0
you  know, it's it's it's  not  No big surprises, but it is  sort of interesting from -	0
It's nice to actually  measure  it though.	0
I wonder about the cause and  effect  there.	1
In other words uh  if you  weren't  going to pause you you  will  because you're g- being  interrupted.	1
Right. There's no statement about cause and  effect.  This is just a statistical correlation, yeah.	1
Yeah, right. No, no, no. Right, I I see. Yeah.	0
But he yeah, he's he's right, y- I mean maybe	0
you weren't  intending  to pause at  all,  but  You were intending to stop for fifty-seven milliseconds,  but then  Chuck  came in and so you  paused for a  second	0
uh, and that was basically it. And and we so we wrote this and then,  we found we were at six pages, and then we started	0
cutting furiously and  threw out half of the  material again, and uh played with the LaTeX stuff and -	0
uh, and until it fi-	0
Made the font smaller and the  narrows  longer.	0
No, no. W- well, d- you couldn't really make  everything  smaller but we s- we put  Oh, I I -	0
Put  the abstract  end .	0
you know the the  gap  between the two columns is like ten millimeters, so I d-	0
shrunk it to  eight  millimeters and that helped some. And stuff like that.	0
Wasn't there wasn't there some result, Andreas I I  thought  maybe Liz presented this at some conference a while ago about  uh, backchannels uh,	1
and that they tend to happen when uh  the pitch drops. You know you get a falling pitch.	1
And so that's when people tend to backchannel. Uh- i- i- do you rem-	0
y- We didn't talk about, uh, prosodic, uh, properties at  all,  although that's I I take it that's something that uh Don will will look at now that we have the data and we have the alignment, so.	1
Yeah, we're gonna be looking at that.	0
This is purely based on	0
you know the words and -	0
I have a reference for that though.	0
So am I recalling correctly? About -	0
Well, I didn't know about  Liz's  finding on that,	0
but I know of another	0
I'd like to see that reference too.	0
It made me think about a cool little device that could be built	0
to handle those people that call you on the phone and just like to talk and talk and talk.	0
And you just have this little  detector  that listens for these  drops in pitch and gives them the  backchannel.	0
And so then you  hook that to the phone and go off and do the  do whatever you r- wanna do, while that thing keeps them busy.	0
There's actually uh there's this a former student of here from Berkeley, Nigel Nigel Ward.  Do you know him?	1
He did a system uh, in he he lives in  Japan  now, and he did this backchanneling, automatic backchanneling system. It's a very -	1
So,  exactly  what you describe, but for Japanese. And it's apparently for Japa- in Japanese it's really important that you backchannel.	1
It's really impolite if you don't, and -	0
Actually for a  lot  of these people I think you could just sort of backchannel continuously and it would  pretty much be fine.	0
It wouldn't matter? Yeah.  Random intervals.	0
Yeah.  That's w- That's what  I  do.	0
There was there was of course a Monty Python sketch with that.	0
Where the barber who was afraid of scissors was playing a a tape of clipping sounds, and saying "uh-huh", "yeah",  "how about them sports teams?"	0
So the paper's on-line and	1
y- I I think I uh -	0
I C_C'ed a message to Meeting Recorder with the U_R_L so you can	0
Printed it out, haven't read it yet.	0
Um, uh one more thing. So I I'm actually -	1
about to send Brian Kingsbury an email saying where he can find the -	1
the m- the material he wanted for the s- for the speech recognition experiment, so -	1
but I haven't sent it out yet because actually my  desktop  locked  up,  like I can't type anything.  Uh b- so if there's any	0
suggestions you have for that I was just gonna	0
Is it the same directory that you had suggested?	0
I made a directory. I called it um -	0
He still  has  his  Unix  account here, you know.	0
Yeah but but but he has to -	1
And he and he's -	0
I'd hafta add him to Meeting Recorder, I guess, but -	0
he prefe- he  said  he would prefer F_T_P	1
and also, um, the  other  person that wants it There is one person at S_R_I who wants to look at the  um,	1
you know, the uh the data we have so far,	1
and so I figured that F_T_P is the best  approach.	1
So what I did is I um -	1
I made a n- new directory	1
after  Chuck  said that would c- that was gonna be	0
Uh, so it's "F_T_P   pub  real" Exactly.	0
What is it again? C_R -	0
Or Yeah. Right? The same the same as the mailing list, and Yeah.	0
Yeah, the  No vowels. Yeah	0
Um,  and then under there -	1
Um actually Oh and this directory,  is not readable. It's only uh, accessible. So,  in other words, to access anything  under  there, you have to  be  told  what the  name  is.	1
So that's sort of a g-  quick and dirty way of doing  access  control. So -	0
uh, and the directory for this I call it I- "A_S_R zero point one" because it's sort of meant for recognition.	0
So anyone who hears this meeting now knows the -	0
And then then in there I have a file that lists all the other  files, so that someone can  get  that file and then know the  file  names and therefore download them. If you don't know the file names you can't -	1
I mean you can -	0
Is that a  dash  or a  dot  in there?	0
Anyway.  So all I all I was gonna do there was stick the the transcripts after we the way that we munged them for scoring, because that's what	1
he cares about, and -	0
and also and then the -	1
the  waveforms that Don segmented. I mean, just basically tar them all up f- I mean -	1
w- for each meeting I tar them all into one	0
tar file and G_zip them and stick them there.	0
put digits in my own  home  directory  home  F_T_P directory, but I'll probably move them there as well.	0
So we could point Mari to this also for her	0
Or  You n- Remember she was -	0
Oh she wanted that  also?	0
Well she was saying that it would be nice if we had  they  had a Or was she talking Yeah.  She was saying it would be nice if they had eh  the same set, so that when they did experiments they could compare.	0
Right, but they don't have a recognizer even.	0
But  yeah,  we can send I can C_C  Mari  on this so that she knows -	0
So, for the thing that We need to give Brian the beeps file,  so I was gonna probably put it -	1
We can put it in the same place. Just put in another directory.	0
Well, make ano- make another directory. You don't n- m- Yeah.	0
I'll make another directory. Yeah. Exactly. Yeah.	0
Um, so either we should regenerate the original  versions,   or um, we should just make a note of it.	0
O_K, because in  one  directory there's two  versions.	0
Yeah, that's the first meeting I cut both versions. Just to check which w- if there is a significant difference.	0
And so I but O_K so but for the  other  meetings it's the  downsampled  version that you have.	1
Oh that's th- important to know, O_K so	1
we should probably uh  give them the  non-downsampled  versions.	1
Alright, then I'll hold  off  on that and I'll wait for you um -	0
Probably by tomorrow I can -	0
I'll send you an email.	0
O_K. Yeah, definitely they should have the full bandwidth version, yeah.	0
Yeah, because I mean I- I think Liz decided to go ahead with the  downsampled versions cuz we can There was no s- like,  r-  significant difference.	0
Well, it takes it takes up less disk space, for one thing.	0
It  does  take up less disk space, and apparently it did even better  than the original than the original versions, which	0
Yeah, it was a small difference but yeah.	0
um  they probably w- want the originals.	1
O_K, good. Good that -	0
Well, it's a good thing that -	0
O_K , I think we're losing,	0
Don and Andreas at three-thirty, right?	0
that's why it was good to have Andreas, say these things but -	0
So, we should probably talk about the I_B_M transcription process stuff that -	1
So, um you know that Adam created um, a b- a script to generate the beep file?	1
something to send to I_B_M.    And, um,	0
you  you  should probably talk about that. But but you were gonna to use the  originally transcribed file because I tightened the time bins and that's also the one that they had  already   in trying to debug the first stage of this.	1
my understanding was that, um -	0
I haven't  I haven't listened to it yet, but it sounded very good and and I understand that you guys  were going to have a meeting today, before this meeting.	0
It was just to talk about how to generate it.	0
Um, just so that while I'm gone, you can regenerate it if you decide to do it a different way.	0
So uh, Chuck and Thilo should,	0
now more or less know how to generate the file and,	1
the other thing Chuck pointed out is that,	1
since this one is  hand-marked,	1
Right? So so when one person is speaking, there's breaks.	0
Whereas  Thilo's  won't have that.	0
Oh! O_K. Ah, interesting. Yeah. Yeah.	0
So what what we're probably gonna do is just write a script,	1
chunks are very close to each other on the same channel we'll just merge them.	1
Oh, sure. Yeah, sure. Makes sense.	0
So, uh, and that will get around the problem of,	0
you know "one word beep, one word beep, one word beep, one word beep".	0
And And it will be more more close close to to the version they will get afterwards after  @@ .	0
Yeah, in fact after our meeting uh, this morning Thilo came in and said that	1
there could be   other  differences between	1
the uh  already  transcribed  meeting with the beeps in it and one that has  just r- been run through  his  process. So tomorrow,	1
when we go to make the um  uh, chunked file  for I_B_M, we're going to actually  compare  the two. So he's gonna run his process  on   that   same  meeting,	1
and then we're gonna do the beep-ify on  both,  and listen to them and see if we notice any real differences.	1
O_K, now one thing that prevented us from apply- you  you  from applying Exactly. The training So that  is  the training meeting.	0
Yeah, it's the training meeting, but -	0
Yeah, w- and we know that. Wel- uh we just wanna if if there're any major differences between	0
I only used the first twenty minutes for training, so we can  use the  @@	0
doing it on the hand-	0
Oh, interesting. Ah! O_K. Interesting idea.	0
But it's the same speakers and the same channels  @@	0
So this  training  meeting, uh w-	0
uh  some data where we have uh very um,	0
you know, accurate  time marks? for -	0
I went back and hand-marked the  ba- the bins, I ment- I mentioned that last week.	0
But the but there's yeah, but there is this one issue with them in that there're  there are time boundaries in there that	0
occur in the middle of speech.	0
Like when we went t- to  um -	0
When I was  listening  to the  original   file  that Adam had, it's like you you hear a word then you hear a  beep   and then you hear the  continuation  of what is the same  sentence.	1
That's  on  the other channel.	0
That's because of  channel  overlap.	1
Well, and and so the th-	0
So there are these chunks that look like uh -	0
I mean that's not gonna be true of the foreground speaker. That'll only be if it's the background speaker.	0
Right. So you'll you'll have a  chunk  of, you know, channel  A_ which starts at zero and ends at ten,	0
and then the same channel starting at eleven, ending at fifteen,	0
and then again, starting at sixteen, ending at twenty. Right, so that's three chunks where  actually we w- can just make  one  chunk out of that	0
which is A_, zero, twenty.	0
That's what I just said, yeah.	0
Yeah. So I just wanted to make sure that it was clear.	0
So  if you were to use  these,  you have to be careful not to pull out these individual -	0
Yeah, I thought that was Yeah.	0
Oh!  I mean it -	0
Right, I mean w- I mean what I would I was  interested  in is having -	1
a se- having time marks for the beginnings and ends of speech	1
Well,  that's  definitely a problem.	0
Uh, because we could use that to fine tune our alignment	1
process  to make it more accurate.	1
uh, it I don't care that you know, there's actually abutting	0
segments that we have to join together. That's fine.  But what we  do  care about is that	0
the beginnings and  ends  um  are actually close to the speech	0
inside of that  uh -	0
Yeah, I think Jane tightened these up by hand.	0
O_K, so what is the sort of how tight are they?	0
Uh,  it  looks much better.	0
reasonably tight, but not excruciatingly tight. That would've taken more time.	1
No, no! I don- actually I I I it's f-	0
I just wanted to get it so tha- So that if you have like "yeah"	0
Let me make a note on yours.	0
in a swimming in a big bin, then it's -	0
That's  fine  because we don't want to -	0
th- that's perfectly fine. In fact it's good. You always want to have a little bit of pause or nonspeech around the speech, say for recognition purposes.	1
Uh, but just just u-	0
w- you know get an id- I just wanted to have an idea of the -	0
of how much extra you allowed  um -	0
so that I can interpret the  numbers  if I compared that with a forced  alignment  segmentation.	0
I can't answer that, but but my main goal was  um, in these areas where you have a three-way overlap  and one of the overlaps involves "yeah",	0
and it's swimming in this huge bin,  I wanted to get it so that it was clo- more closely localized.	0
But are we talking about, I don't know,  a   tenth of a second?  a ?	0
You know? How how much how much extra would you allow at most -	0
I I wanted to -	1
I wanted it to be able to l- he- be heard  normally,	1
so that if you if you play  back that bin and have it in the mode where it stops at the boundary,	1
it sounds like a normal word. It doesn't sound like the person -	1
i- it sounds normal. It's as if the person could've stopped there.	1
And it wouldn't have been an awkward place to stop.	0
Now  sometimes  you know, it's these are involved in places where there  was  no  time.   And so,	0
there wouldn't be  a  gap  afterwards because  I mean some cases, there're some people  um, who -	0
who have very  long   segments of discourse where,  you know, they'll they'll  breath   and then I put a break.	0
But other than that, it's really pretty continuous and this includes things like going from one sentence into the u- one utterance into the next, one sentence into the next,	0
w- without really  stopping.  I mean i-	0
they, i- you know in  writing  you have this  two spaces and a big gap you know.  But but uh   i- some people are planning and, you know, I mean, a lot we always are planning  what we're going to say next.  But uh, in which case,	0
the gap between  these two complete syntactic units,	0
which of course n- spoken things are not  always  complete  syntactically,  but -	0
but it would be a shorter p- shorter	0
break  than  maybe you might like.  But the goal  there  was to  not have  the text be	0
so so crudely  parsed in a time bin. I mean, because  from a discourse m-	0
it's more  it's more useful to be able to see and also you know, from a  speech  recognition purpose my impression is that	0
if you have  too  long a  unit,  it's it doesn't help you very much either, cuz of the memory.	0
So, that means that  the	1
amount of time  after   something	1
is variable depending partly on context, but my general goal  when there  was   sufficient	1
space, room, pause  after it  to have it be  kind of a natural feeling  gap.	1
Which I c- I don't know what it would be quantified as.  You know, Wally Chafe says that  um,  in producing narratives, the spurts that people use  tend to be,	1
uh, that the the what would be a pause might be something like two two seconds.	1
And um, that would be, you know one speaker.	0
The discourse  the people who look at turn taking often do use I was interested that you chose uh,	0
the you know that  you  use cuz I think that's a unit that would be more consistent with sociolinguistics.	0
you know, half a second because	1
if if you go much larger, you have a y-	1
you know, your your statement about how much  overlap  there is becomes less,	1
precise, because you include more of actual  pause  time into what you consider overlap speech.	1
it's sort of a compromise, and  it's also based I mean  Liz  suggested that value based on	1
pause  times that you see in	1
Yeah, I also used I think something around zero point five seconds for the speech-nonspeech detector for the minimum silence length.	1
In any case, this this uh, meeting  that I hand  I I hand-adjusted two of  them   I mentioned before, and I sent I sent email, so -	1
O_K,  So so at some point we will try to fine-tune our forced alignment maybe using those as references	1
And I sent the   path.	0
because you know, what you would  do  is you would play with different	0
parameters. And to get an object- You need an objective	0
measure of how closely you can align the models to the actual speech.	0
your data would be  very important to have.  So, I will -	0
Yeah and hopefully the new meetings  which will start from the channelized version will will	0
better time boundaries  and alignments.	0
But I like this idea of uh, for our purposes for the for the I_B_M preparation,  uh, n-	1
having  these  joined together, and uh -	1
It makes a lot of sense.  And in terms of transcription, it would be easy to do it that way. The way that they have	0
with the longer units, not having to fuss with adding these units at this time.	0
Whi- which could have one drawback. If there is uh a backchannel in between those three things,	1
the the  n-  the backchannel will will occur at the  end  of of those three. And -	1
and in in the -	0
in the  previous  version  where in the n-	0
there, the backchannel would would be in- between  there somewhere, so.	0
I see. Yeah. Well,  that's that's right, but you know, thi- this brings me to the  other  f- stage of this which I discussed with you earlier today,  which is  the  second  stage is  um,	1
That would be more natural but -	0
w- what to do  in terms of the transcribers  adjustment  of these data.  I  discussed this with you too.	0
Um, the tr- so the idea initially was, we would get  uh, for the  new  meetings, so the e- E_D_U meetings, that  Thilo	1
ha- has now presegmented all of them for us, on a channel by channel basis.	1
And um,  so, I've assigned I've I've assigned them to our transcribers  and um,	1
so far I've discussed it with  one,  with uh And I had a  about an hour discussion with her about this yesterday, we went through  uh E_D_U- one,  at some extent.	0
And it occurred to me that  um -	0
that  basically what we have in this kind of a format is you could consider it as a staggered  mixed  file, we had some discussion over the weekend a- about at at this  other  meeting that we were all a- at -	0
um,  about whether the tran- the I_B_M transcribers should hear a  single  channel audio, or a  mixed  channel audio.	0
And um,  in in a  way,  by by having this this chunk and then the backchannel	1
after  it, it's like a stagal-  staggered  mixed channel.	1
And um,  it occurred  to me in my discussion with  her  yesterday that um,  um,	0
the  the the maximal gain,  it's  from the I_B_M  people,  may  be in long stretches of connected speech.  So it's basically a whole bunch of words  which they can  really  do, because of the continuity  within  that person's  turn.	1
So, what  I'm  thinking, and it may be that not all meetings will be  good  for this,  but but what I'm thinking is that  in the E_D_U meetings, they tend to be  driven by a couple of dominant speakers.	1
And, if the chunked files focused on the dominant speakers,  then, when when it got s-	1
patched together when it comes back from I_B_M, we can add the backchannels.	1
It seems to me  that	0
um, you know, the backchannels per- se  wouldn't be so hard, but then there's this question of the  time    @@	0
uh, marking, and whether the beeps would be  uh y- y- y-  And I'm not exactly sure how that how that would work with the with the backchannels.	0
And  certainly  things that are  intrusions of  multiple  words,  taken out of  context  and  displaced  in time from where they  occurred,    that  would be  hard.	0
So, m- my  thought is  i-	0
I'm having this transcriber go through  the E_D_U- one  meeting, and indicate a  start  time	0
f- for each dominant speaker, endpoi-  end  time for each dominant speaker, and the idea that  these units would be generated for the dominant  speakers,   and maybe  not  for the other channels.	0
Yeah the only, um,  disadvantage  of that is, then it's hard to use an  automatic  method to do that.	0
The  advantage  is that it's probably  faster  to do that than it is to use the  automated  method and  correct  it.	0
Well, it O_K. I think  I I think um, you know, the original plan was that the transcriber would adjust the t- the boundaries, and all that for all the  channels  but,	1
We'll just have to see.	0
you know, that is  so  time-consuming, and since we have a bottleneck  here,  we want to get I_B_M things that are  usable  s- as soon as  possible,  then this seemed to me it'd be a way of gett- to get them a  flood  of data,  which would be useful when it comes  back  to us.	1
Oh also, at the same time she when she goes through this, she'll be  uh If there's anything that   was   encoded  as a  pause,  but really has something  transcribable  in it,  then she's going to  uh, make a mark -	0
w- uh, so you know, so  that that bin would be marked as it as double dots  and she'll just add an S_.  And in the other in the other case, if it's marked as  speech,	0
and really there's nothing transcribable in it,	0
then she's going to put a s- dash, and I'll go through and it and um, you know,	0
with a substitution command, get it so that it's clear that those are	0
the other category. I'll just, you know, recode  them.     But um,	0
um, the transcribable events  that um,  I'm  considering in this,  uh, continue to be  laugh, as well as speech, and cough and things like that, so I'm not stripping out anything, just just you know, being very lenient in what's considered speech.	0
Jane?  In terms of the this new procedure you're suggesting,  um,	0
u- what is the -	0
So I'm a little confused, because how do we know where to put beeps? Is it i- d- y- is it -	0
Oh, O_K.  So what it what it what it involves is is really a s- uh,	0
uh, the  original  pr- procedure,  but	0
a certain  strategically chosen  s- aspect of the data.  So -	0
We pick the easy parts of the data basically, and transcriber marks it by hand.	0
But after we've done  Thilo's  thing.	0
Oh,  after.  Oh, O_K, I didn't I didn't  understand  that. O_K.	0
I'm  @@  now I'm confused.	0
O_K.  We start with your presegmented version -	0
O_K, and I'm leaving.  So, um -	0
Yeah, I have to go as well.	0
O_K, leave the mikes on, and just put  them   on the table.	0
We start with the  presegmented   version -	0
You start with the presegmentation, r-  yeah?	0
Let me mark you as no digits.	0
And then um,  the transcriber,  instead of going painstakingly through all the channels and moving the boundaries around, and deciding if it's speech or not, but not  transcribing  anything.	0
O_K? Instead of doing that, which was our original plan,	0
the tra- They focus on the dominant speaker -	0
They just  do that on  the main channels.	0
So what they do is they identify who's the di- dominant speaker, and when the speaker starts.	0
So I mean, you're  still  gonna So we're It's based on your se- presegmentation, that's the basic   thing.	0
and you just use the s-	1
dominant  speaker then? For for sending to to I_B_M or ?	1
So, now Jane, my  question  is  when they're all done adjusting the w- time boundaries for the dominant speaker,	0
have they then also  erased  the time boundaries for the other ones?	0
So how will we know who -	0
That's that's why she's notating the start and end points of the dominant speakers.	0
So, on a you know, so  i- in E_D_U- one,  i- as far as  I  listened to it, you start off with a a s- section by Jerry. So Jerry starts at minute so-and-so, and goes until minute so-and-so. And then Mark Paskin comes in.	0
And he starts at  minute such-and-such, and goes on till minute so-and-so.	0
O_K. And then   meanwhile,  she's listening to	0
both  of these guys' channels,  determining if there're any cases of misclassification of speech as nothing, and nothing as speech,	0
and  a- and adding a tag if that happens.	0
So she does the adjustments on those guys?	0
But you know, I wanted to say, his segmentation is so good, that  um, the part that I listened to with her yesterday	1
didn't  need  any adjustments of the bins.	1
So this is not gonna be a major part of the process,	0
at least least not in not on ones that that really -	0
So if you don't have to adjust the  bins,	0
why not just do  what it  for all the channels?	0
Why not just throw all the channels to I_B_M?	0
Well there's the question o- of  whether -	0
Well, O_K.  She i- It's a question of how much time we want our transcriber to invest  here	0
when she's gonna have to invest that when it comes back from I_B_M  anyway.	0
So if it's only inserting "mm-hmm"s here and there,	0
then, wouldn't that be something that would be just as  efficient  to  do  at  this  end, instead of having it go through I_B_ M,  then be patched  together,  then be double  checked  here.	0
But  then  we could just use the the output of the  detector,  and do the	1
beeping  on it, and send it to I_B_ M.	1
Without having her check  anything.	1
I think we just we just have to listen to it and see how  good  they are.	0
For some meetings, I'm I'm sure it i-	0
I'm I'm  open  to that, it  was   @@	1
Yeah, if it's working  well,	0
that sounds like a good idea since as you say you have to do stuff with the other end anyway.	0
That's And some on  some  meetings it's  good.	0
Well yea- O_K, good. I mean the  detector,  this  Now,  you  were saying that they they differ in how well they work depending on channel s- sys- systems and stuff.	0
Yeah, I mean we have to  fix  it when it comes  back  anyhow.	0
So we  should  perhaps just select meetings on which the speech-nonspeech detection works  well,  and just use,	0
those  meetings to to to send to I_B_M and,	0
How interesting.  You know -	0
What's the problem the l- I forget. Is the problem the lapel, or or -	0
Uh, it really depends.  Um, my my -	0
my impression is that it's  better  for meetings with  fewer  speakers,	0
and it's better for -	0
for meetings where nobody is breathing.	0
So in fact this  might  suggest an  alternative  sort of a a c- a hybrid  between  these two things. So the the one suggestion is you know we -	1
No, the  undead  meeting, yeah.	0
we run Thilo's thing and then we have somebody go and adjust all the time boundaries and we send it to I_B_M. The other one is	1
we just run his thing and send it to I_B_M.	1
There's a a- another  possibility  if we find that there are some  problems,  and that is	1
if we go ahead and we  just run his, and we generate the beeps file, then  we  have somebody  listen   beeps  file.	1
And they listen to each section and say "yes, no" whether that section is	1
intelligible or not.  And it just You know, there's a little interface which will for all the "yes"-es it then  that  will be the final	0
That's interesting! Cuz that's that's  directly  related to the e- end  task.	0
Yeah.  I mean it wouldn't be that much  fun  for a  transcriber  to sit there, hear it, beep, yes or no.  But it would be  quick.	0
I I I don't know.	0
It would be  kind  of quick but they're still listening to everything.	0
But there's no  adjusting.  And  that's  what's slow. There's no adjusting of time boundaries.	0
Well,  eh,  listening   does  take time  too.	0
Yeah.  I don't know, I I think I'm I'm really tending towards I mean,  what's the worst that happens? Do the transcribers I mean as long as th- on the other end they can say there's -	0
One and a half times real time.	0
there's something conventions so that they say "huh?"	0
and then we can flag those later. i- i- It i-	0
That's true. We can just catch it at the catch everything at this side.  Well  maybe that's the best way to go, just -	1
How interesting!  Well E_D_U -	0
I mean it just depends on how -	0
So I was gonna say, E_D_U- one  is  good  enough, maybe we could include it in  this  in  this  set of uh, this stuff we  send.	0
Yeah there's I I think there are some meetings where  it  would would -	0
we  won't  know until we generate a bunch of beep files automatically, listen to them and see how bad they are.	0
We won't be able to s- include it with this first thing,	0
because there's a part of the process of the beep file which requires knowing the normalization coefficients.	0
That's not hard to do.	0
Just it takes you know, it just takes five minutes rather than,	0
Right, except I don't think that the c- the instructions for  doing  that was in that directory, right? I I didn't see where you had gener-	0
So. I just hand hard-coded it.	0
No, but it's easy enough to do.	0
But I but I have a -	0
Doing the gain? It's no problem.	0
O_K. So we just run that one -	0
There are  lots  of ways to do it.  I  have  one  program that'll do it. You can  find   other  programs.	0
I I used it, so.	0
We just run that J_sound-stat?	0
Minus  D_ , capital  D_ .	0
I I have  another suggestion on that, which is,	1
since,  really  what this is, is is is trying to in the  large,  send the right thing to them and there is gonna be this this post-processing step,	1
why don't we check through a bunch of things by  sampling  it?	1
Right? In other words, rather than,	0
uh, saying we're gonna  listen  to  everything  -	0
I  didn't mean listen to everything, I meant,	0
So y- you do a bunch of meetings, you listen to to a little bit here and there,  if it sounds like it's almost always right and there's not any big problem you send it to them.	1
just see if they're any good.	0
Send it to  them.   O_K.	0
And, you know, then they'll send us back what we w- what what they send back to us, and we'll we'll fix things up and	1
some meetings will cost more time to fix up than others.	0
And we should just double-check with Brian on a few simple conventions on how they should mark things.	1
When they when there's either no speech in there, or	0
something they don't understand, things like that.	0
Yeah, cuz  @@  uh- what I had originally said to Brian was well they'll have to mark,	0
when they can't distinguish between the foreground and background, because I thought  that  was gonna be the most  prevalent.	0
But if we send them without  editing,  then we're also gonna hafta have m- uh, notations for words that are cut off,	0
and other sorts of, uh, acoustic problems.	0
And they may just guess at what those cut-off words are, but w- I mean we're gonna adjust everything when we come back -	0
But what what we would  like  them to do is be  conservative   so that they should only write down the transcript if they're  sure.  And otherwise they should mark it so that we can check.	0
Well, we have the unintelligibility  convention. And actually  they  have one  also,   which -	0
i- Can I maybe have have an order of -	0
it's probably in your paper that I haven't looked at lately, but -	0
Uh, an order of magnitude notion of of how -	1
on a  good  meeting, how often uh, do you get	1
segments that come in the middle of words and so forth, and uh in a  bad  meeting how  often?	1
Was is it in a in a what what is the t-	0
Well he's saying, you know, that the the E_D_U meeting was a good  good  meeting, right? Uh, and so so so it was almost it was almost always doing the right thing.	0
In a good meeting,  what?	0
Oh I see, the characteristics.	0
So I wanted to get some sense of what what almost always meant.	0
And then, uh in a  bad  meeting,	0
or p- some meetings where he said oh he's had some  problems,  what does that  mean?	0
So I mean does one of the- does it mean  one  percent and  ten  percent? Or does it mean   five  percent and  fifty  percent?	0
Or Maybe percentage isn't the right word, but  you know  how many how many per minute, or You know.	0
Yeah, the the problem is that, nnn,	0
the numbers  Ian  gave in the paper is just uh, some frame error rate. So that's that's not really -	0
effective for for the transcribers, is -	0
They have to yeah, in- in- they have to insure that that's a real s- spurt or something.	0
And but,  the  numbers  Oops.   Um -	0
So the   speech  the amount of  speech  that is  missed  by the  detector,	1
is around  or  under  one percent, I would say.	1
But there  can   be  -	0
Yeah. For yeah, but there can be  more  -	0
There's There's more amount speech -	0
uh, more amount of -	0
Yeah well, the detector says there  is  speech, but there is  none.	0
So that that can be	0
a  lot  when when it's really a  breathy  channel.	0
But I think that's less of a problem. They'll just listen. It's just wasted time.	0
And th- and  that's  for a  good  meeting.	0
Now what about in a meeting that you said we've you've had some more trouble with?	0
I  can't   really hhh,   Tsk.  I  don't have really representative numbers, I  think.	1
I I did   this  on on four meetings and only five minutes of of every meet- of of these meetings so,	0
it's not not  that  representative, but,	0
Yeah, it's perhaps  then  it's perhaps five percent  of  something, which s- uh the the frames -	0
speech frames which are which are missed, but um,	0
I can't can't really tell.	0
So I  So i- Sometime, we might wanna go back and look at it more in terms of	0
how many times is there a spurt that's that's uh, interrupted?	0
The other problem is, that when it when it uh d- i- on the  breathy  ones, where you get	1
breathing,  uh, inti- indicated as speech.	1
And I  guess  we could just indicate to the  transcribers  not to   encode  that if they We could  still  do the  beep  file.	0
Yeah again I I think that that is probably less of a problem because if you're if there's -	0
If if a if a  word  is is split, then they might have to listen to it a few times to really understand that they can't quite  get  it.	0
Whereas if they listen  to it and there's don't hear any speech I think they'd probably just listen to it  once.  So there'd you'd  think  there'd be a -	0
a factor of three or four in in, uh,  cost  function, you know, between them or something.	0
Yeah, so but I think that's n- that really	0
doesn't happen very often that that that a word is cut in the middle or something.  That's that's really not not normal.	0
So so what you're  saying  is that nearly  always  what happens when there's a problem is that is that uh, there's  some uh, uh  nonspeech  that uh that is b- interpreted as speech.	0
That is marked as speech. Yeah.	0
Well then, we  really  should just  send  the stuff.	0
Right? Because that doesn't do any  harm.	0
You know, if they they hear you know, a dog bark and they say what was the  word,  they  you know, they -	0
Yeah, I als- I -	0
Yeah I also thought of there there are really  some  channels where it is almost	0
um, only bre-  breathing  in it.	0
Eh, um. Yeah. I've got a a  P_- a  method with loops into the cross-correlation with the P_Z_M mike,	1
and then to reject everything which which seems to be breath.	1
So, I could run this on those breathy channels, and perhaps throw out -	1
Wow,  that's  a  great  idea.	0
Yeah. But I think I th-  Again,  I think that sort of that that would be good,  and what that'll do is just cut the time a little further.	1
But I think  none  of this is stuff that really needs somebody doing these these uh, uh,	0
Oh, I'd be  delighted  with that, I I was very impressed with the with the result.  Yeah.	0
Yeah, cuz the  other  thing that was concerning me about it was that it seemed kind of specialized to the E_D_U meeting, and and that then when you get	0
a meeting like this or something, and  and you have a b- a bunch of different dominant speakers you know, how are you gonna handle it. Whereas this sounds like a more general solution is -	0
Oh yeah, I pr- I much prefer this, I was just trying to find a way  Cuz I I don't think the staggered mixed channel is awfully good as a way of handling overlaps.	0
Well  good.  That that really  simplifies  thing then.  And  we can just, you know, get the meeting, process it,	1
put the beeps file, send it off to I_B_M. You know?	1
With very little  work on our side.	0
Process it,  hear into it.	0
Um,   listen  to it, and then -	0
Or at least  sample  it.	0
Well, sample it. Sample it.	0
I I would just use some samples, make sure you don't	0
send them three hours of "bzzz"  or something.  Yeah.	0
Yeah. Yeah that would be very good.	0
And then we can you know  That'll oughta be a good way to get the pipeline	0
And there's there's one point which I  uh -	1
yeah, which which I r-	1
we covered when I when I r- listened to one of the E_D_U meetings, and that's	1
that somebody is playing sound from his laptop.	1
the speech-nonspeech detector just assigns randomly the speech to to one of the channels, so.	1
Uh- I haven't- I didn't think of of s- of	0
this before, but what what shall we do about s- things like this?	0
Well  you  were suggesting  You  suggested maybe just not sending that part of the  meeting.  But -	0
the the laptop is in the background and some somebody is is talking, and,	0
that's really a little bit confusing, but -	0
It's a little bit  confusing.  I mean,  what're we gonna  do?	0
Even a  hand-transcription  would -	1
a  hand-transcriber  would have trouble with that. So.	1
Yeah, that's that's a  second  question, "what what will different transcribers do with with the laptop sound?"	0
Would you would Yeah, go ahead.	0
What was the l- what was the laptop sound? I mean was it  speech,  or was it -	0
Well, so I mean So  my  standard approach has been if it's not someone close-miked,	0
then, they don't end up on one of the close-miked  channels.  They end up on a  different  channel. And we have any  number  of channels available, I mean it's an infinite number of channels.  So just put  them   on some  other  channel.	0
when thi- when this is sent to to the I_M_- eh, I_B_ M  transcribers, I don't know if if they can tell that's really -	0
Yeah cuz there will be  no  channel on which it is  foreground.	0
Well, they have a convention, in  their   own  procedures,  which is for a background  sound.	0
Right, but, uh, in general I don't think we  want  them transcribing the background, cuz that would be too much work.	0
Right? For it because in the overlap sections, then they'll-	0
Well I don't think Jane's saying they're gonna  transcribe  it, but they'll just mark it as being there's some  background  stuff there, right?	0
But that's gonna be all  over  the place. How w- how will they tell the difference between  that  sort of background and the dormal  normal  background of two people talking at once?	0
Oh, I think I think it'd be  easy  to to say "background laptop".	0
But  wait  a minute,  why  would they treat them  differently?	0
How would they  know  that?	0
Well because  one  of them -	0
Because otherwise it's gonna be too much work for them to  mark  it.	0
They'll be marking it all  over  the place.	0
Oh, I s- background laptop or, background L_T   wouldn't take any time.	0
Sure,  but how are they gonna tell bet- the difference between  that  and two people just talking at the same  time?	0
Oh, you can  tell.  Acoustically, can't you tell?	0
It's really good sound, so -	0
Well, I mean, isn't there a category something like uh, "sounds for someone for whom there is no i- close mike"?	0
Yeah that would be very important, yeah.	0
But how do we d- how do we do that for the I_B_ M  folks?	0
How can they  tell  that?	0
Well we may just have to do it when it gets back here.	0
Yes, that's my opinion as  well.  So we don't do  anything  for it with it.	1
And they'll just mark it however they mark it, and we'll correct it when it comes back.	1
there was a category for	0
Well, as it comes back, we have a uh when we can use the channelized interface for encoding it, then it'll be easy for us to handle. But -	0
but if if out of context, they can't  tell  if it's a channeled speak- uh,	0
you know, a close-miked speaker or not,  then that would be confusing to  them.	0
I don't know, I it doesn't I don't -	0
Either way would be fine with me, I don't really care.	0
So. Shall we uh, do digits and get out of here?	0
I have o- I have one question. Do you think we should send the um that whole meeting to them and not worry about pre-processing it? Or Uh, what I mean is  we we should	0
leave the  part with the audio  in  the	0
uh, beep file that we send to I_B_M for that one, or should we  start after the that part of the meeting is over	0
in what we send.  So, the part where they're using sounds from their from their laptops.	0
with the laptop sound, or ?	0
w- If we have speech from the laptop should we just uh, excise that from what we send to I_B_M, or should we  i- give it to them and let them do with it what they can?	0
I think we should just it it's gonna be too much work if we hafta	0
O_K,  that'd  be  nice  to have a a uniform procedure.	0
worry about that I think. Yeah, I think if we just m- send it  all  to  them.	0
Worry about it when we get back.	0
Good. And see how well they do.	0
Let Yeah, worry about it when we get back in.	0
And give them freedom to  to indicate if it's just not workable. Yeah, O_K, excellent.	0
Yeah. Cuz, I wouldn't don't think we would  mind   having that  transcribed, if they did it.	0
As I say, we'll just have to listen to it and see how horrible it is.	0
I think that that will be a  little  bit of a problem as it really switches around between  two different channels, I think. What what  I would  -	0
Mm-hmm, and and they're very it's very audible? on the close-talking channels?	0
I mean, it's the same problem as the lapel mike.	0
O_K, so we read the transcript number first, right?	0
Are we gonna do it  altogether  or  separately?	0
Uh,  why don't we do it together, that's that's a nice fast way to do it.	0
It's kind of interesting if there're any more errors in these,  than we had the first set.	0
Nnn, yeah, I think there probably  will  be.	0
Do you guys plug your ears when you do it?	0
I  usually  do. I  didn't   this  time.	0
You  don't?   How  can you  do  that? I I -	0
Perhaps there are  lots of errors in it  but	0
Total concentration. Are you guys ready?	0
You hate to have your ears plugged?  Really?	0
