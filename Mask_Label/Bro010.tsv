O_K, what are we talking about today?	0
I don't know. Do you have news from the conference talk?	1
Yesterday morning on video conference.	1
Uh,  oh,   I'm  sorry. I know -  now  I know what you're talking about. No, nobody's told me anything.	1
Oh, this was the, uh,	0
talk where they were supposed to try to decide -	0
to decide what to do, yeah.	0
Yeah. No, that would have been a good thing to find out before this meeting, that's.  No, I have no - I have no idea. Um,	1
Uh, so I mean, let's - let's assume for right now that we're just kind of plugging on ahead, because even if they	1
tell us that, uh, the rules are different, uh, we're still interested in	1
doing what we're doing. So what are you doing?	1
a little bit worked on trying to see,	1
uh, what were the bugs and the problem with the latencies. So,	1
We took - first we took [MASK] and,	1
uh, we designed new filters,	1
using uh recursive filters actually.	1
So when you say "we", is that something Sunil is doing or is that - ?	0
So we took the filters -	1
designed, uh, [MASK] that have the same frequency response.	1
similar,  but that have shorter delays.	1
So they had two filters, one for the low frequency bands and another for the high frequency bands.	0
And so we redesigned two filters. And the low frequency band has	1
sixty-four milliseconds of delay, and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the	1
But it's not yet test. So we have the filters but we still have to implement a routine that does recursive filtering and -	0
You - you had a discussion with Sunil about this though?	1
Yeah, you should  talk  with him.	1
Yeah.  No, I mean, because the - the - the - the whole problem that happened before was coordination, right? So - so you need to	1
discuss with him what we're doing, uh, cuz they could be doing the same thing and - or something.	1
Uh, I - yeah, I don't know if th- that's what they were trying to -	0
They were trying to do something different like	0
taking, uh - well, using filter that takes only a past and	0
this is just a little bit different. But I will- I will send him an email and tell him exactly what we are doing, so.	0
Yeah, yeah. Um, I mean -	0
We just - we just have to be in contact more. I think that - the - the fact that we -	1
we did that with - had that thing with the latencies was indicative of the fact that there wasn't enough communication. So.	1
Well, there is w- one, um,	0
remark about these filters, that	0
they don't have a linear phase. So,	0
Well, I don't know, perhaps it - perhaps it doesn't hurt because the phase is almost linear but.	0
Um, and so, yeah, for the delay I gave you here, it's -	0
the five hertz modulation frequency, which is the -	0
the most important for speech  so .	0
Uh, this is the first thing.	0
So that would be, uh, a reduction of a hundred and thirty-six milliseconds, which, uh -	1
What was the total we ended up with through the whole system?	1
So that would be within - ?	1
Yeah, but there are other points actually,	1
uh, which will perhaps add some more delay. Is that	0
some other - other stuff in the process were perhaps not very -	0
perf- well, not very correct,	0
like the downsampling which w- was simply dropping frames.	0
so we will try also to add a nice downsampling having a filter	0
that - that - well,	0
a low-pass filter at - at twenty-five hertz.	0
Uh, because wh- when - when we look at [MASK] well, they are basically low-pass but	0
leave a lot of what's above twenty-five hertz.	0
Um, and so, yeah, this will be another filter which would add ten milliseconds again.	0
yeah, and then there's a third thing,	0
is just using this recursion	0
on - on the um,	0
and - but this is a filter, so it has also a delay.	0
look at this filter actually it has a delay of eighty-five milliseconds. So if we -	0
If we want to be very	0
correct, so if we want to -	0
the estimation of the mean t- t- to - to be -	0
the right estimation of the mean,	0
we have to t- to take eighty-five milliseconds in the future.	0
That's a little bit of a problem.	0
But, well, when we add up everything it's - it will be alright.	1
We would be at six- so, sixty-five,	1
plus ten, plus - for the downsampling, plus eighty-five for [MASK]	1
Uh, yeah, but then there's -	0
plus - plus eighty for [MASK]	1
So it would be around two hundred and forty - so, well,	1
Just - just barely in there.	1
plus - plus the frames, but it's O_K.	0
Two-fifty, unless they changed the rules.	1
Which there is - there's some discussion of. But -	1
What were they thinking of changing it to?	1
Uh, well the people who had very low latency want it to be low - uh, very -	1
very- very narrow, uh, latency bound. And the people who have longer latency don't. So.	1
Unfortunately we're the main ones with long latency, but	1
But, uh, you know, it's -	0
Yeah, and basically the best proposal had something like thirty or forty milliseconds of latency. So.	1
Yeah, so they were basically - I mean,	0
they were more or less trading computation for performance and we were,	0
uh, trading latency for performance. And	0
they were dealing with noise explicitly and we weren't, and	0
so I think of it as complementary,	0
that if we can put the -	0
Think of it as  what?	0
I think the best systems -	0
so, uh, everything that we did in- in a  way  it was - it was just	0
adamantly insisting on going in with a brain damaged system, which is something - actually, we've done a  lot  over the last thirteen years.	0
Uh,  which is we say, well  this  is the way we should do it. And then we do it. And then	0
does something that's straight forward. So, w- th- w- this was a test that largely had additive noise and we did - we adde-	0
did absolutely nothing explicitly to handle ad- additive noise.	0
We just, uh, you know, trained up systems	0
And, uh, we did this, uh, [MASK] which	0
was done in the log domain and was tending to handle convolutional noise. We did - we actually did nothing about additive noise.	0
the, uh, [MASK] schemes a couple places did seem to- seem to do a nice job. And so, uh,	0
we're talking about putting - putting some of that  in  while still keeping some of our stuff. I think you should be able to end up with a system that's better than	0
both but clearly the way that we're operating for this  other  stuff  does  involved some latency to - to	0
get rid of most of that latency. To get down to forty or fifty milliseconds we'd have to throw out most of what we're doing.	1
And - and, uh, I don't think there's any good reason for it in the application actually. I mean, you're -	0
you're - you're speaking to a recognizer on a remote server	0
and, uh, having a - a - a quarter second	0
for some processing to clean it up. It doesn't seem like it's that	0
big a deal. These aren't large vocabulary things so the decoder shouldn't take a really long time, and.	0
And I don't think anybody's gonna notice the difference between a quarter of a second of latency and thirty milliseconds of latency.	0
No. What - what does - wa- was your experience when you were doing this stuff with, uh, the -	0
the - the surgical, uh,	0
uh, microscopes and so forth. Um, how long was it from when somebody, uh,	0
finished an utterance to when, uh, something started happening?	0
Um, we had a silence detector, so	0
we would look for the end of an utterance based on the silence detector.	0
And I - I can't remember now off the top of my head how many	0
frames of silence we had to detect before we would declare it to be	0
the end of an utterance. Um,	0
I would say it was probably around the order of two hundred and fifty milliseconds.	0
Yeah, and that's when you'd  start	0
Yeah, we did the back trace at that point to get the answer.	0
Of course that didn't take too long at that point. Yeah.	0
No, no it was pretty quick.	0
Yeah, so you - you - so you had a	0
so you had a - a quarter second delay before, uh,	0
plus some little processing time, and then	0
the - the microscope would start moving or something.	0
And there's physical inertia there, so probably the - the motion itself was  all  -	0
And it felt to, uh, the users that it was	0
instantaneous. I mean, as fast as talking to a person. It -	0
th- I don't think anybody ever complained about the delay.	0
Yeah, so you would think as long as it's under half a second or something. Uh, I'm not an expert on that but.	0
I don't remember the exact numbers but	0
it was something like that.	0
I don't think you can really  tell.	0
A person - I don't think a person can  tell  the difference between,	1
uh, you know, a quarter of a second and a hundred milliseconds, and -	1
I'm not even sure if we can tell the difference between a quarter of a second and  half  a second.	1
I mean it just - it feels so quick.	1
I mean, basically if you - yeah, if you	0
"what's the, uh, uh - what's the shortest route to the opera?"	0
and it took half a second to get back to you,  I mean,  it would be f- I mean, it might even be too abrupt. You might have to put in a s- a s-  a delay. Yeah.	0
I mean, it  may  feel different than talking to a person because when we talk to each other we tend to step on each other's utterances.	0
So like if I'm asking you a question, you may start answering before I'm even  done.	0
So it - it would probably feel different but I don't think it would feel	0
I mean, I think -	0
we  could  cut - we know what else, we could cut down on the neural net time by - by, uh,	1
playing around a little bit, going more into the past, or something like that. We t- we talked about that.	1
So is the latency from the neural net caused by how far  ahead  you're looking?	1
And there's also - well, there's the neural net and there's also this, uh, uh, multi-frame, uh, uh, [MASK]	0
Was it in the, uh, recurrent neural nets where they weren't looking ahead at all?	0
They weren't looking ahead  much.	0
They p- they looked ahead a little bit.	0
Yeah, I mean, you could do this with a recurrent net. And - and then - But you  also  could just, um,	0
I mean, we haven't  experimented  with this but I  imagine  you could, um,	0
uh, predict a, uh -	0
um, a label, uh, from more in the past than in - than - than in the future.	0
I mean, we've d- we've  done  some stuff with that before. I think it - it works O_K.	0
We've always had -  usually  we used the symmetric windows but I don't think -	0
Yeah, but we've - but we played a little bit with - with asymmetric, guys. You can do it.	0
So, that's what - that's what you're busy with, s- messing around with this, yeah.	0
Also we were thinking to -	1
to, uh, apply the eh, [MASK]	1
I'm missing that last word. Context-	0
[MASK] I'm sorry.	0
Uh, to change and use [MASK]	1
What is the advantage of that?	0
Well, it's that by the- for the moment we have, uh, something that's discriminant and nonlinear.	0
And the other is linear but it's not discriminant at all. Well, it's	0
it's a linear  transformation,  that -	0
So at least just to understand maybe what the difference was between how much you were getting from	0
just putting the frames together and how much you're getting from the discriminative,	0
what the nonlinearity does for you or doesn't do for you.	0
Just to understand it a little better I guess.	0
Well - uh - yeah.	0
Actually what we want to do, perhaps it's to replace - to - to have something that's discriminant but linear, also.	0
And to see if it - if it improves ov- over - over [MASK]	0
And if the neural net is better than this or, well.	0
Yeah, well, that's what I meant, is to see whether -	0
whether it - having the neural net really buys you anything.	0
Uh, I mean, it doe-  did  look like it buys you something over just [MASK]	0
But maybe it's just the discrimination and - and maybe - yeah, maybe [MASK] isn't necessary.	0
Good - good to know.	0
But the  other  part you were saying was the spectral subtraction, so you just kind of, uh -	0
At what stage do you  do  that? Do you - you're doing that, um - ?	0
So it would be on the um -	0
on - on [MASK] so. Yeah, be- before  everything.	0
Yeah, we - no - nnn	0
O_K, so just do that on the mel f-	0
We - we was thinking to do before after [MASK] or-	0
Oh,  we don't know exactly when it's better. Before after [MASK] or -	0
So - so you know that - that - that the way that	0
they're - uh,  one  thing that would be no - good to find out about from this conference call is that what they were  talking  about, what they're  proposing  doing,	1
was having a third party, um,	1
and - and determine boundaries.	1
And then given those boundaries,	1
then have everybody do the recognition.	1
The  reason  for that was that, um, uh -	0
if some- one p- one group put in [MASK] and another  didn't,	0
uh, or one had a  better  [MASK] than the other	0
since that - they're not viewing  that  as being	0
part of the - the  task,	0
and that any - any manufacturer would	0
put a bunch of effort into having some s- kind of good speech-silence detection.	0
It still wouldn't be  perfect  but I mean,	0
e- the argument was "let's not have that be part of this test."	0
"Let's - let's separate that out."	0
uh, I guess they argued about that yesterday and,	1
yeah, I'm sorry, I don't - don't know the answer but we should find out. I'm sure we'll find out soon	1
what they, uh - what they decided.	0
So, uh - Yeah, so there's the question of [MASK] but otherwise it's - it's on the - the, uh -	0
energies I guess? You do - doing the - ?	0
And you're - you're subtracting in the - in the - in the -	0
I guess it's power - power domain,	0
uh, or - or magnitude domain. Probably power domain, right?	0
I guess it's power domain, yeah. I don't remember exactly.	0
But - yeah, so it's before everything else, and -	0
I mean, if you look at the theory, it's - it  should  be in the power domain but - but, uh, I've seen implementations where people do it in the magnitude domain and -	0
I have asked people  why  and they shrug their shoulders and say, "oh, it works." So.	0
Uh, and there's this - I guess there's this mysterious - I mean people who do this a lot I guess have developed little tricks of the trade. I mean, there's -	0
there's this, um - you don't just subtract the - the estimate of [MASK] You subtract th- that  times  -	0
A little bit more and -	0
Or - or  less,  or -	0
And generated this - this, um,	0
so you have the estimation of [MASK]	0
and you multiply this by a factor which is depend- dependent on [MASK]	0
When the speech lev- when the signal level is more important, compared to this noise level,	0
the coefficient is small, and around one.	0
But when the power le- the s- signal level is	0
uh small compared to the noise level, the coefficient is more important.	0
And this reduce actually the music- musical noise, uh	0
which is more important during silence portions, when	0
the s- the energy's small.	0
So there are tricks like this but, mmm.	0
Is the estimate of [MASK] a  running  estimate?	0
Well, that's - I mean, that's what differs from different -	0
different tasks and different s- uh, [MASK] methods. I mean, if -	0
if you have, uh, fair assurance that, uh,	0
the noise is - is quite stationary,	0
then the smartest thing to do is use as much	0
data as  possible  to estimate the noise, get a much better estimate, and subtract it off.	0
But if it's varying at all, which is gonna be the case for almost any real situation, you have to	0
do it on-line, uh, with some forgetting factor or something.	0
So do you - is there some long window that extends into the past over which you calculate the average?	0
Well, there's a lot of different ways of computing [MASK] So one of the things	1
that, uh, [MASK] did, uh - and pas- and other people - actually, he's - he wasn't the only one I guess,	0
was to, uh, take some period of - of - of speech	0
and in each band, uh, develop a histogram.	0
So, to get a decent histogram of these energies	0
takes at least a few seconds really. But, uh - I mean you can  do  it with a smaller amount but it's pretty rough.	0
And, um, in  fact  I think the NIST	0
standard method of determining signal-to-noise ratio is based on this.	0
No, no, it's based on this kind of method, this histogram method.  So you have a  histogram.	0
Now, if you have  signal  and you have  noise,  you basically have these two  bumps	0
in the histogram, which you could approximate as [MASK]	0
But wh- don't they overlap sometimes?	0
So you have a mixture of [MASK]	0
Right? And you can use [MASK] to figure out what it  is.  You know. So - so basically now you have this mixture	0
and, uh, so this gives you what the signal is and what the  noise  e- energy is	0
in that band in the  spectrum.  And then you look over the whole thing and now you have a noise spectrum.	0
So, uh, Hans-Guenter  Hirsch  and others have used that kind of method. And the other thing to do	0
is - which is sort of more trivial and obvious  - is to, uh,	0
uh, determine through magical means that - that, uh, there's no speech in some period, and then see what the spectrum is.	0
you know, it's - that - that - that's	0
tricky to do. It has mistakes. Uh, and if you've got enough time, uh, this other method appears to be somewhat more reliable.	0
Uh, a variant on that for just determining signal-to-noise ratio	0
is to just, uh - you can do a w- a uh - an iterative thing, [MASK] to determine means only. I guess it is [MASK] still, but just - just determine the means only.	0
Don't worry about the variances. And then you just use those mean values as being the - the, uh	0
signal-to-noise ratio in that band.	0
But what is the -	0
it seems like this kind of thing could add to the latency.	1
where the window was that you used to calculate  the signal-to-noise ratio.	1
Not necessarily. Cuz if you don't look into the future, right?  if you just - yeah - I mean, if you just - if you -	1
O_K, well that - I guess that was my question, yeah.	0
you, uh - a- at the beginning you have some -	0
esti- some guess and - and, uh, uh -	0
It's an interesting question. I wonder how they did	0
Actually, it's a mmm -	1
If- if you want to have a good estimation on non-stationary noise you have to look in the - in the  future.  I mean,	1
if you take your window and build your histogram in this window,	0
um, what you can expect is to have an estimation of th- of the noise in - in the middle of the window, not at the end. So -	0
Well, yeah, but what does - what - what - what does [MASK] do? And -	1
the - but - but people -	0
They just look in the past. I guess it works because the noise are, uh	1
pret- uh, almost stationary but,	1
Well, the thing, e- e- e- e-	1
Yeah, y- I mean, you're talking about non-stationary noise but I think that [MASK] is rarely - is - is not gonna work really well for - for non-stationary noise, you know?	1
Well, if y- if you have a good estimation of the noise,  yeah,  because well it- it  has  to work. i-	0
But it's hard to - but that's hard to do.	1
Yeah, that's hard to do. Yeah.	1
Yeah. So - so I think that - that what - what is -	0
wh- what's more common is that you're going to be helped with r- slowly varying or stationary noise.	0
That's what [MASK] will help with, practically speaking.	0
If it varies a  lot,  to get a- If - if - to get a good estimate you need a few seconds of  speech,   even  if it's  centered,	0
right?  if you need a few seconds to get a decent estimate but it's changed a lot in a few seconds,	0
then it, you know, i- it's kind of a problem. I mean, imagine e- five hertz is the middle of the - of [MASK] right?	0
So imagine a jack hammer going at five hertz.	0
I mean, good - good  luck.  So,	0
So in this case, yeah, sure, you cannot -	0
But I think y- um,	0
Hirsch does experiment with windows of	0
like between five hundred milliseconds and one second. And	0
well, five hundred wa- was not so bad. I mean	0
and he worked on non-stationary noises, like noise modulated with	0
well, wi- with amplitude modulations and	0
things like that, and -	0
Were his, uh, windows centered around the -	0
yeah. Well, I think - Yeah. Well, in - in the paper he showed that actually the estimation of the noise is - is delayed. Well, it's - there is -	0
you - you have to center the window, yeah.	0
No, I understand it's better to  do  but I just think that - that, uh,	0
for  real  noises wh- what - what's  most  likely to happen is that there'll be some things that are relatively stationary where you can use one or another [MASK] thing and  other  things where it's not so stationary and -	0
I mean, you can always pick something that - that falls between your methods, uh, uh, but I don't know if, you know, if sinusoidally, uh,	0
modul- amplitude modulated noise is - is sort of a big problem in - in in - practice. I think that  it's uh -	0
We could  probably  get a  really  good estimate of the noise if we just went to the  noise  files,	0
and built the averages from  them.	0
Just cheat - You're saying,  cheat.	0
But if the - if the noise is stationary	0
perhaps you don't even  need  some kind of noise estimation algorithm. We just take th- th-	0
th- the beginning of the utterance and	0
I- I know p- I don't know if people tried this for [MASK] Well, everybody seems to use some kind of adaptive, well,	0
is it very useful and is the c-	0
Right, the word "stationary" is - has a very precise statistical meaning. But, you know, in - in signal-processing really what we're talking about I think is things that change slowly,	0
uh, compared with our - our processing techniques. So	0
if you're driving along in a car I - I would think that most of the time	0
the nature of the noise is going to change relatively slowly. It's not gonna stay absolute the same. If you - if you check it out,	0
uh, five minutes later you may be in a different part of the road or	0
whatever. But it's - it's - i- i- i-	0
characteristics in time, is probably going to work pretty well.	0
But you could get hurt a lot if you just took some- something from the beginning of all the speech, of, you know, an hour of speech and then later -	0
Uh, so they may be - you know, may be  overly,  uh, complicated for - for this test but -	0
but - but, uh,  I  don't know.	0
But what you're saying, you know, makes sense, though. I mean, if possible you shouldn't -	0
you should - you should make it, uh, the center of the - center of the window. But -	0
uh, we're  already  having problems with these delay, uh -  delay issues. So, uh, we'll have to figure ways  without  it.	0
If they're going to provide a,	0
that will tell you the boundaries of the speech, then,	0
couldn't you just go outside those boundaries and do your estimate there?	0
Yeah.  So I - I imagine that's what they're  doing,  right? Is they're -	0
they're probably looking in nonspeech sections and getting some, uh -	0
Yeah, they have some kind of threshold on - on the previous estimate, and -  So.	0
I  think.  Yeah, I think	0
[MASK] used this kind of threshold. Yeah, so, they h- they have an estimate of the noise level	0
and they put a threshold like six or ten D_B above,	0
what's under this threshold is used to update the estimate.	0
Is - is that right or - ?	0
I have not here the proposal.	0
So it's - it's - Yeah.	0
Does [MASK] do this -	0
It's like saying what's under the threshold is silence, and -	0
Does [MASK] do th- do the same thing?	0
I do- I have not here the proposal.	0
O_K, if we're - we're done - done with that, uh,	0
let's see. Uh, maybe we can talk about a couple other things briefly, just, uh, things that - that we've been	1
chatting about  but  haven't made it into these meetings yet. So you're coming up with your quals proposal, and, uh - Wanna just	1
give a two three minute summary of what you're planning on doing?	0
two, three, it can be shorter than that. Um.	0
I've talked to some of you already. Um, but I'm, uh, looking into extending the work done by Larry Saul and John Allen and uh Mazin Rahim.	1
Um, they - they have a system that's, uh, a multi-band, um, system but their multi-band	1
is - is a little different than the way that we've been doing multi-band in the past, where	1
um - Where  we've  been	1
sub-band features and i- training up these neural nets and - on - on phonetic targets, and then combining them some- somehow down the line,	1
they're - they're taking sub-band features and, um,	1
training up a detector that detects for, um,	1
for example, um, he presents um,	0
uh, a detector to detect [MASK]	0
And so what - what it  basically  is - is, um - it's - there's -	0
at the lowest level, there - it's - it's an  OR  ga- I mean, it's an  AND  gate. So, uh, on each sub-band you have several	0
um, there's the existence of [MASK] in a sub-band.	0
And then, um, it c- it's combined by a soft AND gate.	0
And at the - at the  higher  level,	0
for every - if, um - The  higher  level there's a soft  OR  gate.	0
Uh, so if - if this detector detects	0
um, the presence of - of [MASK] in any of the sub-bands, then the detect- uh, the  OR  gate at the top says, "O_K, well this frame	0
has evidence of [MASK]" And these are all -	0
What are - what are some of the low level detectors that they use?	0
Oh, O_K. Well, the low level detectors are logistic regressions.	0
Um, and the, uh - the one o-	0
So  that,  by the way, basically is a - is one of the units in our - in our - our neural network. So that's all it is. It's a sig- it's a sigmoid,	0
uh, with weighted sum at the input,	0
which you train by gradient  descent.	0
Yeah, so he uses, um, [MASK] to -	0
to um train up these um parameters for the logistic regression.	0
Well, actually, yeah, so I was using [MASK] to get the  targets.	0
So - so you have this - this - this AND gate - what we were calling an AND gate, but it's a product - product rule thing at the output.	0
And then he uses, uh, i- u- and then feeding  into  that are - I'm sorry, there's - it's an  OR  at the output, isn't it? Yeah, so  that's  the product. And then, um,	0
then he has each of these  AND  things. And, um,	0
but - so they're little  neural  -  neural  units.	0
Um, and, um, they have to have  targets.  And so the  targets  come from E_M.	0
And so are each of these, low level detectors  - are they, uh -	0
are these something that you decide  ahead  of time, like "I'm going to look for this particular feature or I'm going to look at this frequency," or -	0
What - what - what are they  looking  at? What are their  inputs?	0
Right, so the - O_K, so at each- for each sub-band	0
there are basically, uh, several measures of [MASK] and - and correlation.	0
Um, um and he said there's like twenty of these per - per sub-band.	0
and for - for every s- every sub-band,	0
e- you - you just	0
pick ahead of time, um, "I'm going to have like five	0
And you initialize these parameters,	0
um, in some - some way	0
to come up with your training targets for a - for the - the low-level detectors.	0
And then, once you get that done, you - you - you train the whole -	0
whole thing on maximum likelihood.  Um,	0
and h- he shows that using this - this method to detect sonorance is-	1
it's very robust compared to, um -	1
[MASK] um estimations of - of sonorance.	1
so that's just - that's just one detector. So you can imagine	1
building many of these detectors on different features. You get enough of these detectors together,	1
um, then you have enough information to do, um, higher level discrimination, for example, discriminating between phones	1
and then you keep working your way up until you - you build a full recognizer.	1
So, um, that's - that's the direction	1
which I'm - I'm thinking about going in my quals.	1
You know, it has a number of properties that I really liked. I mean, one is the going towards, um,	0
using narrow band information for, uh, ph- phonetic features of some sort rather than just, uh,	0
immediately going for the - the typical sound units.	0
Another thing I like about it is that you t- this thing is going to be trained -	0
explicitly  trained for a product of errors rule,	0
which is what, uh, Allen keeps pointing out that Fletcher observed in the twenties,	0
uh, for  people  listening to narrow band stuff. That's Friday's talk, by the way.	0
Uh, the  third  thing I like about it is,	0
uh, and we've played around with this in a different kind of way a  little  bit but it hasn't been our dominant way of - of operating anything,	0
um, this issue of where the targets come from.	0
So in  our  case when we've been training it multi-band things, the way we get the targets for the individual bands	0
is, uh, that we get the phonetic label -	0
for the  sound  there and we say, "O_K, we train every -"  What  this  is saying is, O_K, that's maybe what our  ultimate  goal is - or not ultimate but	0
penultimate  goal is getting these - these small sound units. But - but, um,	0
along the way how much should we, uh -	0
uh, what should we be training these  intermediate  things  for?	0
I mean, because, uh, we don't know	0
uh, that this is a particularly good feature. I mean, there's no way, uh - someone in the audience yesterday was asking, "well couldn't you have people go through and mark the individual bands and say where the -	0
where it was sonorant or not?"	0
But, you know, I think having a bunch of people listening to critical band wide,	0
uh, chunks of speech trying to determine whether -  I think it'd be  impossible.  It's  all  gonna sound like - like  sine  waves to you, more or  less.  I mean - Well not- I mean, it's g- all g- narrow band	0
uh, i- I m- I think it's very hard for someone to - to - a person to make that determination. So, um, um, we don't really  know  how those should be labeled.	0
It could sh- be that you should,	0
not be paying that much attention to, uh, certain bands for certain sounds, uh, in order to get the	0
best result. So, um, what we have been doing	0
there, just sort of mixing it all  together,  is certainly much - much  cruder  than that. We trained these things up on the - on the, uh- the final label. Now we  have	0
I guess done experiments - you've probably done stuff where you have,	0
um, done separate, uh, Viterbis on the different -	0
Yeah. Forced alignment on the sub-band labels? Yeah.	0
You've done that. Did - did that  help  at all?	0
Um, it helps for one or t- one iteration but	0
So - so that may or  may  t- it - that aspect of what he's doing may or may not be helpful because in a  sense  that's the same sort of thing. You're taking global information and determining what you - how you should -  But this is - this is, uh, I th- I think a little more direct.	0
How did they measure the performance of their detector?	0
Well, he's look- he's just actually looking at, uh, the confusions between [MASK]	0
So he hasn't applied it to recognition or if he did he didn't talk about it. It's - it's just -	0
And one of the concerns in the audience, actually, was that - that, um,	0
the, uh, uh - he - he did a comparison to, uh,	0
you know, our old foil, the - the nasty old standard recognizer with  mel - mel filter bank at the front, and [MASK] and - and so forth.	0
And, um, it didn't do nearly as  well,  especially in - in  noise.	0
But the - one of the good questions in the audience was, well, yeah, but that wasn't  trained  for that. I mean,	0
this use of a very smooth, uh, spectral envelope is something that, you know, has evolved as being generally a good thing for speech recognition	0
but if you  knew  that what you were gonna do is detect  sonorants  or not - So sonorants and non-sonorants is - is -	0
is almost like [MASK] except I guess that the voiced stops are -	0
are also called [MASK] Uh, so it's -	0
it's - uh, but with the exception of the  stops  I guess it's pretty much the same as [MASK] right? So - so -	0
if you  knew  you were doing that, if you were doing something say for a - a, uh - a - a  Vocoder,	0
you wouldn't  use  the same kind of features. You  would  use something that was sensitive to the periodicity and - and not just the envelope.	0
Uh, and so in that sense it was an unfair test. Um,	0
so I think that the questioner was  right.  It - it was in that sense an unfair test. Nonetheless, it was one that was  interesting  because,	0
uh, this  is  what we are actually using for speech recognition, these smooth envelopes. And	0
this says that perhaps even, you know, trying to use them in the best way that we  can,  that - that - that we ordinarily  do,  with,	0
you know, [MASK]  and so forth, you - you don't, uh, actually  do  that well on determining whether something is  sonorant  or not. Which means you're gonna make errors between similar sounds that are son- sonorant or obstruent.	0
Didn't they also do some kind of an oracle experiment	0
where they said "if we  could detect the sonorants perfectly  and then show how it would improve	0
I  thought  I remember hearing about an experiment like that.	0
The- these same people? I don't  remember  that.	0
That would - that's - you're right, that's exactly the question to follow up this discussion, is suppose you did that, uh, got that right. Um,	0
What could be the other low level detectors, I mean, for -	0
Other kind of features, or - ?  in addition to [MASK] or - ?	0
Th- that's what you want to - to - to go for also or - ?	0
Oh, build other - other detectors on different  phonetic features? Um,	0
Yeah, I d- I don't know.	0
I mean, w- easiest thing would be to go - go do some  voicing  stuff but that's very [MASK]	0
When we - when we talked with John Ohala the other day we made a list of some of the things that w-	0
Yeah, so there's a half dozen like that that are -  Now this was coming at it from a different  angle  but maybe it's a good	0
way to  start.  Uh, these are things which, uh,	0
John felt that a - a, uh - a  human  annotator	0
would be able to reliably  mark.	0
So the sort of things he felt would be  difficult  for a human annotator to reliably mark	0
would be  tongue  position kinds of things. Yeah.	0
There's also things like stress.	0
You can look at stress.	0
fit in this thing of coming up with features that will distinguish words from one another, right? It's a - it's a good thing to mark and will probably help us ultimate with recognition but -	0
Yeah, there's a  few  cases where it can like  permit   and  permit.	0
But - that's not very common in  English.  In  other  languages it's more	0
Well, yeah, but i- either case you'd write [MASK] right? So you'd get the  word  right.	0
No, I'm saying, i- i- e- I thought you were saying that stress doesn't help you distinguish between  words.	0
Oh, I see what you're saying. As long as you get -	0
We're g- if we're doing - if we're talking about  transcription  as opposed to something else -	0
So where it could help is maybe at a  higher  level. Yeah. Understanding, yeah. Exactly.	0
Like a understanding application. Yeah.	0
Yeah. But that's this  afternoon's  meeting. Yeah.  We don't understand anything in this meeting.	0
Yeah, so that's - yeah, that's, you know, a neat - neat thing and - and, uh -	0
S- so, um, Ohala's going to help do these, uh  transcriptions of the meeting data?	0
Uh, well I don't know. We d- we sort of didn't get that far. Um, we just talked about some	0
possible features that could be marked	0
because of having maybe some extra transcriber time we thought we could go through and mark some portion of the  data  for that.	0
Yeah, I mean, that's not an immediate problem, that we don't immediately have a lot of extra transcriber time. But - but, uh, in the long term I guess Chuck is gonna continue the dialogue with John and - and, uh,	0
and, we'll - we'll end up doing  some  I think.	0
I'm definitely interested in this	0
area, too, f- uh, acoustic feature	0
Yeah, I think it's an interesting - interesting way to go. Um,	0
I say it like "said-int" . I think it has a number of good things.	0
so, uh, y- you want to talk maybe a c- two or three minutes about what	1
we've  been talking about today and other days?	1
we're interested in, um, methods for far mike speech recognition, um,  mainly, uh, methods that deal with the reverberation  in the far mike signal. So, um,	1
one approach would be, um, say [MASK] like was used in Aurora one and, um,	1
there are other approaches which actually attempt to   remove  the reverberation, instead of being  robust  to it like [MASK]	1
And so we're interested in, um,	1
comparing the performance of  um, a robust approach like [MASK] with these, um, speech enhancement or  de-reverber-  de-reverberation approaches.	1
it looks like we're gonna use the Meeting Recorder digits data for that.	0
And the de-reverberation algorithm, do you have -	0
can you give some more details on this or - ? Does it use one microphone?	0
Several microphones? Does it - ?	0
there was something that was done by, um,	0
a guy named Carlos, I forget his last name,  who worked with Hynek, who, um,	0
um, it was like [MASK] in the sense that of it was, um,	0
um, except he used a longer  time  window,	0
like a  second  maybe. And the reason for that is [MASK] is too short to, um	0
include the whole, um, reverberation -	0
um, I don't know what you call it  - the reverberation response.	0
I- if you see wh- if you see what I mean.	0
The reverberation filter from my mouth to that mike is like - it's t- got- it's too long	0
in the - in the time domain for the um - for the RASTA filtering to take care of it.	0
then there are a couple of other speech enhancement approaches	0
which haven't been tried for speech recognition yet but have just been tried for enhancement, which, um,	0
um, you can do [MASK]	0
analysis of th- of the signal you get at the far microphone and	0
the, um, all pole filter that you get out of that should be good.	0
It's just the, um, excitation signal	0
that  is  going to be distorted by the reverberation	0
and so you can try and reconstruct a better excitation signal	0
and, um, feed  that  through the i-	0
um, all pole filter and get enhanced speech with reverberation reduced.	0
There's  also  this, uh, um,	1
uh, echo cancellation stuff that we've sort of been chasing, so, uh	1
we have, uh - and when we're saying these digits now we  do  have a close microphone signal and then there's the distant microphone signal.	1
And you  could  as a kind of  baseline  say, "O_K,  given  that we have  both  of these, uh, we  should  be able to do, uh, a  cancellation. "	1
we - we, uh, essentially identify the system in between - the linear time invariant system between the microphones and - and - and - and re- and invert it,	1
uh, or - or cancel it out to - to some - some reasonable approximation	1
through one method or another. Uh, that's not a  practical  thing,	0
uh, if you have a distant mike, you  don't  have a close mike ordinarily,  but we thought that might make - also might make a good  baseline.	0
Uh, it still won't be  perfect  because there's  noise.	0
Uh,  but  -  And then there are s- uh, there are	0
single  microphone methods that I  think  people have done for, uh - for this kind of de-reverberation. Do y- do you know any	0
references to any? Cuz I - I w- I was - w- w- I - I lead him down a - a bad	0
I g- I guess - I guess when people are working with single microphones,	0
they are more trying to do -	0
well, not - not very -	0
Well, there is [MASK]	0
but also trying to mmm,	0
but in the um -	0
not in the time domain but in the	0
the stream of features  uh I guess .	0
Well,  @@   there - there's someone working on this on	0
we should try t- to - He's working on this, on trying to -	0
on re- reverberation, um -	0
The  first  paper on this is gonna have  great  references, I can tell already.	0
It's  always  good to have references, especially when reviewers read it or - or one of the authors and,	0
feel  they'll  "You're O_K, you've r- You cited me."	0
Well, he did  echo cancellation  and he did some fancier  things  like, uh,	0
uh, training different network on different reverberation conditions and then trying to find the best one, but. Well.	0
The oth- the other thing, uh, that Dave was talking about earlier was, uh, uh, multiple mike things,	0
uh, where they're  all  distant. So, um, I mean, there's - there's  all  this work on  arrays,  but the  other  thing is, uh,  what can we do that's cleverer	0
that can take some advantage of only  two  mikes, uh, particularly if there's an obstruction  between  them, as we - as we have over  there.	0
If there is - ?	0
It creates a  shadow  which is - is  helpful.  It's part of why you have such good directionality with,	0
with two  ears  even though they're not several feet  apart.	0
most - for  most  people's heads.	0
So that - Yeah, the - the  head,  in the way, is really -	0
That's what the head's for?	0
Yeah, it's to separate the ears.	0
Anyway, O_ K.  Uh, I think that's - that's all we have this week. And, uh, I think it's digit time.	0
Actually the, um - For some reason the digit forms are  blank.	0
Uh, I think th- that may be due to the fact that	0
Adam ran out of digits,  uh, and didn't have time to regenerate any.	0
Oh! I guess it's - Well there's no real reason to write our  names  on here then, is there?	0
Yeah, if you want to put your credit card numbers and, uh -	0
Or do - did any - do we need the names for the  other  stuff, or - ?	0
Uh, yeah, I do need your names and - and the time, and all that, cuz we put that into the "key" files. Um.	0
That's why we have the forms, uh, even if there are no digits.	0
O_K, yeah, I didn't  notice  this. I'm sitting here and I was - I was about to  read   them    too.   It's a, uh, blank sheet of paper.	0
So I guess we're - we're done.	0
Yeah, yeah, I'll do my credit card number  later.  O_K.	0
