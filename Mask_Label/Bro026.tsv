We - we had a meeting with, uh - with Hynek,	1
um, in - in which, uh,	1
summarized where they were and -	1
talked about where we were gonna go.	1
So that - that happened sort of mid-week.	1
D- did - did you guys get your code	1
It's - it's - it's - it was updated yesterday, right?	1
Oh, right, I saw - I saw the note.	0
You probably received the mail. Yeah.	0
So there is th- then - the - all the new features  that go in .	1
These are the - Yeah.	1
uh, up at [MASK] grabbing code	1
Uh, I don't think - I don't think -	0
I don't know if they use it, but.	1
Yeah, I- I don't think anybody up there is like	1
working on it right now.	1
I think it more likely that what it means is that when Sunil is up there	0
So right now nobody's working on [MASK] there.	1
They're - Yeah. They're working on a different task.	1
But what'll happen is - is he'll go back up there	0
and, uh, Pratibha will come back from -	0
from, uh, the east coast.	0
and - and I guess actually, uh, after [MASK] for a little bit, uh,  he'll  go up there too. So, actually	0
who's working on it  will be up there for at least a little while.	0
So they'll remotely access it   from there . Yeah.	0
remotely accessing [MASK] using, uh,	1
I don't know if Hari did that or - You d-	0
I  can actually do it today. I mean, I can just log into -	0
Have you tried it yet?	0
So I- I'll try it today.	0
Actually I - I tried wh- while -	1
repository, I tried from Belgium.	1
logged in there and I tried	1
So, right now it's the mechanism with S_S_H.	0
I don't  s- I didn't set up -	0
You can also set up [MASK]	0
well  uh, a main server, or d- You can do [MASK]	0
Then that's using [MASK] password mechanism and all that, right?	0
But I didn't do that because I was not sure about	0
security problems. I - I would have to -	0
when you came in from Belgian -	0
was it asking you for your own	0
So if yo- you can only do that if you have an account at ICSI?	0
Cuz there is an - a way to set up anonymous [MASK] right? So that -	0
Yeah, you ha- in this way you ca- you have to set up a C_V_S server but then,	0
yeah, you can access it.	0
you   - you can set up priorities. You can access them and mostly if you - if y- the set- the server is set up like this.	0
Oh, O_K. So the anonymous mechanism -	0
Because a lot of the open source stuff works with anonymous C_V_S and I'm just wondering -	0
I mean, for our  transcripts  we may want to do that.	0
Yeah, for  this  stuff I don't think we're	0
I mean, we're still so much in development. We want to have just the insiders.	0
Oh, I wasn't suggesting for this. I'm	0
thinking of the Meeting Recorder  stuff but.	0
Well, I mean, I think	0
to me might be - I me- I'm sure you've just been working on -	0
details of that since the meeting, right?	0
That was - that was Tuesday.	0
well, I - I've been - I've been train-	0
So they should be ready.	0
But I guess maybe the thing -	1
yo- you guys weren't at that - that meeting,	1
might be just - just to,	1
the conclusions of the meeting.	1
You're talking about the meeting with Hynek?	1
Yeah. Cuz that was sort of, uh - we - we'd sort of been working up to that,	0
that - that, uh, he would come here this week and -	0
and we would sort of -	0
Since he's going out of town	1
like  now,  and I'm going out town in a couple weeks,	1
and time is marching, sort of,	1
given all the mu- many wonderful things we could be working on, what - what will we actually focus on?	1
and what do we freeze? And, you know, what do we - ?	1
software that these guys created was certainly a - a key part.	0
So then there's something central and there aren't at least	0
a bunch of different versions going off in - in ways that	0
and then  within  that, I guess the idea was to freeze a certain set of  options  for now,	1
to  run  it, uh, a particular way,	1
and decide on what things	1
are gonna be  experimented  with, as opposed to just experimenting with everything.	1
So keep a certain set of things constant.	1
maybe describe roughly what -	1
what we are keeping constant for now, or - ?	1
So we've been working like six weeks on -	1
on the noise compensation and	1
Are you gonna use - which of the two techniques?	1
So finally it's - it's, um, [MASK]	1
And it uses, uh, two steps,	0
smoothing of the transfer function,	0
there is a further smoothing along frequency,	0
which use a sliding window of twenty [MASK]	0
So this is on the -	0
before any [MASK] has been done? This is -	0
This - this smoothing is done on the estimate,	0
um, of what you're going to subtract?	0
Or on the thing that has already had something subtracted?	0
it's on the transfer function.	0
Oh, it's on the transfer function for [MASK]	0
Yeah, so basically we tried	0
different configuration within this idea.	0
We tried u- u- applying this on [MASK] having	0
Well, finally we end up with  this configuration that works, uh, quite well. So we are going to fix this for the moment and work on the other aspects of  the whole system. So -	1
Actually, let me int- eh,	0
Dave isn't here to talk about it, but let me just interject.	0
i- I mean, you would know whether it's  true in  fact,	0
is somewhat independent from the rest of it. I mean, because you - you re-synthesize speech, right?	0
Uh, well you don't - I guess you  don't  re-synthesize speech, but you could -	0
We - we do not fo-	0
Well - well, we  do,  but we don't - don't re-synthesize. In - in the program we don't re-synthesize and then re-analyze once again. We just	0
use the clean F_F_T bins.	0
But you have a re-synthesized thing that you - that's an - an option  here .	0
This is an option that - then you can - Yeah.	0
Yeah, I gu- I guess my point is that, um,	0
i- in some of the work  he's  doing in [MASK] one of the things that we're finding	0
is that, uh, it's - it's - for the -	0
we can just deal with [MASK] and his techniques work really  well.	0
But for the  real  situation	0
uh, problem is, is that you don't just have [MASK] you hav	0
So in fact it might be a very nice thing to do, to just take the noise	0
removal part of it and put that in front of what he's looking at.	0
And, uh, generate new files or whatever,	0
uh - and  then  do the reverberation part.	0
So Dave hasn't  tried that yet?	0
No, no. He's - I mean, e- a-	0
I guess he's busy with -	0
but - but, you know, that'll - uh, it's clear that we, uh -	0
we are not - with the  real  case that we're looking at,	0
we can't  just  look at reverberation in isolation because the interaction between that and noise is - is considerable.	0
I mean, in the past we've looked at, uh,	0
and this is hard  enough,	0
the interaction between channel effects	0
and - and, uh - and additive noise, uh, so [MASK] and - and additive effects.	0
And that's hard enough. I mean, I don't think we really - I mean, we're  trying  to deal with that.	0
In a sense that's what we're trying to deal with in [MASK]	0
And we have, uh, the, uh, uh, [MASK] stuff that in principle is doing something about [MASK]	0
noise suppression that's doing something about noise.	0
Uh, even that's hard enough. And - and [MASK] as well, in that s- category.	0
There's all these interactions between these two and that's part of why these guys had to work	0
so hard on - on juggling everything around.	0
But now when you throw in the reverberation, it's even worse,	0
because not only do you have these effects, but you  also  have some long time effects.	0
uh, is doing some nice things under some conditions with - with long time effects but when it's - when there's noise there too,	0
it's - it's - it's pretty hard. So we have to start -	0
Since any - almost any real situation is gonna have - uh, where you have the microphone distant,	0
is going to have both things,	0
we - we actually have to think about both at the same time.	0
So there's this noise suppression thing, which is sort of worked out and then,	0
uh, maybe you should just continue telling what - what else is in the -	0
the other parts of the system are the -	0
the blocks that were already present before and that	0
we did not modify a lot.	0
So that's - again, that - that's the Wiener filtering, followed	0
uh, that's done at [MASK]	0
The - the - the filtering is done	0
Then finally, we compute delta and	0
Right, and then in parallel with - an - [MASK] And then following neural net, some - probably some orthogonalization. Uh -	0
be [MASK] also, used for estimated silence probabilities. And	0
the input of this [MASK] would be	0
somewhere between log  mel bands or	0
one of the earlier stages of the processing.	0
So that's sort of - most of this stuff is - yeah, is operating  parallel  with this other stuff.	0
So the things that we, um,	0
I guess we sort of - uh,	0
There's - there's some, uh, neat ideas for  [MASK] -	0
So, I mean, in -	0
I think there's sort of like -	0
There's a bunch of tuning things to improve stuff. There's questions about	0
various places where there's an exponent, if it's the right exponent, or	0
ways that we're estimating noise, that we can improve estimating noise. And there's gonna be a host of those. But  structurally  it seemed like the things -	1
the main things that - that we brought up that, uh, are - are gonna need to get worked on seriously are,	1
uh, uh, a -  [MASK]	1
putting the neural net on,	1
um, which, you know, we haven't been doing anything with,	1
the, uh, neural net at the end there,	1
opening up the second front.	1
The other half of the channel?	1
Yeah, yeah, I mean, cuz we - we have - we have, uh,	1
uh, half the - the, uh,	1
data rate that they allow.	1
And, uh, so the  initial  thing which came from, uh, the meeting that we had down south	1
we'll initially just put in [MASK]	1
There's a question about  exactly  how we do it. We probably will go to something better later,	1
the  initial  thing is that [MASK] behave  differently,  so.	0
I think Tony Robinson used to do -	0
I was saying this before. I think he used to do	0
He used them as alternate features.	0
So if you took the system the way it is now, the way it's fro- you're gonna freeze it,	1
and it ran it on the last evaluation, where it would it be?	1
Ri- right now it's second.	1
Although you - you know, you haven't  tested  it actually on the German and Danish, have you?	0
No, we didn't.  No, um.	0
So on the ones that you  did  test it on it would have been  second?	0
Would it - I mean -	0
When you're saying second, you're comparing to the numbers that the, uh - that the best system before got on, uh - also without German and Danish?	0
And th- the ranking actually didn't change after the German and Danish.	0
didn't  before,  but I'm just asking	0
where theirs was without the German and Danish, right?	0
where were we actually on the last test?	0
Oh, we were also esp-	0
essentially second, although there were -	0
I mean,  we  had a couple systems and  they  had a couple systems. And so, I guess by that	0
we were  third,  but I mean,	0
there were two systems that were pretty close,	0
that came from the same place.	0
so  institutionally  we were -  we were second,	0
with, uh, the third - third system.	0
We're - so this  second  that you're saying now is	0
Uh, no I think it's also institutional, isn't it? Right? I mean, I think  both  of their systems probably -	0
Uh, we are between their two systems. So	0
It is a triumph .	0
Their - their first system is fifty-four point something. And, uh, we are fifty-three point something.	0
And their second system is also fifty-three point something.	0
But everything is  within the range of one -	0
Yeah, so - so basically they're all - they're all pretty close. And -	1
and,  um, you know, in some sense we're all doing fairly similar things.	1
Uh, I mean, one could argue about [MASK] and so forth but I - I think,	0
you know, in a lot of ways we're doing very similar things. But what - what -	0
So how did they fill up this -	1
all these - these bits? I mean, if we're u- u-	1
Um, why are we using half?	1
Well, so you could - you c-	0
Or how are they using  more  than half, I guess maybe is what I -	0
Yeah, so I -  I  think -	0
uh, you guys are closer to it than me, so correct me if I'm wrong,	0
but I - I think that what's going on is	0
that in - in  both  cases,	0
some kind of normalization is done	0
to deal with convola- [MASK]	0
Uh, they have some [MASK] right?	0
In  our  case we have a  couple  things. We have [MASK] and then we hav	1
they seem to comple- complement each other enough and be different enough that they both seem to help - help us.	0
But in  any  event, they're both doing the same sort of thing. But there's one difference.	1
uh, throws away  high  [MASK]	1
And they're not  doing  that.	1
So that if you throw away high modulation frequencies, then you can  downsample.	1
So what if you didn't -	0
So do you  explicitly  [MASK] then?	0
And what if we didn't  do  that?	0
Would we get worse performance?	0
I think it doesn't affect it, does it?	0
Yeah, not better, not worse.	0
So I think the thing is, since	0
we're not evidently throwing away useful information, let's try to put in some  useful  information.	0
And, uh, so I - you know, we -	1
we've found in a lot of	1
ways for quite a while that having a second stream	1
So that's - that's put in, and	1
you know, it may even end up with [MASK] even though I'm saying I think we could do much better, just because it's simple.	1
And you know, in the long run having something everybody will look at and say, "oh, yeah, I understand", is - is very helpful.	0
So you would - you're -	0
You're thinking to put the, uh,	0
[MASK] in  before  any of the noise removal stuff? or  after?	0
I mean, we were talking about that. It looks like	0
it'd be straightforward to -	0
to, uh, remove the noise,	0
Cuz  that  happens before the  mel  conversion, right?	0
So, I mean, to do it  after  the mel conversion -	0
uh, after the noise removal, after [MASK]	0
There's even a question in my mind anyhow of whether th- you should take the log or not.	0
I sort of think you should, but	0
What about norm- normalizing also?	0
Some  kind would be  good.	0
You know? I would  think.	0
Well, it - it - it -	0
it - so it actually makes it dependent on the overall energy of the -	0
If you  do  or  don't  normalize?	0
If yo- if you  don't  normalize and - if - if you  don't  normalize.	0
Yes, so I mean, one would  think	0
that you would want to normalize.	0
But I - I - w- w-	0
uh, particularly if you take the log,	0
if - if normalization  helps,  then y- you have something to compare against, and say, "O_K, this much effect" -	0
I mean, you don't want to change six things and then see what  happens.  You want to change them one at a  time.  So adding this other  stream  in,	0
that's simple in some way.	0
And then  saying, oh - uh -	0
particularly  because we've found in the past there's all these - these - these different results you get with slight	0
modifications of how you do normalization. Normalization's a very tricky, sensitive thing and  you learn a lot.	0
I would think you would wanna	0
have some baseline that says, "O_K, we  don't  normalize, this is what we get", when we do  this  normalization, when we do  that  normalization.	0
but the  other  question is -	0
So I think  ultimately  we'll wind up doing some normalization. I agree.	0
will it add latency to the system or - ?	1
We're not talking about  computation  time here. We're ta- I think we're pretty far out. So it's just	1
in terms of what data it's depending on. It's depending on the same data as the  other.  So it's in parallel.	1
So with this, uh, new stream would you train up a V_A_D on  both  -  both  features, somehow?	0
No, I guess the V_A_D has its own set of features.	0
I mean, which could be this - one of these streams, or it can be something derived from  these streams.	0
And there is also the idea of using [MASK] maybe, for [MASK]	0
when, she was at [MASK] that	0
Would - would that fit on the handset, or - ?	0
Well, it has t- I mean	0
It would have to fit but -	0
Yeah, if it has to fit the delays and all this stuff.	0
Well, there's the delays and the storage, yeah.	0
But I don't think the storage is so big for that.	0
I think th- the  biggest  we've run into for storage is the neural net.	0
I guess the issue  there  is, are we - are we using [MASK]	0
and - and how big are they?	0
So that'll - that'll be, you know, an issue.	0
Maybe they can be little ones.	0
Cuz she also does the, uh - the correlation-based,	0
And maybe for [MASK] they would be O_K. Yeah.	0
Or a  simple  neural net, right? I mean, the thing is, if you're doing correlation, you're just doing a simple -	0
dot product, you know, with some weights which you happened to learn from this - learn from the  data.  And so,	0
uh, putting a nonlinearity on it is,	0
you know, not that big a deal.	0
It certainly doesn't take much space.	0
So, uh, the question is, how complex a function do you need? Do you need to have	0
an added  layer  or something?	0
you know, it could be big. So.	0
Maybe  s- s-  remind us.	0
So the meeting with Hynek that you guys just had was to	0
decide exactly what you were gonna freeze in this system? Is that - ?	0
Or was there - ?	0
Were you talking about what t-  new  stuff, or - ?	0
What to freeze and then what to do after we  froze.	0
And like I was saying, I think the - you know, the basic	0
directions are, uh, uh -	0
I mean, there's lots of little things, such as improve the noise estimator but the bigger things are adding on the neural net and,	0
I'll actually - after the meeting I'll add the second stream	1
to [MASK] and maybe I'll start with the feature net in that case.	1
It's like, you're looking at [MASK] right?	0
I- I've [MASK] ready also.	0
Well p- two network, [MASK] Mm-hmm.	0
Oh, you already have it?	0
O_K, so just figure how to take the features	1
But, yeah, I think there are plenty of issues to work on for [MASK]  @@ .	0
What about the, um -	1
uh, the new part of the evaluation,	1
the, uh, Wall Street Journal part?	1
Have you ever - ?	0
Have you ever worked with the Mississippi State h- uh, software?	1
Well you - you may be called upon to help,	1
uh, uh, on account of, uh,	1
all the work in this stuff here has been, uh, with small vocabulary.	1
So what - how is the, uh, interaction supposed to happen?	0
Uh, I remember the last time we talked about this,	0
it was sort of up in the air whether  they  were going to be taking, uh,	0
people's features and then running them or they were gonna give the system out or -	0
Oh, so they're gonna just deliver a system basically.	1
Do we already have it?	0
Yeah, th- I - I guess it's almost ready.	1
So they have released their, uh, document,	1
point it  at Chuck, because, I mean -	0
So we'll have to grab this over [MASK] or something?	0
It- no, it's just downloadable from their - from their web site.	0
Is that how they do it?	0
Cuz one of the things that might be helpful, if you've - if you've got time in all of this is, is if -	1
if these guys are really focusing on	1
improving, uh, all the digit stuff, uh, maybe -	1
and you got the front-end from them, maybe  you  could do the runs for the -	1
and - and, you know, iron out hassles that - that you have to,	1
tweak Joe about or whatever, because you're more experienced with running the large vocabulary stuff.	1
So I'll point you to the web site and the mails corresponding.	1
And it - but it's not ready yet, the system?	0
I - I think they are still, uh, tuning something on that.	0
d- they're varying different parameters like the insertion penalty and other stuff, and then seeing what's the performance.	0
Are those going to be	0
parameters that are frozen, nobody can change? Or - ?	0
Uh, w- I guess there is, uh, time during which people are gonna make suggestions.	0
Oh, but  everybody's  gonna have to use the same values.	0
Yeah, I guess. So these sugges- these -	1
this, uh, period during which people are gonna make suggestions is to know whether it is actually  biased  towards any set of features or -	1
Yeah, so I th- th- certainly the thing that I would	1
uh, on in- insertion penalty, language model, scaling, sorts of things.	1
Uh, in which case, um, H- Hari or	1
you know, push the  case	1
And we may be able to revisit this idea about, you know, somehow modifying our features to	1
Yes. In  this  case, that's  right.	0
Um, some of that may be,	0
uh, a last minute rush thing because if the - if our features are changing -	0
Yeah, the other thing is that even though	0
it's starting to seem to me now like November fifteenth is right around the corner.	0
And, um, if they haven't decided things like this,	0
like what the parameters are gonna be for this,	0
uh, when "deciding" is not just somebody  deciding.  I mean, in fact there should be some	0
deciding, which means some experiments and - and so forth. It - it - it  seems  pretty  tight  to me.	0
So wha- what's the significance of November fifteenth?	0
That's when the evaluation is.	0
So, yeah, so after - But, you know, they may even  decide  in the end to push it  off.	0
It wouldn't, you know, entirely surprise me. But, uh,	0
due to  other  reasons, like some people are going away, I'm - I'm hoping it's not pushed off for  a l- a  long  while. That would be, uh - put us in an awkward position. But -	0
Yeah, I think that'll be helpful. There's - there's not anybody [MASK] currently who's -	0
who's, uh, working with this and - and	0
Is - is this part of the evaluation just a  small  part, or ho- how important is this to the overall - ?	0
I - I think it's - it's, um - it depends how badly  you do.	0
I mean, I think that it - it is -	0
This is one of those things that will be debated afterwards?	0
Yeah. Well, I mean, it's - it's -	0
again, you guys correct me if I'm  wrong,  but	0
my impression is that, um,	0
they  want  it as a double check.	0
That you haven't come across - you haven't	0
which are actually gonna do badly	0
for a - a significantly different task,	0
particularly one with larger vocabulary.	0
it's not the  main  emphasis. I mean, the truth is, most of the applications they're looking at are pretty small vocabulary.	0
So it's - it's a double check. So they'll probably assign it some sort of low weight.	0
Seems to me that if it's a double check, they should give you a one or a zero.	0
Y- you  passed  the threshold or you  didn't  pass the threshold, and they shouldn't even	0
care about what the score is.	0
But, I mean, we'll - we'll - we'll see what they come up with. Uh, but	0
in - in the  current  thing, for instance, where you have this well-matched, moderately-matched, and - and mis- highly-mismatched,	0
uh, the emphasis is somewhat on the - on the  well-matched,	0
but it's only a - a  marginal,  right? It's like forty,	0
thirty-five, twenty-five, or something like that. So you still -	0
if you were  way,  way off on the highly-mismatched, it would have a big effect.	0
wouldn't surprise me if they did something like that with  this.  So again, if you're -	0
If it doesn't help you much,	0
uh, for noisy versions of this - of large vocabulary data,	0
then, uh, you know, it may not hurt you  that  much. But if it - if you don't -	0
if it doesn't help you much at  all,	0
um, or to put it another way, if it helps  some  people a  lot  more than it helps  other  people,	0
uh, if their strategies do, then -	0
So is this, uh - ?	0
Uh, Guenter was putting a bunch of Wall Street Journal data on our disks.	0
So that's the data that we'll be running on?	0
we have the  data,  just not the recognizer.	0
So this test may take quite a while to run, then.	0
May- judging by the amount of data that he was putting	0
well there's training and test, right?	0
I - I guess, I'm not sure. I just -	0
No, I mean, if it's like the other things, there's - there's	0
data for training [MASK] and - and data for testing it. So	0
So it - it's -	0
So,  training  the recognizer, but, um	0
But I think it's trained on clean and -	0
Is it trained on clean and - and test on - ?	0
Apparently, no. It's training on	0
a range between ten and twenty D_B, I think, and testing between five and fifteen.	0
what I got  on -	0
It's like a medium - medium-mismatch condition, sort of.	0
So the noise is -	0
There is a range of different noises also - um -	0
which are selected randomly and added randomly,	0
And there are noises that are different from the noises used	0
Yeah. I mean, I wouldn't imagine that the amount of testing data	0
They probably put training - uh, almost certain they put training data there too.	0
Uh, one - one last question on that. When did they estimate that they would have that system available for download?	0
I guess - I guess one - some preliminary version is already there.	0
Oh, so there's w- something you can download to just	0
Yeah, it's already there. Yeah.	0
actually parallel-y doing some modifications also, I think.	0
So I guess the f- final system will be frozen by middle of,	0
like, one more week maybe.	0
Oh, well  that's  pretty soon.	0
Yeah, that's just one more.	0
Is this their, um, [MASK]	0
No, it's just a straightforward [MASK]	0
You know, their - their -	0
They have a lot of options	0
in their recognizer and - and [MASK] is one of the things they've done with it, but it's not their more standard thing.	0
For the most part it's - it's Gaussian mixtures.	0
Yeah, [MASK] It was just a - it - it - it was like a hybrid, like - what? Yeah.	0
Yeah, this is a g- yeah, this i- yeah.	0
So, just so that I understand, they're providing scripts and everything so that	0
you - you push a button and it does  training,  and then it does  test,  and everything?	0
I - I - I think - yeah, I - I guess something like that.	0
as painless as possible, is what -	0
Do they provide all the scripts, everything, and then -	0
Somehow yo- there's hooks to put your	0
Yeah, I th- I think.	0
In fact, I mean, if you look into it a little bit, it might be reasonable - You know Joe, right?	1
Yeah. Just to sort of ask him about the issue of, um,	1
different features having different kinds of, uh, scaling characteristics and so on. So that,	1
you know, w- w- possibly having entirely different optimal values for - for the usual twiddle factors and what's - what's the plan about that?	0
So sh- shall we, like, add Chuck also to the mailing lists?	1
It may be better, I mean, in that case if he's going to -	0
Because there's a mailing list for this.	0
Yeah, I guess maybe Hari or Hynek,	1
one  of them, has to  send a mail to Joe.	1
Or maybe if you -	0
I - I could send him an email.	1
Well, yeah, to add or maybe wh-	0
I - I know him really well. I - I was just talking with him on email the other day actually.	1
Yeah, so that's just fine. So -	0
Uh, yeah, and just, um, se- maybe see. Do you have Hari's, uh - ?	1
Yeah, so maybe just C_C Hari and say that you've just been asked to handle the large vocabulary part here,	1
and, uh, you know, end.	0
Would it be better if I asked Hari to ask Joe?	0
Why don't you just ask Joe but C_C Hari, and then in the note say, "Hari, hopefully this is O_K with you".	1
And then if Joe feels like he needs a confirmation, Hari can answer it.	1
That way you can get started asking  Joe quickly while he's - while he's maybe still,	0
you know, putting in nails and screws and doing  that stuff	0
And there is an, uh, archive of all the mails that has been	0
gon- that has gone, uh, between these people - among these people.	0
So just you can see all this	0
mails in [MASK] web site - Mississippi web site.	0
Is that a password controlled - ? O_K.	0
So, like - like, it's, like -	0
Have you thought about  how long  would be	0
uh, most useful for you to go up to [MASK]	0
I don't know, uh. We can -	0
For September, we can set up	0
a work schedule and we can maybe work independently.	0
And then at some point it maybe be better to	0
Oh, so you're - you're imagining more that you would come back here first for a while and then - and then go up there? I mean, it's to you. I ju- you guys are	0
Well, y- anyway, you don't have to decide this second but thi- think about it - about what - what you would think would be the -	0
the best way to work it. I'll support it either way, so.	0
Got anything to tell us?	1
I guess, let me put it in context.	0
O_K, so we're talking about	1
And, uh, I was looking at some of the work that,	1
uh, Sangita was doing on these [MASK] things. So	1
she has, um - she has	1
um, a certain set of [MASK]	1
from - from TIMIT, right?	1
the most common [MASK] And each one of them has - has a - a nice pattern over time, a one - one second window.	0
And it has - has these patterns.	0
Um, so she has, um	0
um, times fifteen, for each of the fifteen critical bands.	0
And, um,  she does this [MASK]	0
which - which basically, um, is [MASK] that, uh, starts with many, many, many different points - many different clusters - uh, corresponding to the number of data, uh, patterns that you have in the data.	0
And then you have this distance mej- metric which, uh, measures how - how closely related they are. And you start, um	0
by merging the patterns that are most closely related.	0
And you create a tree.	0
And y- yeah, yeah, a dendrogram tree.	0
And then you can pick, uh, values anywhere along that tree to	0
fix your set of clusters.	0
Right, usually it's when, um -	0
when the sol- similarity measures,	0
um, don't go down as much.	0
And so, uh - so you stop at that point.	0
And what she found was, sh- um, was there were five broad,	0
uh, corresponding to, uh, things like, uh, [MASK] and, uh,	0
And, uh, one for silence and - and another one for schwa - [MASK]	0
um, I was thinking about ways to - to generalize this because w- you're - it's sort of like a -	1
it's not a completely automatic way of clustering,	1
because yo- beforehand you have these - these [MASK] and you're saying that -	0
that these frames correspond to this particular [MASK]	0
Um, and that's - that's constraining your - your clustering to -	0
to the set of phonemes that you already have.	0
Um, whereas maybe we want to just take - take a look at, um, arbitrary windows in time,	0
um, of varying length, um, and cluster those. And I'm thinking if we -	0
if we do that, then we would probably, um, at some point in the clustering algorithm	0
find that we've clustered things like, O_K, thi- this is a transition, um, this is a relatively stable - stable point.	0
Um, and I'm hoping to find other things of - of similarity and maybe use  these  things as the intermediate, um - intermediate categories that, uh, um, I'll later classify.	0
Are you looking at these in narrow bands?	1
Cuz that's what you're gonna be  using,  right?	0
Yeah, yeah. I - I haven't exactly figured out, um, the exact details for that but, uh,	0
the - the representation of the data that I was thinking of, was using, um, critical band, um, energies,  um, over different lengths of time. So -	0
Yeah, I mean, it seems somehow that needs th- uh, there's a couple things that I wonder about with this. I mean, so one is -	1
is,  again, looking at the same representation, I mean, if you're going for this sort of thing where you have	1
uh, little detectors that are looking at narrow bands,	1
what you're going to be looking  for  should be some category that you can find with the narrow bands.	1
That - that seems to be kind of fundamental to it.	0
Um, and then the other thing,	0
that I  wonder  about with it,	0
and - and don't take this in the wrong way, like I - I know what I'm doing or anything,	0
answer about this sort of thing is that if you're trying to find	1
the right system in some sense, whether you're trying by categories or - or parameters	1
um, and your goal is discrimination,	1
then having choices based on discrimination as opposed to, um, unsupervised  nearness  of things,	1
Um, and I don't know if that - I mean, since you're dealing with issues of  robustness,	1
you know, maybe - maybe this isn't right, but	1
it'd be something I'd be concerned about. Because, for instance,	1
uh, i- i- if you remember from - from, uh - from your - your  quals,  John Ohala saying that, uh, "buh"  and "puh"  differed, uh, not really cuz of voicing but because of aspiration.	1
I mean, in as far as wha- what's really there in the acoustics.	0
So, um, if you looked -	1
if you were doing some coarse clustering, you probably would put those two  sounds  together.	1
And yet, I would gue- I would guess that many of your recognition errors were coming from, uh, um, pfft,	1
screwing up on this distinction.	1
So, in fact, it's a little hard because recognizers, to first order,  sort  of work.	0
And the reasons we're doing the things we're doing is because they don't work as  well  as we'd like.	0
And since they  sort  of  work,	0
uh, it means that they are already doing - if you go and take	1
any recognizer that's already out there and you say, "how well is it distinguishing between  [MASK] "	1
Boy, I bet they're all doing	1
nearly perfectly on this, right? So these - these big categories that differ in huge obvious ways, we already know how to do.	1
So, what are we bringing to the party? I mean, in  fact  what we wanna do is have something that, particularly in the presence of noise,	0
uh, is better at distinguishing between, uh, categories that are actually  close  to one another,	0
and hence, would probably be  clustered  together.	0
So  that's  th-  that's  the  hard  thing. I mean, I understand that there's this other	0
constraint that you're considering, is that you wanna have categories that, uh - that would be straightforward for, say, a human being to mark if you had manual annotation.	0
And it's something that you really think you can pick up. But	0
I think it's also essential that you wanna look at what are the   confusions	0
that you're making and how can you come up with, uh,  categories  that, uh, can  clarify  these  confusions.	0
So, I mean, the  standard  sort of way of doing that is take a look at the algorithms you're looking at, but then throw in some discriminative aspect to it.	0
Y- y- this is more like, you know, how does [MASK] differ fr	0
I mean, they're the same sort of thing. They're both orthogonalizing. But,	0
you know - and - and, um,	0
this is a little  harder  because you're not just trying to find  parameters.  You're actually trying to find the - the - the - the categories  themselves.	0
Uh, so a little more like brain surgery, I think  on yourself.  Uh.  So, uh  Um, anyway.	0
You've been thinking about this problem for a  long  time actually. I mean, well -	0
W- actually, you stopped thinking about it for a long time, but you  used  to think about it  a lot. And you've been thinking about it more now, these categories.  Mm-hmm.	0
I don't - I don't - um, it's not clear to me how to reconcile, you know, what you're saying, which I think is right, with	0
the way I've been looking at it. That it's - it's - it's all not very clear to me. But	0
it seems to me that the desire - the desirable feature to have is something that, um,	0
is bottom-up. You know, however we do that. And	0
I guess what I don't understand is how to do that	0
and still be discriminative, because to be discriminative you have to have categories	0
and the only categories that we know of to use are sort of these human - human sig- significant - categories that are significant to humans, like phonemes, things like that. But that's sort of what you want to  avoid.  And so	0
Well, here's a - here's a, uh, uh	0
that feels - I don't know how to get out of this.	0
Here's a generic and possibly useless thought, which is,	0
um, what do you  really  - I mean, in a sense the only s- s- systems that make sense,	0
are ones that - that have something from top-down in th- in them.	0
Right? Because if e- even the smallest organism that's trying to learn to do anything, if it doesn't have any kind of  reward	0
for doing - or penal-  penalty  for doing anything, then it's just going to behave randomly.	0
So whether you're talking about something being learned through evolution or being learned through experience, it's  gotta  have something come down to it that gives its reward or, you know, at  least  some [MASK] right?	0
So the question is, how  far  down?	0
We could stop at words, but we don't, right? We go all the way down to phonemes.	0
Right, but I me- I - I think that maybe in some ways part of the difficulty is - is trying to deal with the - with these [MASK]	0
You know, and - and - and i- it's almost like you want  categories  if - if our - if our, uh, um,	0
metric of - of goodness, uh, i- if our - correction - if our metric of  badness   is word error rate	0
then, um, maybe we should be looking at words.	0
I mean, for - for - for very nice, uh, reasons we've looked for a while at syllables, and they have a lot of good properties, but	0
i- i- i- if you go all the way to  words,  I mean, that's  really  - I mean, d- w-	0
In many applications you wanna go  further.  You wanna go to  concepts  or something, or have - have - have concepts, actions, this sort of thing. But, words aren't bad, yeah. And - and	0
But words would be a nice -	0
Yeah, so the common - right, the common wisdom is you can't do  words  because there's too many of them, right? So you have to have some smaller set that you can	0
and - and so everybody goes to  [MASK]  But the problem is that we - we build models of words in terms of  [MASK]  and these models are -	0
are  really  cartoon-ish, right? So when you look at conversational speech, for example, you don't see [MASK] that you - that you have in your  word  models.	0
But - but - but we're not trying for  models  of words here. See, so her- here's maybe where - If the issue is that we're trying to come up with, um, some sort of intermediate categories which will then be useful	0
then  maybe it doesn't  matter	0
that we can't have enough -	0
what you wanna do is - is build up these categories that are - that are best for word recognition.	0
And - and somehow if that's built into the loop of what the categories - I mean, we do this every day	0
in this very  gross  way of - of running o- a thousand experiments because we have fast computers and picking the thing that has the best word error rate.	0
In some way - I mean, we derive that all the time. In some ways it's really not  a bad - bad thing to do because it tells you in fact how your adjustments at the very low level affect the -	0
Um, so maybe there's a way to even put that in in a much more automatic way, where you take, you know, something about the error at the level of the word or some other - it could be syllable - but in some large unit,	0
uh - yeah, you may not have word models, you have phone models, whatever, but you sort of  don't worry about that,	0
and just somehow feed it back through. You know, so that's, uh, wh- what I called a useless comments because I'm not really telling you how to do it. But I mean, it's a -  it's - it's, you know - it	0
No, but I think the important part in there is that, you know, if you want to be discriminative, you have to have	0
And I think this - the important categories are the words,	0
Right. If you can put the words in to the loop somehow for determining goodness of your sets of clusters -	0
Now, that being said, I think that - that if you have something that is, um - i-	0
Once you start dealing with spontaneous speech, all the things you're saying are - are really true.	0
If you  have  read  speech that's been manually annotated, like TIMIT,	0
then, you know, i- i- you- the phones are gonna be right, actually,  for the most part. So - so, uh, it doesn't really hurt  them   to -	0
to do that, to put in discrimination at that level.	0
Um, if you go to spontaneous speech then it's - it's trickier and - and - and, uh, the phones are -	0
uh, you know, it's gonna be based on bad pronunciation models that you have of - and, um -	0
And it won't allow for the overlapping phenomenon that -	0
So it's almost like there's this mechanism that we have that, you know, when - when we're hearing read speech and all the phonemes are there	0
you know, we - we deal with that, but - but when we go to conversational, and then all of a sudden	0
not all the [MASK] are there, it doesn't really matter that much to us as humans because we have some kind of mechanism that allows for	0
these word models, whatever those models are, to be  munged, you know, and - and it doesn't really hurt, and	0
I'm not sure how -  how to build that in.	0
Yeah, I mean, I guess the other thing i- is - is to think of a little bit - I mean, we- when y- when you start looking at these kind of results I think it usually is - is  pretty   intuitive,  but start looking at	0
um, what are the kinds of confusions that you  do  make, uh, you know, between words if you want or - or - or, uh, even phones in - in - in - in read speech, say,	0
uh, when there is noise.	0
You know, so is it more across place or more across manner? Or is it cor- you know, is it - ? I mean, I know one thing that happens is that you - you - you, uh,	0
you lose the, um, uh, low energy phones.	0
I mean, if there's added noise then low energy phones  sometimes don't get heard.	0
And if that - if that is - if it - uh, if that turns it into another word or - or different - you know, or another pair of words or something, then it's more likely to happen. But, um,	0
I don't know, I w- I would - I would  guess  that you'd -	0
W- I don't know. Anyway, that's -	0
I think part of the difficulty is that a l- a lot of the robustness that we have is probably	0
coming from a much higher level. You know, we understand the context of the situation when we're having a conversation. And so if there's noise in there, you know, our brain fills in and  imagines  what - what  should  be there.	0
Yeah. We're - we're doing some sort of  prediction  of what -	0
Oh, sure, that's really big. Uh, but I mean, even if you do	0
um, uh, [MASK] kind of things, you know, where there really isn't an- any information like that, uh, people are still better in noise	0
than they - than they are in - in, uh - uh, than the machines are.	0
So, I mean, that's - i-	0
Right. We can't - we can't get it at all without any language models. Language models are there and important but - but, uh -	0
If we're not working on that then  we should work on something else and improve it, but - especially if it looks like the potential is there. So -	0
Should we do some digits?	0
